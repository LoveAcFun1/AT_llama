nohup: ignoring input

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so
CUDA SETUP: CUDA runtime path found: /home/baishengyuan/anaconda3/envs/nllm/lib/libcudart.so.11.0
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 118
CUDA SETUP: Loading binary /home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...
[2024-01-12 09:48:10,164] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-01-12 09:48:16.430 | INFO     | __main__:init_components:107 - Initializing components...
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:46<00:46, 46.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 23.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.90s/it]
You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
2024-01-12 09:49:16.694 | INFO     | utils.dataset_new:__init__:189 - Loading data: /cto_labs/baishengyuan/noise_llm_data/RE/SciERC
2024-01-12 09:49:16.796 | INFO     | utils.dataset_new:__init__:198 - there are 1366 data in dataset
2024-01-12 09:49:16.798 | INFO     | utils.dataset_new:__init__:189 - Loading data: /cto_labs/baishengyuan/noise_llm_data/RE/SciERC
2024-01-12 09:49:16.835 | INFO     | utils.dataset_new:__init__:198 - there are 397 data in dataset
2024-01-12 09:50:00.479 | INFO     | __main__:main:228 - *** starting training ***
memory footprint of model: 7.040058135986328 GB
trainable params: 39,976,960 || all params: 6,778,392,576 || trainable%: 0.589770503135875
verify all params of the model
torch.float32 302387200 0.044610458395497925
torch.int8 6476005376 0.9553895416045021
torch.float32 ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight']

verify trainable params the model
torch.float32 39976960 1.0
torch.float32 39976960
  0%|          | 0/1710 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  0%|          | 1/1710 [00:22<10:39:12, 22.44s/it]  0%|          | 2/1710 [00:38<8:47:23, 18.53s/it]   0%|          | 3/1710 [00:59<9:21:22, 19.73s/it]  0%|          | 4/1710 [01:20<9:31:53, 20.11s/it]  0%|          | 5/1710 [01:38<9:19:07, 19.68s/it]  0%|          | 6/1710 [01:56<8:58:21, 18.96s/it]  0%|          | 7/1710 [02:13<8:41:47, 18.38s/it]  0%|          | 8/1710 [02:33<8:50:24, 18.70s/it]  1%|          | 9/1710 [02:52<8:53:31, 18.82s/it]  1%|          | 10/1710 [03:13<9:11:16, 19.46s/it]                                                     1%|          | 10/1710 [03:13<9:11:16, 19.46s/it]  1%|          | 11/1710 [03:39<10:15:27, 21.73s/it]  1%|          | 12/1710 [04:01<10:09:18, 21.53s/it]  1%|          | 13/1710 [04:19<9:41:15, 20.55s/it]   1%|          | 14/1710 [04:36<9:09:44, 19.45s/it]  1%|          | 15/1710 [04:55<9:10:16, 19.48s/it]  1%|          | 16/1710 [05:15<9:09:16, 19.45s/it]  1%|          | 17/1710 [05:38<9:39:21, 20.53s/it]  1%|          | 18/1710 [05:57<9:28:08, 20.15s/it]  1%|          | 19/1710 [06:15<9:11:26, 19.57s/it]  1%|          | 20/1710 [06:33<8:57:00, 19.07s/it]                                                     1%|          | 20/1710 [06:33<8:57:00, 19.07s/it]  1%|          | 21/1710 [06:56<9:31:47, 20.31s/it]  1%|▏         | 22/1710 [07:20<9:58:26, 21.27s/it]  1%|▏         | 23/1710 [07:38<9:33:05, 20.38s/it]  1%|▏         | 24/1710 [08:03<10:08:01, 21.64s/it]  1%|▏         | 25/1710 [08:20<9:27:56, 20.22s/it]   2%|▏         | 26/1710 [08:45<10:06:43, 21.62s/it]  2%|▏         | 27/1710 [09:05<9:56:53, 21.28s/it]   2%|▏         | 28/1710 [09:29<10:19:44, 22.11s/it]  2%|▏         | 29/1710 [09:48<9:55:33, 21.26s/it]   2%|▏         | 30/1710 [10:07<9:32:49, 20.46s/it]                                                     2%|▏         | 30/1710 [10:07<9:32:49, 20.46s/it]  2%|▏         | 31/1710 [10:29<9:47:07, 20.98s/it]  2%|▏         | 32/1710 [10:46<9:09:46, 19.66s/it]  2%|▏         | 33/1710 [11:02<8:45:27, 18.80s/it]  2%|▏         | 34/1710 [11:21<8:41:36, 18.67s/it]  2%|▏         | 35/1710 [11:39<8:37:16, 18.53s/it]  2%|▏         | 36/1710 [12:00<8:55:24, 19.19s/it]  2%|▏         | 37/1710 [12:21<9:11:57, 19.80s/it]  2%|▏         | 38/1710 [12:38<8:46:54, 18.91s/it]  2%|▏         | 39/1710 [13:00<9:13:26, 19.87s/it]  2%|▏         | 40/1710 [13:18<8:55:41, 19.25s/it]                                                     2%|▏         | 40/1710 [13:18<8:55:41, 19.25s/it]  2%|▏         | 41/1710 [13:34<8:32:45, 18.43s/it]  2%|▏         | 42/1710 [13:54<8:43:49, 18.84s/it]  3%|▎         | 43/1710 [14:10<8:22:16, 18.08s/it]  3%|▎         | 44/1710 [14:27<8:09:36, 17.63s/it]  3%|▎         | 45/1710 [14:44<8:03:55, 17.44s/it]  3%|▎         | 46/1710 [15:02<8:08:15, 17.61s/it]  3%|▎         | 47/1710 [15:19<8:07:36, 17.59s/it]  3%|▎         | 48/1710 [15:36<7:57:45, 17.25s/it]  3%|▎         | 49/1710 [15:54<8:05:05, 17.52s/it]  3%|▎         | 50/1710 [16:17<8:46:59, 19.05s/it]                                                     3%|▎         | 50/1710 [16:17<8:46:59, 19.05s/it]  3%|▎         | 51/1710 [16:41<9:30:56, 20.65s/it]  3%|▎         | 52/1710 [17:03<9:37:00, 20.88s/it]  3%|▎         | 53/1710 [17:22<9:21:14, 20.32s/it]  3%|▎         | 54/1710 [17:41<9:10:48, 19.96s/it]  3%|▎         | 55/1710 [18:00<9:01:24, 19.63s/it]  3%|▎         | 56/1710 [18:15<8:30:15, 18.51s/it]  3%|▎         | 57/1710 [18:31<8:08:44, 17.74s/it]{'loss': 8.6161, 'learning_rate': 1.4492753623188407e-05, 'epoch': 0.18}
{'loss': 7.9938, 'learning_rate': 2.753623188405797e-05, 'epoch': 0.35}
{'loss': 6.3223, 'learning_rate': 4.202898550724638e-05, 'epoch': 0.53}
{'loss': 3.317, 'learning_rate': 5.652173913043478e-05, 'epoch': 0.7}
{'loss': 1.2882, 'learning_rate': 7.101449275362319e-05, 'epoch': 0.88}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:06<03:28,  3.20s/it][A
  4%|▍         | 3/67 [00:11<04:07,  3.87s/it][A
  6%|▌         | 4/67 [00:15<04:17,  4.08s/it][A
  7%|▋         | 5/67 [00:26<06:39,  6.44s/it][A
  9%|▉         | 6/67 [00:35<07:19,  7.21s/it][A
 10%|█         | 7/67 [00:43<07:35,  7.59s/it][A
 12%|█▏        | 8/67 [00:51<07:28,  7.59s/it][A
 13%|█▎        | 9/67 [00:57<06:50,  7.07s/it][A
 15%|█▍        | 10/67 [01:01<06:03,  6.38s/it][A
 16%|█▋        | 11/67 [01:10<06:40,  7.15s/it][A
 18%|█▊        | 12/67 [01:23<08:07,  8.86s/it][A
 19%|█▉        | 13/67 [01:28<06:48,  7.57s/it][A
 21%|██        | 14/67 [01:33<06:03,  6.86s/it][A
 22%|██▏       | 15/67 [01:39<05:38,  6.52s/it][A
 24%|██▍       | 16/67 [01:46<05:38,  6.63s/it][A
 25%|██▌       | 17/67 [01:52<05:35,  6.70s/it][A
 27%|██▋       | 18/67 [02:01<05:49,  7.13s/it][A
 28%|██▊       | 19/67 [02:07<05:37,  7.04s/it][A
 30%|██▉       | 20/67 [02:19<06:39,  8.51s/it][A
 31%|███▏      | 21/67 [03:18<18:01, 23.52s/it][A
 33%|███▎      | 22/67 [03:27<14:22, 19.16s/it][A
 34%|███▍      | 23/67 [03:32<10:51, 14.81s/it][A
 36%|███▌      | 24/67 [04:30<19:59, 27.90s/it][A
 37%|███▋      | 25/67 [04:52<18:13, 26.02s/it][A
 39%|███▉      | 26/67 [04:57<13:30, 19.77s/it][A
 40%|████      | 27/67 [05:05<10:54, 16.36s/it][A
 42%|████▏     | 28/67 [05:13<08:53, 13.67s/it][A
 43%|████▎     | 29/67 [06:10<17:03, 26.92s/it][A
 45%|████▍     | 30/67 [06:21<13:38, 22.12s/it][A
 46%|████▋     | 31/67 [06:24<09:50, 16.40s/it][A
 48%|████▊     | 32/67 [06:41<09:31, 16.32s/it][A
 49%|████▉     | 33/67 [06:46<07:28, 13.18s/it][A
 51%|█████     | 34/67 [06:53<06:13, 11.33s/it][A
 52%|█████▏    | 35/67 [06:59<05:09,  9.68s/it][A
 54%|█████▎    | 36/67 [07:07<04:38,  9.00s/it][A
 55%|█████▌    | 37/67 [07:14<04:16,  8.53s/it][A
 57%|█████▋    | 38/67 [07:22<04:02,  8.38s/it][A
 58%|█████▊    | 39/67 [07:29<03:40,  7.88s/it][A
 60%|█████▉    | 40/67 [07:35<03:14,  7.22s/it][A
 61%|██████    | 41/67 [07:41<03:00,  6.96s/it][A
 63%|██████▎   | 42/67 [07:48<02:54,  6.97s/it][A
 64%|██████▍   | 43/67 [07:56<02:58,  7.42s/it][A
 66%|██████▌   | 44/67 [08:06<03:06,  8.12s/it][A
 67%|██████▋   | 45/67 [08:11<02:40,  7.27s/it][A
 69%|██████▊   | 46/67 [08:19<02:33,  7.30s/it][A
 70%|███████   | 47/67 [08:27<02:31,  7.56s/it][A
 72%|███████▏  | 48/67 [08:37<02:37,  8.27s/it][A
 73%|███████▎  | 49/67 [08:49<02:49,  9.43s/it][A
 75%|███████▍  | 50/67 [08:56<02:26,  8.60s/it][A
 76%|███████▌  | 51/67 [09:10<02:45, 10.32s/it][A
 78%|███████▊  | 52/67 [09:16<02:15,  9.04s/it][A
 79%|███████▉  | 53/67 [09:26<02:08,  9.21s/it][A
 81%|████████  | 54/67 [09:35<02:01,  9.33s/it][A
 82%|████████▏ | 55/67 [09:44<01:49,  9.15s/it][A
 84%|████████▎ | 56/67 [09:49<01:27,  7.94s/it][A
 85%|████████▌ | 57/67 [10:49<03:54, 23.46s/it][A
 87%|████████▋ | 58/67 [10:57<02:50, 18.93s/it][A
 88%|████████▊ | 59/67 [11:08<02:13, 16.63s/it][A
 90%|████████▉ | 60/67 [12:06<03:22, 28.94s/it][A
 91%|█████████ | 61/67 [12:11<02:09, 21.65s/it][A
 93%|█████████▎| 62/67 [12:20<01:30, 18.05s/it][A
 94%|█████████▍| 63/67 [12:31<01:03, 15.76s/it][A
 96%|█████████▌| 64/67 [12:38<00:39, 13.17s/it][A
 97%|█████████▋| 65/67 [12:42<00:20, 10.32s/it][A
 99%|█████████▊| 66/67 [12:50<00:09,  9.77s/it][A
100%|██████████| 67/67 [12:52<00:00,  7.46s/it][A                                                   
                                               [A  3%|▎         | 57/1710 [31:35<8:08:44, 17.74s/it]
100%|██████████| 67/67 [12:54<00:00,  7.46s/it][A
                                               [A{'f1_1': 0.12166859791425261, 'precision': 0.13761467889908258, 'recall': 0.10903426791277258}
{'f1': 0.08690614136732329, 'precision': 0.0982961992136304, 'recall': 0.0778816199376947}
{'eval_f1': 0.08690614136732329, 'eval_precision': 0.0982961992136304, 'eval_recall': 0.0778816199376947, 'eval_runtime': 783.7934, 'eval_samples_per_second': 0.507, 'eval_steps_per_second': 0.085, 'epoch': 1.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  3%|▎         | 58/1710 [31:56<116:26:28, 253.75s/it]  3%|▎         | 59/1710 [32:19<84:43:08, 184.73s/it]   4%|▎         | 60/1710 [32:39<61:54:11, 135.06s/it]                                                       4%|▎         | 60/1710 [32:39<61:54:11, 135.06s/it]  4%|▎         | 61/1710 [32:56<45:40:42, 99.72s/it]   4%|▎         | 62/1710 [33:23<35:38:27, 77.86s/it]  4%|▎         | 63/1710 [33:39<27:11:23, 59.43s/it]  4%|▎         | 64/1710 [33:57<21:25:28, 46.86s/it]  4%|▍         | 65/1710 [34:15<17:25:54, 38.15s/it]  4%|▍         | 66/1710 [34:32<14:36:33, 31.99s/it]  4%|▍         | 67/1710 [34:53<13:02:38, 28.58s/it]  4%|▍         | 68/1710 [35:22<13:07:06, 28.76s/it]  4%|▍         | 69/1710 [35:42<11:52:58, 26.07s/it]  4%|▍         | 70/1710 [36:00<10:48:36, 23.73s/it]                                                      4%|▍         | 70/1710 [36:00<10:48:36, 23.73s/it]  4%|▍         | 71/1710 [36:20<10:17:23, 22.60s/it]  4%|▍         | 72/1710 [36:40<9:53:42, 21.75s/it]   4%|▍         | 73/1710 [36:55<8:56:38, 19.67s/it]  4%|▍         | 74/1710 [37:19<9:34:40, 21.08s/it]  4%|▍         | 75/1710 [37:38<9:19:27, 20.53s/it]  4%|▍         | 76/1710 [37:59<9:22:33, 20.66s/it]  5%|▍         | 77/1710 [38:17<8:57:16, 19.74s/it]  5%|▍         | 78/1710 [38:35<8:42:30, 19.21s/it]  5%|▍         | 79/1710 [38:54<8:46:40, 19.37s/it]  5%|▍         | 80/1710 [39:14<8:49:53, 19.51s/it]                                                     5%|▍         | 80/1710 [39:14<8:49:53, 19.51s/it]  5%|▍         | 81/1710 [39:35<8:58:50, 19.85s/it]  5%|▍         | 82/1710 [39:53<8:47:36, 19.45s/it]  5%|▍         | 83/1710 [40:10<8:22:47, 18.54s/it]  5%|▍         | 84/1710 [40:25<7:56:21, 17.58s/it]  5%|▍         | 85/1710 [40:45<8:12:27, 18.18s/it]  5%|▌         | 86/1710 [41:00<7:50:08, 17.37s/it]  5%|▌         | 87/1710 [41:21<8:19:46, 18.48s/it]  5%|▌         | 88/1710 [41:40<8:23:52, 18.64s/it]  5%|▌         | 89/1710 [42:02<8:52:06, 19.70s/it]  5%|▌         | 90/1710 [42:21<8:38:24, 19.20s/it]                                                     5%|▌         | 90/1710 [42:21<8:38:24, 19.20s/it]  5%|▌         | 91/1710 [42:37<8:18:45, 18.48s/it]  5%|▌         | 92/1710 [42:53<7:57:13, 17.70s/it]  5%|▌         | 93/1710 [43:14<8:25:23, 18.75s/it]  5%|▌         | 94/1710 [43:32<8:11:38, 18.25s/it]  6%|▌         | 95/1710 [43:48<7:58:58, 17.79s/it]  6%|▌         | 96/1710 [44:10<8:27:29, 18.87s/it]  6%|▌         | 97/1710 [44:28<8:24:56, 18.78s/it]  6%|▌         | 98/1710 [44:44<8:04:01, 18.02s/it]  6%|▌         | 99/1710 [45:01<7:50:02, 17.51s/it]  6%|▌         | 100/1710 [45:19<7:56:21, 17.75s/it]                                                      6%|▌         | 100/1710 [45:19<7:56:21, 17.75s/it]  6%|▌         | 101/1710 [45:41<8:29:46, 19.01s/it]  6%|▌         | 102/1710 [46:02<8:46:26, 19.64s/it]  6%|▌         | 103/1710 [46:26<9:18:34, 20.86s/it]  6%|▌         | 104/1710 [46:43<8:51:43, 19.87s/it]  6%|▌         | 105/1710 [47:02<8:43:56, 19.59s/it]  6%|▌         | 106/1710 [47:23<8:55:25, 20.03s/it]  6%|▋         | 107/1710 [47:45<9:04:59, 20.40s/it]  6%|▋         | 108/1710 [48:03<8:49:08, 19.82s/it]  6%|▋         | 109/1710 [48:22<8:38:17, 19.42s/it]  6%|▋         | 110/1710 [48:41<8:38:52, 19.46s/it]                                                      6%|▋         | 110/1710 [48:41<8:38:52, 19.46s/it]  6%|▋         | 111/1710 [49:04<9:04:50, 20.44s/it]  7%|▋         | 112/1710 [49:22<8:45:20, 19.73s/it]  7%|▋         | 113/1710 [49:42<8:49:44, 19.90s/it]  7%|▋         | 114/1710 [49:59<8:25:23, 19.00s/it]{'loss': 0.8753, 'learning_rate': 8.55072463768116e-05, 'epoch': 1.05}
{'loss': 0.7523, 'learning_rate': 0.0001, 'epoch': 1.23}
{'loss': 0.6622, 'learning_rate': 9.999083759831513e-05, 'epoch': 1.4}
{'loss': 0.6329, 'learning_rate': 9.996335375124467e-05, 'epoch': 1.58}
{'loss': 0.6074, 'learning_rate': 9.991755853151051e-05, 'epoch': 1.75}
{'loss': 0.5368, 'learning_rate': 9.985346872288058e-05, 'epoch': 1.93}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:50,  5.40s/it][A
  4%|▍         | 3/67 [00:16<05:58,  5.60s/it][A
  6%|▌         | 4/67 [00:23<06:22,  6.07s/it][A
  7%|▋         | 5/67 [00:42<11:03, 10.69s/it][A
  9%|▉         | 6/67 [00:53<10:54, 10.73s/it][A
 10%|█         | 7/67 [01:03<10:35, 10.59s/it][A
 12%|█▏        | 8/67 [01:16<10:53, 11.07s/it][A
 13%|█▎        | 9/67 [02:13<24:31, 25.37s/it][A
 15%|█▍        | 10/67 [02:22<19:23, 20.41s/it][A
 16%|█▋        | 11/67 [02:33<16:21, 17.53s/it][A
 18%|█▊        | 12/67 [02:42<13:47, 15.04s/it][A
 19%|█▉        | 13/67 [02:50<11:35, 12.87s/it][A
 21%|██        | 14/67 [02:58<10:01, 11.34s/it][A
 22%|██▏       | 15/67 [03:09<09:52, 11.40s/it][A
 24%|██▍       | 16/67 [03:17<08:44, 10.29s/it][A
 25%|██▌       | 17/67 [03:27<08:21, 10.04s/it][A
 27%|██▋       | 18/67 [03:34<07:37,  9.33s/it][A
 28%|██▊       | 19/67 [03:50<09:05, 11.35s/it][A
 30%|██▉       | 20/67 [03:56<07:34,  9.68s/it][A
 31%|███▏      | 21/67 [04:06<07:29,  9.77s/it][A
 33%|███▎      | 22/67 [04:22<08:42, 11.60s/it][A
 34%|███▍      | 23/67 [04:29<07:32, 10.28s/it][A
 36%|███▌      | 24/67 [04:56<10:49, 15.10s/it][A
 37%|███▋      | 25/67 [05:23<13:07, 18.76s/it][A
 39%|███▉      | 26/67 [05:28<10:01, 14.67s/it][A
 40%|████      | 27/67 [05:37<08:39, 12.98s/it][A
 42%|████▏     | 28/67 [05:50<08:22, 12.89s/it][A
 43%|████▎     | 29/67 [05:58<07:16, 11.50s/it][A
 45%|████▍     | 30/67 [06:05<06:12, 10.06s/it][A
 46%|████▋     | 31/67 [06:12<05:35,  9.32s/it][A
 48%|████▊     | 32/67 [06:19<04:59,  8.55s/it][A
 49%|████▉     | 33/67 [06:31<05:24,  9.54s/it][A
 51%|█████     | 34/67 [06:39<05:05,  9.25s/it][A
 52%|█████▏    | 35/67 [06:48<04:53,  9.17s/it][A
 54%|█████▎    | 36/67 [07:01<05:19, 10.29s/it][A
 55%|█████▌    | 37/67 [07:06<04:17,  8.58s/it][A
 57%|█████▋    | 38/67 [07:19<04:52, 10.08s/it][A
 58%|█████▊    | 39/67 [07:26<04:11,  9.00s/it][A
 60%|█████▉    | 40/67 [07:44<05:17, 11.76s/it][A
 61%|██████    | 41/67 [07:52<04:32, 10.50s/it][A
 63%|██████▎   | 42/67 [08:03<04:27, 10.71s/it][A
 64%|██████▍   | 43/67 [08:24<05:29, 13.71s/it][A
 66%|██████▌   | 44/67 [08:35<05:01, 13.13s/it][A
 67%|██████▋   | 45/67 [08:41<03:57, 10.79s/it][A
 69%|██████▊   | 46/67 [08:49<03:31, 10.07s/it][A
 70%|███████   | 47/67 [09:01<03:32, 10.61s/it][A
 72%|███████▏  | 48/67 [09:10<03:10, 10.04s/it][A
 73%|███████▎  | 49/67 [09:22<03:14, 10.80s/it][A
 75%|███████▍  | 50/67 [09:32<02:59, 10.55s/it][A
 76%|███████▌  | 51/67 [09:45<02:59, 11.25s/it][A
 78%|███████▊  | 52/67 [09:55<02:40, 10.69s/it][A
 79%|███████▉  | 53/67 [10:10<02:49, 12.14s/it][A
 81%|████████  | 54/67 [10:27<02:55, 13.52s/it][A
 82%|████████▏ | 55/67 [10:36<02:27, 12.30s/it][A
 84%|████████▎ | 56/67 [10:43<01:57, 10.66s/it][A
 85%|████████▌ | 57/67 [10:54<01:46, 10.62s/it][A
 87%|████████▋ | 58/67 [11:04<01:35, 10.66s/it][A
 88%|████████▊ | 59/67 [11:18<01:31, 11.46s/it][A
 90%|████████▉ | 60/67 [11:27<01:16, 10.96s/it][A
 91%|█████████ | 61/67 [11:35<00:59,  9.89s/it][A
 93%|█████████▎| 62/67 [11:44<00:48,  9.78s/it][A
 94%|█████████▍| 63/67 [11:52<00:36,  9.05s/it][A
 96%|█████████▌| 64/67 [11:59<00:25,  8.46s/it][A
 97%|█████████▋| 65/67 [12:04<00:15,  7.50s/it][A
 99%|█████████▊| 66/67 [12:16<00:08,  8.83s/it][A
100%|██████████| 67/67 [12:18<00:00,  6.79s/it][A                                                    
                                               [A  7%|▋         | 114/1710 [1:02:32<8:25:23, 19.00s/it]
100%|██████████| 67/67 [12:20<00:00,  6.79s/it][A
                                               [A{'f1_1': 0.24027858386535111, 'precision': 0.2723684210526316, 'recall': 0.21495327102803738}
{'f1': 0.21125943122460822, 'precision': 0.2394736842105263, 'recall': 0.18899273104880582}
{'eval_f1': 0.21125943122460822, 'eval_precision': 0.2394736842105263, 'eval_recall': 0.18899273104880582, 'eval_runtime': 752.5423, 'eval_samples_per_second': 0.528, 'eval_steps_per_second': 0.089, 'epoch': 2.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  7%|▋         | 115/1710 [1:02:51<108:29:12, 244.86s/it]  7%|▋         | 116/1710 [1:03:07<78:03:51, 176.31s/it]   7%|▋         | 117/1710 [1:03:27<57:15:06, 129.38s/it]  7%|▋         | 118/1710 [1:03:51<43:15:38, 97.83s/it]   7%|▋         | 119/1710 [1:04:09<32:39:12, 73.89s/it]  7%|▋         | 120/1710 [1:04:36<26:18:12, 59.56s/it]                                                         7%|▋         | 120/1710 [1:04:36<26:18:12, 59.56s/it]  7%|▋         | 121/1710 [1:04:54<20:51:05, 47.24s/it]  7%|▋         | 122/1710 [1:05:11<16:52:53, 38.27s/it]  7%|▋         | 123/1710 [1:05:29<14:09:27, 32.12s/it]  7%|▋         | 124/1710 [1:05:48<12:27:03, 28.26s/it]  7%|▋         | 125/1710 [1:06:10<11:37:25, 26.40s/it]  7%|▋         | 126/1710 [1:06:31<10:49:49, 24.61s/it]  7%|▋         | 127/1710 [1:06:50<10:06:44, 23.00s/it]  7%|▋         | 128/1710 [1:07:07<9:15:58, 21.09s/it]   8%|▊         | 129/1710 [1:07:26<9:01:52, 20.56s/it]  8%|▊         | 130/1710 [1:07:50<9:27:47, 21.56s/it]                                                        8%|▊         | 130/1710 [1:07:50<9:27:47, 21.56s/it]  8%|▊         | 131/1710 [1:08:09<9:07:56, 20.82s/it]  8%|▊         | 132/1710 [1:08:26<8:36:27, 19.64s/it]  8%|▊         | 133/1710 [1:08:43<8:18:28, 18.97s/it]  8%|▊         | 134/1710 [1:09:04<8:28:55, 19.38s/it]  8%|▊         | 135/1710 [1:09:28<9:08:09, 20.88s/it]  8%|▊         | 136/1710 [1:09:52<9:31:12, 21.77s/it]  8%|▊         | 137/1710 [1:10:10<9:03:57, 20.75s/it]  8%|▊         | 138/1710 [1:10:34<9:23:26, 21.51s/it]  8%|▊         | 139/1710 [1:10:53<9:03:49, 20.77s/it]  8%|▊         | 140/1710 [1:11:12<8:54:39, 20.43s/it]                                                        8%|▊         | 140/1710 [1:11:12<8:54:39, 20.43s/it]  8%|▊         | 141/1710 [1:11:28<8:18:43, 19.07s/it]  8%|▊         | 142/1710 [1:11:47<8:18:41, 19.08s/it]  8%|▊         | 143/1710 [1:12:06<8:18:15, 19.08s/it]  8%|▊         | 144/1710 [1:12:25<8:14:26, 18.94s/it]  8%|▊         | 145/1710 [1:12:42<8:00:54, 18.44s/it]  9%|▊         | 146/1710 [1:13:02<8:11:39, 18.86s/it]  9%|▊         | 147/1710 [1:13:20<8:05:37, 18.64s/it]  9%|▊         | 148/1710 [1:13:37<7:52:29, 18.15s/it]  9%|▊         | 149/1710 [1:13:57<8:01:05, 18.49s/it]  9%|▉         | 150/1710 [1:14:21<8:46:48, 20.26s/it]                                                        9%|▉         | 150/1710 [1:14:21<8:46:48, 20.26s/it]  9%|▉         | 151/1710 [1:14:40<8:35:30, 19.84s/it]  9%|▉         | 152/1710 [1:15:00<8:37:55, 19.95s/it]  9%|▉         | 153/1710 [1:15:22<8:55:21, 20.63s/it]  9%|▉         | 154/1710 [1:15:41<8:38:25, 19.99s/it]  9%|▉         | 155/1710 [1:16:03<8:59:16, 20.81s/it]  9%|▉         | 156/1710 [1:16:22<8:44:43, 20.26s/it]  9%|▉         | 157/1710 [1:16:43<8:50:26, 20.49s/it]  9%|▉         | 158/1710 [1:17:01<8:25:39, 19.55s/it]  9%|▉         | 159/1710 [1:17:20<8:24:22, 19.51s/it]  9%|▉         | 160/1710 [1:17:40<8:25:52, 19.58s/it]                                                        9%|▉         | 160/1710 [1:17:40<8:25:52, 19.58s/it]  9%|▉         | 161/1710 [1:17:59<8:20:49, 19.40s/it]  9%|▉         | 162/1710 [1:18:21<8:43:33, 20.29s/it] 10%|▉         | 163/1710 [1:18:39<8:21:57, 19.47s/it] 10%|▉         | 164/1710 [1:18:59<8:29:52, 19.79s/it] 10%|▉         | 165/1710 [1:19:21<8:46:41, 20.45s/it] 10%|▉         | 166/1710 [1:19:41<8:40:09, 20.21s/it] 10%|▉         | 167/1710 [1:19:58<8:11:19, 19.11s/it] 10%|▉         | 168/1710 [1:20:15<8:00:53, 18.71s/it] 10%|▉         | 169/1710 [1:20:36<8:18:41, 19.42s/it] 10%|▉         | 170/1710 [1:20:55<8:08:51, 19.05s/it]                                                       10%|▉         | 170/1710 [1:20:55<8:08:51, 19.05s/it] 10%|█         | 171/1710 [1:21:10<7:37:19, 17.83s/it]{'loss': 0.4953, 'learning_rate': 9.977110781401771e-05, 'epoch': 2.11}
{'loss': 0.4778, 'learning_rate': 9.967050598987111e-05, 'epoch': 2.28}
{'loss': 0.4765, 'learning_rate': 9.955170012061367e-05, 'epoch': 2.46}
{'loss': 0.4619, 'learning_rate': 9.941473374812931e-05, 'epoch': 2.63}
{'loss': 0.4376, 'learning_rate': 9.925965707005484e-05, 'epoch': 2.81}
{'loss': 0.4447, 'learning_rate': 9.9086526921383e-05, 'epoch': 2.98}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:44,  5.30s/it][A
  4%|▍         | 3/67 [00:17<06:15,  5.86s/it][A
  6%|▌         | 4/67 [00:24<06:35,  6.28s/it][A
  7%|▋         | 5/67 [00:40<10:13,  9.89s/it][A
  9%|▉         | 6/67 [00:52<10:35, 10.42s/it][A
 10%|█         | 7/67 [01:04<10:52, 10.88s/it][A
 12%|█▏        | 8/67 [01:28<14:59, 15.25s/it][A
 13%|█▎        | 9/67 [01:37<12:34, 13.01s/it][A
 15%|█▍        | 10/67 [01:44<10:47, 11.36s/it][A
 16%|█▋        | 11/67 [01:55<10:18, 11.05s/it][A
 18%|█▊        | 12/67 [02:10<11:17, 12.32s/it][A
 19%|█▉        | 13/67 [02:18<09:52, 10.97s/it][A
 21%|██        | 14/67 [02:25<08:51, 10.02s/it][A
 22%|██▏       | 15/67 [02:39<09:29, 10.95s/it][A
 24%|██▍       | 16/67 [02:46<08:32, 10.05s/it][A
 25%|██▌       | 17/67 [03:06<10:49, 12.99s/it][A
 27%|██▋       | 18/67 [03:17<09:56, 12.18s/it][A
 28%|██▊       | 19/67 [03:25<08:56, 11.18s/it][A
 30%|██▉       | 20/67 [03:40<09:31, 12.17s/it][A
 31%|███▏      | 21/67 [03:57<10:31, 13.73s/it][A
 33%|███▎      | 22/67 [04:17<11:40, 15.56s/it][A
 34%|███▍      | 23/67 [04:23<09:20, 12.73s/it][A
 36%|███▌      | 24/67 [04:42<10:28, 14.61s/it][A
 37%|███▋      | 25/67 [05:01<11:02, 15.78s/it][A
 39%|███▉      | 26/67 [05:06<08:43, 12.76s/it][A
 40%|████      | 27/67 [05:19<08:22, 12.57s/it][A
 42%|████▏     | 28/67 [05:33<08:30, 13.09s/it][A
 43%|████▎     | 29/67 [05:41<07:18, 11.55s/it][A
 45%|████▍     | 30/67 [05:47<06:06,  9.89s/it][A
 46%|████▋     | 31/67 [05:51<04:49,  8.05s/it][A
 48%|████▊     | 32/67 [06:02<05:13,  8.95s/it][A
 49%|████▉     | 33/67 [06:23<07:14, 12.77s/it][A
 51%|█████     | 34/67 [06:33<06:27, 11.73s/it][A
 52%|█████▏    | 35/67 [06:41<05:38, 10.59s/it][A
 54%|█████▎    | 36/67 [06:52<05:33, 10.77s/it][A
 55%|█████▌    | 37/67 [06:57<04:28,  8.97s/it][A
 57%|█████▋    | 38/67 [07:10<04:56, 10.23s/it][A
 58%|█████▊    | 39/67 [07:16<04:11,  8.97s/it][A
 60%|█████▉    | 40/67 [07:29<04:40, 10.40s/it][A
 61%|██████    | 41/67 [07:41<04:40, 10.78s/it][A
 63%|██████▎   | 42/67 [07:56<04:58, 11.95s/it][A
 64%|██████▍   | 43/67 [08:20<06:15, 15.64s/it][A
 66%|██████▌   | 44/67 [08:32<05:37, 14.66s/it][A
 67%|██████▋   | 45/67 [08:38<04:19, 11.80s/it][A
 69%|██████▊   | 46/67 [08:52<04:25, 12.65s/it][A
 70%|███████   | 47/67 [09:09<04:39, 13.95s/it][A
 72%|███████▏  | 48/67 [09:23<04:24, 13.92s/it][A
 73%|███████▎  | 49/67 [09:41<04:30, 15.05s/it][A
 75%|███████▍  | 50/67 [09:55<04:10, 14.71s/it][A
 76%|███████▌  | 51/67 [10:10<03:57, 14.85s/it][A
 78%|███████▊  | 52/67 [10:22<03:31, 14.12s/it][A
 79%|███████▉  | 53/67 [10:32<03:00, 12.92s/it][A
 81%|████████  | 54/67 [10:41<02:29, 11.53s/it][A
 82%|████████▏ | 55/67 [10:52<02:18, 11.51s/it][A
 84%|████████▎ | 56/67 [11:02<01:59, 10.90s/it][A
 85%|████████▌ | 57/67 [11:22<02:17, 13.79s/it][A
 87%|████████▋ | 58/67 [11:30<01:49, 12.13s/it][A
 88%|████████▊ | 59/67 [11:45<01:43, 12.99s/it][A
 90%|████████▉ | 60/67 [11:59<01:32, 13.29s/it][A
 91%|█████████ | 61/67 [12:09<01:13, 12.18s/it][A
 93%|█████████▎| 62/67 [12:18<00:55, 11.15s/it][A
 94%|█████████▍| 63/67 [12:28<00:43, 10.83s/it][A
 96%|█████████▌| 64/67 [12:38<00:31, 10.66s/it][A
 97%|█████████▋| 65/67 [12:45<00:19,  9.52s/it][A
 99%|█████████▊| 66/67 [13:01<00:11, 11.49s/it][A
100%|██████████| 67/67 [13:03<00:00,  8.63s/it][A                                                      
                                               [A 10%|█         | 171/1710 [1:34:27<7:37:19, 17.83s/it]
100%|██████████| 67/67 [13:04<00:00,  8.63s/it][A
                                               [A{'f1_1': 0.3090221501890869, 'precision': 0.32207207207207206, 'recall': 0.29698857736240913}
{'f1': 0.29173419773095627, 'precision': 0.30405405405405406, 'recall': 0.2803738317757009}
{'eval_f1': 0.29173419773095627, 'eval_precision': 0.30405405405405406, 'eval_recall': 0.2803738317757009, 'eval_runtime': 797.1599, 'eval_samples_per_second': 0.498, 'eval_steps_per_second': 0.084, 'epoch': 3.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 10%|█         | 172/1710 [1:34:50<110:25:54, 258.49s/it] 10%|█         | 173/1710 [1:35:07<79:26:50, 186.08s/it]  10%|█         | 174/1710 [1:35:26<57:59:35, 135.92s/it] 10%|█         | 175/1710 [1:35:45<42:59:12, 100.82s/it] 10%|█         | 176/1710 [1:36:02<32:16:20, 75.74s/it]  10%|█         | 177/1710 [1:36:22<25:12:01, 59.18s/it] 10%|█         | 178/1710 [1:36:40<19:54:22, 46.78s/it] 10%|█         | 179/1710 [1:36:57<16:03:51, 37.77s/it] 11%|█         | 180/1710 [1:37:13<13:14:59, 31.18s/it]                                                        11%|█         | 180/1710 [1:37:13<13:14:59, 31.18s/it] 11%|█         | 181/1710 [1:37:39<12:36:32, 29.69s/it] 11%|█         | 182/1710 [1:37:57<11:09:44, 26.30s/it] 11%|█         | 183/1710 [1:38:15<10:06:17, 23.82s/it] 11%|█         | 184/1710 [1:38:34<9:24:48, 22.21s/it]  11%|█         | 185/1710 [1:39:03<10:14:42, 24.19s/it] 11%|█         | 186/1710 [1:39:19<9:18:48, 22.00s/it]  11%|█         | 187/1710 [1:39:38<8:54:53, 21.07s/it] 11%|█         | 188/1710 [1:39:58<8:42:21, 20.59s/it] 11%|█         | 189/1710 [1:40:19<8:46:30, 20.77s/it] 11%|█         | 190/1710 [1:40:39<8:40:36, 20.55s/it]                                                       11%|█         | 190/1710 [1:40:39<8:40:36, 20.55s/it] 11%|█         | 191/1710 [1:41:01<8:52:23, 21.03s/it] 11%|█         | 192/1710 [1:41:22<8:52:05, 21.03s/it] 11%|█▏        | 193/1710 [1:41:41<8:30:47, 20.20s/it] 11%|█▏        | 194/1710 [1:41:58<8:12:42, 19.50s/it] 11%|█▏        | 195/1710 [1:42:21<8:35:29, 20.42s/it] 11%|█▏        | 196/1710 [1:42:37<8:04:01, 19.18s/it] 12%|█▏        | 197/1710 [1:42:59<8:19:46, 19.82s/it] 12%|█▏        | 198/1710 [1:43:16<7:58:49, 19.00s/it] 12%|█▏        | 199/1710 [1:43:36<8:08:01, 19.38s/it] 12%|█▏        | 200/1710 [1:43:54<8:00:57, 19.11s/it]                                                       12%|█▏        | 200/1710 [1:43:54<8:00:57, 19.11s/it] 12%|█▏        | 201/1710 [1:44:20<8:47:28, 20.97s/it] 12%|█▏        | 202/1710 [1:44:42<9:00:11, 21.49s/it] 12%|█▏        | 203/1710 [1:45:01<8:40:15, 20.71s/it] 12%|█▏        | 204/1710 [1:45:24<8:51:07, 21.16s/it] 12%|█▏        | 205/1710 [1:45:43<8:39:20, 20.70s/it] 12%|█▏        | 206/1710 [1:46:01<8:17:27, 19.85s/it] 12%|█▏        | 207/1710 [1:46:19<8:06:18, 19.41s/it] 12%|█▏        | 208/1710 [1:46:36<7:46:39, 18.64s/it] 12%|█▏        | 209/1710 [1:46:55<7:46:37, 18.65s/it] 12%|█▏        | 210/1710 [1:47:13<7:43:49, 18.55s/it]                                                       12%|█▏        | 210/1710 [1:47:13<7:43:49, 18.55s/it] 12%|█▏        | 211/1710 [1:47:31<7:36:33, 18.27s/it] 12%|█▏        | 212/1710 [1:47:54<8:11:10, 19.67s/it] 12%|█▏        | 213/1710 [1:48:12<8:01:35, 19.30s/it] 13%|█▎        | 214/1710 [1:48:30<7:51:10, 18.90s/it] 13%|█▎        | 215/1710 [1:48:59<9:01:28, 21.73s/it] 13%|█▎        | 216/1710 [1:49:15<8:19:39, 20.07s/it] 13%|█▎        | 217/1710 [1:49:35<8:22:59, 20.21s/it] 13%|█▎        | 218/1710 [1:49:57<8:32:19, 20.60s/it] 13%|█▎        | 219/1710 [1:50:14<8:09:45, 19.71s/it] 13%|█▎        | 220/1710 [1:50:34<8:07:39, 19.64s/it]                                                       13%|█▎        | 220/1710 [1:50:34<8:07:39, 19.64s/it] 13%|█▎        | 221/1710 [1:50:50<7:42:06, 18.62s/it] 13%|█▎        | 222/1710 [1:51:09<7:40:27, 18.57s/it] 13%|█▎        | 223/1710 [1:51:27<7:42:46, 18.67s/it] 13%|█▎        | 224/1710 [1:51:46<7:41:13, 18.62s/it] 13%|█▎        | 225/1710 [1:52:07<7:59:06, 19.36s/it] 13%|█▎        | 226/1710 [1:52:28<8:08:26, 19.75s/it] 13%|█▎        | 227/1710 [1:52:46<8:00:34, 19.44s/it] 13%|█▎        | 228/1710 [1:53:04<7:42:27, 18.72s/it]{'loss': 0.4227, 'learning_rate': 9.889540675363236e-05, 'epoch': 3.16}
{'loss': 0.3883, 'learning_rate': 9.868636661159283e-05, 'epoch': 3.33}
{'loss': 0.3427, 'learning_rate': 9.84594831076544e-05, 'epoch': 3.51}
{'loss': 0.3758, 'learning_rate': 9.8214839393729e-05, 'epoch': 3.68}
{'loss': 0.3672, 'learning_rate': 9.795252513077572e-05, 'epoch': 3.86}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:13<07:32,  6.96s/it][A
  4%|▍         | 3/67 [00:22<08:03,  7.55s/it][A
  6%|▌         | 4/67 [00:31<08:32,  8.14s/it][A
  7%|▋         | 5/67 [00:56<14:38, 14.17s/it][A
  9%|▉         | 6/67 [01:15<15:51, 15.59s/it][A
 10%|█         | 7/67 [01:33<16:16, 16.27s/it][A
 12%|█▏        | 8/67 [01:57<18:30, 18.82s/it][A
 13%|█▎        | 9/67 [02:07<15:37, 16.17s/it][A
 15%|█▍        | 10/67 [02:16<13:18, 14.01s/it][A
 16%|█▋        | 11/67 [02:36<14:37, 15.66s/it][A
 18%|█▊        | 12/67 [02:47<13:10, 14.37s/it][A
 19%|█▉        | 13/67 [02:53<10:37, 11.80s/it][A
 21%|██        | 14/67 [03:15<13:12, 14.95s/it][A
 22%|██▏       | 15/67 [03:29<12:31, 14.44s/it][A
 24%|██▍       | 16/67 [03:37<10:43, 12.62s/it][A
 25%|██▌       | 17/67 [03:59<12:52, 15.46s/it][A
 27%|██▋       | 18/67 [04:10<11:35, 14.19s/it][A
 28%|██▊       | 19/67 [04:23<11:02, 13.79s/it][A
 30%|██▉       | 20/67 [04:36<10:35, 13.51s/it][A
 31%|███▏      | 21/67 [04:57<12:00, 15.67s/it][A
 33%|███▎      | 22/67 [05:14<12:06, 16.15s/it][A
 34%|███▍      | 23/67 [05:26<10:56, 14.92s/it][A
 36%|███▌      | 24/67 [06:24<20:03, 28.00s/it][A
 37%|███▋      | 25/67 [06:47<18:30, 26.45s/it][A
 39%|███▉      | 26/67 [06:56<14:21, 21.02s/it][A
 40%|████      | 27/67 [07:09<12:31, 18.80s/it][A
 42%|████▏     | 28/67 [07:27<12:03, 18.54s/it][A
 43%|████▎     | 29/67 [07:36<09:56, 15.69s/it][A
 45%|████▍     | 30/67 [07:47<08:44, 14.17s/it][A
 46%|████▋     | 31/67 [07:56<07:34, 12.62s/it][A
 48%|████▊     | 32/67 [08:05<06:44, 11.56s/it][A
 49%|████▉     | 33/67 [08:23<07:38, 13.47s/it][A
 51%|█████     | 34/67 [08:35<07:06, 12.93s/it][A
 52%|█████▏    | 35/67 [08:45<06:26, 12.09s/it][A
 54%|█████▎    | 36/67 [08:54<05:49, 11.29s/it][A
 55%|█████▌    | 37/67 [09:00<04:47,  9.59s/it][A
 57%|█████▋    | 38/67 [09:12<05:04, 10.49s/it][A
 58%|█████▊    | 39/67 [09:20<04:29,  9.64s/it][A
 60%|█████▉    | 40/67 [09:36<05:10, 11.49s/it][A
 61%|██████    | 41/67 [10:09<07:46, 17.94s/it][A
 63%|██████▎   | 42/67 [10:24<07:09, 17.18s/it][A
 64%|██████▍   | 43/67 [10:41<06:51, 17.15s/it][A
 66%|██████▌   | 44/67 [10:55<06:13, 16.23s/it][A
 67%|██████▋   | 45/67 [11:00<04:43, 12.90s/it][A
 69%|██████▊   | 46/67 [11:09<04:01, 11.48s/it][A
 70%|███████   | 47/67 [11:28<04:38, 13.95s/it][A
 72%|███████▏  | 48/67 [11:39<04:04, 12.88s/it][A
 73%|███████▎  | 49/67 [12:01<04:42, 15.68s/it][A
 75%|███████▍  | 50/67 [12:13<04:10, 14.71s/it][A
 76%|███████▌  | 51/67 [12:29<03:59, 14.99s/it][A
 78%|███████▊  | 52/67 [12:42<03:36, 14.43s/it][A
 79%|███████▉  | 53/67 [12:55<03:14, 13.88s/it][A
 81%|████████  | 54/67 [13:06<02:51, 13.17s/it][A
 82%|████████▏ | 55/67 [13:22<02:45, 13.82s/it][A
 84%|████████▎ | 56/67 [13:28<02:08, 11.66s/it][A
 85%|████████▌ | 57/67 [14:33<04:35, 27.52s/it][A
 87%|████████▋ | 58/67 [14:42<03:17, 21.99s/it][A
 88%|████████▊ | 59/67 [15:43<04:28, 33.61s/it][A
 90%|████████▉ | 60/67 [16:03<03:27, 29.65s/it][A
 91%|█████████ | 61/67 [16:14<02:23, 23.91s/it][A
 93%|█████████▎| 62/67 [16:23<01:38, 19.72s/it][A
 94%|█████████▍| 63/67 [16:36<01:09, 17.46s/it][A
 96%|█████████▌| 64/67 [16:48<00:48, 16.04s/it][A
 97%|█████████▋| 65/67 [16:57<00:27, 13.82s/it][A
 99%|█████████▊| 66/67 [17:14<00:14, 14.90s/it][A
100%|██████████| 67/67 [17:16<00:00, 11.03s/it][A                                                      
                                               [A 13%|█▎        | 228/1710 [2:11:26<7:42:27, 18.72s/it]
100%|██████████| 67/67 [17:18<00:00, 11.03s/it][A
                                               [A{'f1_1': 0.3931372549019608, 'precision': 0.372330547818013, 'recall': 0.4164070612668744}
{'f1': 0.37745098039215685, 'precision': 0.3574744661095636, 'recall': 0.39979231568016615}
{'eval_f1': 0.37745098039215685, 'eval_precision': 0.3574744661095636, 'eval_recall': 0.39979231568016615, 'eval_runtime': 1102.1079, 'eval_samples_per_second': 0.36, 'eval_steps_per_second': 0.061, 'epoch': 4.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 13%|█▎        | 229/1710 [2:11:47<143:59:19, 350.01s/it] 13%|█▎        | 230/1710 [2:12:03<102:44:17, 249.90s/it]                                                          13%|█▎        | 230/1710 [2:12:03<102:44:17, 249.90s/it] 14%|█▎        | 231/1710 [2:12:24<74:26:42, 181.20s/it]  14%|█▎        | 232/1710 [2:12:46<54:51:33, 133.62s/it] 14%|█▎        | 233/1710 [2:13:04<40:35:56, 98.96s/it]  14%|█▎        | 234/1710 [2:13:25<30:59:32, 75.59s/it] 14%|█▎        | 235/1710 [2:13:44<24:00:18, 58.59s/it] 14%|█▍        | 236/1710 [2:14:05<19:16:31, 47.08s/it] 14%|█▍        | 237/1710 [2:14:25<15:57:15, 38.99s/it] 14%|█▍        | 238/1710 [2:14:44<13:31:48, 33.09s/it] 14%|█▍        | 239/1710 [2:15:03<11:49:46, 28.95s/it] 14%|█▍        | 240/1710 [2:15:27<11:11:58, 27.43s/it]                                                        14%|█▍        | 240/1710 [2:15:27<11:11:58, 27.43s/it] 14%|█▍        | 241/1710 [2:15:43<9:49:18, 24.07s/it]  14%|█▍        | 242/1710 [2:16:02<9:05:18, 22.29s/it] 14%|█▍        | 243/1710 [2:16:19<8:31:05, 20.90s/it] 14%|█▍        | 244/1710 [2:16:38<8:12:14, 20.15s/it] 14%|█▍        | 245/1710 [2:16:58<8:10:34, 20.09s/it] 14%|█▍        | 246/1710 [2:17:18<8:15:53, 20.32s/it] 14%|█▍        | 247/1710 [2:17:37<8:04:17, 19.86s/it] 15%|█▍        | 248/1710 [2:17:59<8:16:36, 20.38s/it] 15%|█▍        | 249/1710 [2:18:20<8:19:04, 20.50s/it] 15%|█▍        | 250/1710 [2:18:38<8:02:14, 19.82s/it]                                                       15%|█▍        | 250/1710 [2:18:38<8:02:14, 19.82s/it] 15%|█▍        | 251/1710 [2:18:59<8:12:09, 20.24s/it] 15%|█▍        | 252/1710 [2:19:20<8:18:42, 20.52s/it] 15%|█▍        | 253/1710 [2:19:38<8:01:23, 19.82s/it] 15%|█▍        | 254/1710 [2:20:02<8:26:40, 20.88s/it] 15%|█▍        | 255/1710 [2:20:21<8:12:22, 20.30s/it] 15%|█▍        | 256/1710 [2:20:39<7:53:43, 19.55s/it] 15%|█▌        | 257/1710 [2:21:02<8:20:09, 20.65s/it] 15%|█▌        | 258/1710 [2:21:25<8:39:37, 21.47s/it] 15%|█▌        | 259/1710 [2:21:41<7:57:24, 19.74s/it] 15%|█▌        | 260/1710 [2:21:58<7:40:36, 19.06s/it]                                                       15%|█▌        | 260/1710 [2:21:58<7:40:36, 19.06s/it] 15%|█▌        | 261/1710 [2:22:18<7:42:55, 19.17s/it] 15%|█▌        | 262/1710 [2:22:39<7:55:07, 19.69s/it] 15%|█▌        | 263/1710 [2:23:03<8:25:27, 20.96s/it] 15%|█▌        | 264/1710 [2:23:23<8:20:43, 20.78s/it] 15%|█▌        | 265/1710 [2:23:42<8:06:37, 20.21s/it] 16%|█▌        | 266/1710 [2:23:59<7:41:02, 19.16s/it] 16%|█▌        | 267/1710 [2:24:21<8:07:33, 20.27s/it] 16%|█▌        | 268/1710 [2:24:40<7:52:25, 19.66s/it] 16%|█▌        | 269/1710 [2:25:01<8:03:32, 20.13s/it] 16%|█▌        | 270/1710 [2:25:21<8:00:51, 20.04s/it]                                                       16%|█▌        | 270/1710 [2:25:21<8:00:51, 20.04s/it] 16%|█▌        | 271/1710 [2:25:39<7:49:35, 19.58s/it] 16%|█▌        | 272/1710 [2:25:56<7:27:25, 18.67s/it] 16%|█▌        | 273/1710 [2:26:14<7:27:00, 18.66s/it] 16%|█▌        | 274/1710 [2:26:32<7:18:15, 18.31s/it] 16%|█▌        | 275/1710 [2:26:53<7:41:37, 19.30s/it] 16%|█▌        | 276/1710 [2:27:12<7:35:34, 19.06s/it] 16%|█▌        | 277/1710 [2:27:29<7:22:31, 18.53s/it] 16%|█▋        | 278/1710 [2:27:47<7:17:18, 18.32s/it] 16%|█▋        | 279/1710 [2:28:10<7:48:18, 19.64s/it] 16%|█▋        | 280/1710 [2:28:29<7:44:52, 19.51s/it]                                                       16%|█▋        | 280/1710 [2:28:29<7:44:52, 19.51s/it] 16%|█▋        | 281/1710 [2:28:45<7:22:56, 18.60s/it] 16%|█▋        | 282/1710 [2:29:03<7:11:49, 18.14s/it] 17%|█▋        | 283/1710 [2:29:28<8:01:14, 20.23s/it] 17%|█▋        | 284/1710 [2:29:45<7:43:28, 19.50s/it] 17%|█▋        | 285/1710 [2:30:00<7:09:12, 18.07s/it]{'loss': 0.3151, 'learning_rate': 9.767263645594034e-05, 'epoch': 4.04}
{'loss': 0.2783, 'learning_rate': 9.73752759473215e-05, 'epoch': 4.21}
{'loss': 0.325, 'learning_rate': 9.706055258637619e-05, 'epoch': 4.39}
{'loss': 0.2889, 'learning_rate': 9.672858171797853e-05, 'epoch': 4.56}
{'loss': 0.3189, 'learning_rate': 9.637948500814628e-05, 'epoch': 4.74}
{'loss': 0.3006, 'learning_rate': 9.601339039945074e-05, 'epoch': 4.91}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:11<06:22,  5.88s/it][A
  4%|▍         | 3/67 [00:22<08:28,  7.94s/it][A
  6%|▌         | 4/67 [00:32<08:56,  8.51s/it][A
  7%|▋         | 5/67 [00:50<12:23, 12.00s/it][A
  9%|▉         | 6/67 [01:05<13:15, 13.04s/it][A
 10%|█         | 7/67 [01:21<14:01, 14.02s/it][A
 12%|█▏        | 8/67 [01:44<16:21, 16.63s/it][A
 13%|█▎        | 9/67 [02:02<16:31, 17.09s/it][A
 15%|█▍        | 10/67 [02:11<13:54, 14.64s/it][A
 16%|█▋        | 11/67 [02:31<15:09, 16.23s/it][A
 18%|█▊        | 12/67 [02:42<13:22, 14.58s/it][A
 19%|█▉        | 13/67 [02:51<11:36, 12.91s/it][A
 21%|██        | 14/67 [03:15<14:31, 16.44s/it][A
 22%|██▏       | 15/67 [03:28<13:25, 15.48s/it][A
 24%|██▍       | 16/67 [03:39<11:51, 13.95s/it][A
 25%|██▌       | 17/67 [03:47<10:17, 12.36s/it][A
 27%|██▋       | 18/67 [04:04<11:05, 13.59s/it][A
 28%|██▊       | 19/67 [04:24<12:26, 15.55s/it][A
 30%|██▉       | 20/67 [04:41<12:24, 15.84s/it][A
 31%|███▏      | 21/67 [05:15<16:24, 21.40s/it][A
 33%|███▎      | 22/67 [05:38<16:31, 22.02s/it][A
 34%|███▍      | 23/67 [05:54<14:41, 20.04s/it][A
 36%|███▌      | 24/67 [07:05<25:25, 35.47s/it][A
 37%|███▋      | 25/67 [07:32<23:05, 32.98s/it][A
 39%|███▉      | 26/67 [07:42<17:48, 26.06s/it][A
 40%|████      | 27/67 [08:04<16:28, 24.71s/it][A
 42%|████▏     | 28/67 [08:28<15:55, 24.50s/it][A
 43%|████▎     | 29/67 [08:36<12:19, 19.46s/it][A
 45%|████▍     | 30/67 [08:47<10:31, 17.07s/it][A
 46%|████▋     | 31/67 [08:54<08:25, 14.06s/it][A
 48%|████▊     | 32/67 [09:03<07:21, 12.60s/it][A
 49%|████▉     | 33/67 [09:21<08:01, 14.16s/it][A
 51%|█████     | 34/67 [09:32<07:18, 13.28s/it][A
 52%|█████▏    | 35/67 [09:45<06:55, 13.00s/it][A
 54%|█████▎    | 36/67 [09:56<06:23, 12.36s/it][A
 55%|█████▌    | 37/67 [10:02<05:18, 10.62s/it][A
 57%|█████▋    | 38/67 [10:19<05:58, 12.38s/it][A
 58%|█████▊    | 39/67 [10:28<05:24, 11.59s/it][A
 60%|█████▉    | 40/67 [10:39<05:06, 11.34s/it][A
 61%|██████    | 41/67 [10:58<05:56, 13.70s/it][A
 63%|██████▎   | 42/67 [11:18<06:24, 15.37s/it][A
 64%|██████▍   | 43/67 [11:32<06:00, 15.03s/it][A
 66%|██████▌   | 44/67 [11:44<05:27, 14.22s/it][A
 67%|██████▋   | 45/67 [11:49<04:11, 11.45s/it][A
 69%|██████▊   | 46/67 [12:01<04:02, 11.53s/it][A
 70%|███████   | 47/67 [12:14<03:59, 11.98s/it][A
 72%|███████▏  | 48/67 [12:29<04:05, 12.94s/it][A
 73%|███████▎  | 49/67 [12:54<04:57, 16.52s/it][A
 75%|███████▍  | 50/67 [13:06<04:15, 15.04s/it][A
 76%|███████▌  | 51/67 [13:30<04:46, 17.88s/it][A
 78%|███████▊  | 52/67 [13:39<03:49, 15.27s/it][A
 79%|███████▉  | 53/67 [13:51<03:17, 14.13s/it][A
 81%|████████  | 54/67 [13:59<02:40, 12.35s/it][A
 82%|████████▏ | 55/67 [14:22<03:06, 15.56s/it][A
 84%|████████▎ | 56/67 [14:42<03:04, 16.77s/it][A
 85%|████████▌ | 57/67 [15:05<03:08, 18.84s/it][A
 87%|████████▋ | 58/67 [15:45<03:45, 25.11s/it][A
 88%|████████▊ | 59/67 [16:06<03:12, 24.02s/it][A
 90%|████████▉ | 60/67 [16:26<02:39, 22.75s/it][A
 91%|█████████ | 61/67 [16:36<01:53, 18.89s/it][A
 93%|█████████▎| 62/67 [16:43<01:16, 15.32s/it][A
 94%|█████████▍| 63/67 [16:59<01:01, 15.45s/it][A
 96%|█████████▌| 64/67 [17:10<00:42, 14.17s/it][A
 97%|█████████▋| 65/67 [17:19<00:25, 12.53s/it][A
 99%|█████████▊| 66/67 [17:35<00:13, 13.68s/it][A
100%|██████████| 67/67 [17:39<00:00, 10.83s/it][A                                                      
                                               [A 17%|█▋        | 285/1710 [2:48:02<7:09:12, 18.07s/it]
100%|██████████| 67/67 [17:41<00:00, 10.83s/it][A
                                               [A{'f1_1': 0.37494112105511074, 'precision': 0.3431034482758621, 'recall': 0.4132917964693666}
{'f1': 0.35421573245407445, 'precision': 0.32413793103448274, 'recall': 0.3904465212876428}
{'eval_f1': 0.35421573245407445, 'eval_precision': 0.32413793103448274, 'eval_recall': 0.3904465212876428, 'eval_runtime': 1081.5602, 'eval_samples_per_second': 0.367, 'eval_steps_per_second': 0.062, 'epoch': 5.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 17%|█▋        | 286/1710 [2:48:20<135:30:25, 342.57s/it] 17%|█▋        | 287/1710 [2:48:37<96:48:42, 244.92s/it]  17%|█▋        | 288/1710 [2:48:53<69:39:23, 176.35s/it] 17%|█▋        | 289/1710 [2:49:10<50:43:55, 128.53s/it] 17%|█▋        | 290/1710 [2:49:31<37:53:27, 96.06s/it]                                                         17%|█▋        | 290/1710 [2:49:31<37:53:27, 96.06s/it] 17%|█▋        | 291/1710 [2:49:53<29:08:42, 73.94s/it] 17%|█▋        | 292/1710 [2:50:09<22:15:00, 56.49s/it] 17%|█▋        | 293/1710 [2:50:30<18:02:59, 45.86s/it] 17%|█▋        | 294/1710 [2:50:49<14:51:27, 37.77s/it] 17%|█▋        | 295/1710 [2:51:13<13:14:00, 33.67s/it] 17%|█▋        | 296/1710 [2:51:37<12:04:13, 30.73s/it] 17%|█▋        | 297/1710 [2:51:56<10:40:07, 27.18s/it] 17%|█▋        | 298/1710 [2:52:13<9:29:36, 24.20s/it]  17%|█▋        | 299/1710 [2:52:31<8:44:40, 22.31s/it] 18%|█▊        | 300/1710 [2:52:48<8:06:58, 20.72s/it]                                                       18%|█▊        | 300/1710 [2:52:48<8:06:58, 20.72s/it] 18%|█▊        | 301/1710 [2:53:08<8:05:27, 20.67s/it] 18%|█▊        | 302/1710 [2:53:35<8:49:24, 22.56s/it] 18%|█▊        | 303/1710 [2:53:53<8:18:29, 21.26s/it] 18%|█▊        | 304/1710 [2:54:16<8:28:16, 21.69s/it] 18%|█▊        | 305/1710 [2:54:33<7:57:18, 20.38s/it] 18%|█▊        | 306/1710 [2:54:52<7:41:50, 19.74s/it] 18%|█▊        | 307/1710 [2:55:10<7:34:42, 19.45s/it] 18%|█▊        | 308/1710 [2:55:28<7:20:34, 18.85s/it] 18%|█▊        | 309/1710 [2:55:46<7:15:13, 18.64s/it] 18%|█▊        | 310/1710 [2:56:05<7:17:18, 18.74s/it]                                                       18%|█▊        | 310/1710 [2:56:05<7:17:18, 18.74s/it] 18%|█▊        | 311/1710 [2:56:23<7:12:55, 18.57s/it] 18%|█▊        | 312/1710 [2:56:41<7:10:21, 18.47s/it] 18%|█▊        | 313/1710 [2:56:59<7:02:15, 18.14s/it] 18%|█▊        | 314/1710 [2:57:16<6:55:36, 17.86s/it] 18%|█▊        | 315/1710 [2:57:34<6:57:27, 17.96s/it] 18%|█▊        | 316/1710 [2:57:55<7:13:58, 18.68s/it] 19%|█▊        | 317/1710 [2:58:15<7:23:35, 19.11s/it] 19%|█▊        | 318/1710 [2:58:32<7:11:34, 18.60s/it] 19%|█▊        | 319/1710 [2:58:57<7:52:36, 20.39s/it] 19%|█▊        | 320/1710 [2:59:16<7:48:06, 20.21s/it]                                                       19%|█▊        | 320/1710 [2:59:16<7:48:06, 20.21s/it] 19%|█▉        | 321/1710 [2:59:37<7:48:46, 20.25s/it] 19%|█▉        | 322/1710 [2:59:56<7:39:20, 19.86s/it] 19%|█▉        | 323/1710 [3:00:12<7:12:11, 18.70s/it] 19%|█▉        | 324/1710 [3:00:32<7:25:31, 19.29s/it] 19%|█▉        | 325/1710 [3:00:53<7:31:07, 19.54s/it] 19%|█▉        | 326/1710 [3:01:09<7:12:41, 18.76s/it] 19%|█▉        | 327/1710 [3:01:28<7:13:59, 18.83s/it] 19%|█▉        | 328/1710 [3:01:51<7:42:00, 20.06s/it] 19%|█▉        | 329/1710 [3:02:14<7:59:18, 20.82s/it] 19%|█▉        | 330/1710 [3:02:33<7:43:50, 20.17s/it]                                                       19%|█▉        | 330/1710 [3:02:33<7:43:50, 20.17s/it] 19%|█▉        | 331/1710 [3:02:53<7:41:53, 20.10s/it] 19%|█▉        | 332/1710 [3:03:13<7:45:19, 20.26s/it] 19%|█▉        | 333/1710 [3:03:32<7:37:55, 19.95s/it] 20%|█▉        | 334/1710 [3:03:50<7:20:41, 19.22s/it] 20%|█▉        | 335/1710 [3:04:11<7:32:58, 19.77s/it] 20%|█▉        | 336/1710 [3:04:33<7:46:52, 20.39s/it] 20%|█▉        | 337/1710 [3:04:52<7:37:14, 19.98s/it] 20%|█▉        | 338/1710 [3:05:11<7:32:42, 19.80s/it] 20%|█▉        | 339/1710 [3:05:28<7:11:51, 18.90s/it] 20%|█▉        | 340/1710 [3:05:45<6:58:02, 18.31s/it]                                                       20%|█▉        | 340/1710 [3:05:45<6:58:02, 18.31s/it] 20%|█▉        | 341/1710 [3:06:06<7:15:30, 19.09s/it] 20%|██        | 342/1710 [3:06:21<6:47:55, 17.89s/it]{'loss': 0.2743, 'learning_rate': 9.563043206412628e-05, 'epoch': 5.09}
{'loss': 0.2523, 'learning_rate': 9.523075035489676e-05, 'epoch': 5.26}
{'loss': 0.2381, 'learning_rate': 9.481449175353685e-05, 'epoch': 5.44}
{'loss': 0.222, 'learning_rate': 9.438180881718695e-05, 'epoch': 5.61}
{'loss': 0.2506, 'learning_rate': 9.393286012244166e-05, 'epoch': 5.79}
{'loss': 0.264, 'learning_rate': 9.346781020723209e-05, 'epoch': 5.96}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:11<06:20,  5.85s/it][A
  4%|▍         | 3/67 [00:18<06:50,  6.42s/it][A
  6%|▌         | 4/67 [00:26<07:09,  6.82s/it][A
  7%|▋         | 5/67 [00:49<13:02, 12.61s/it][A
  9%|▉         | 6/67 [01:05<13:45, 13.53s/it][A
 10%|█         | 7/67 [01:19<13:37, 13.63s/it][A
 12%|█▏        | 8/67 [01:43<16:50, 17.12s/it][A
 13%|█▎        | 9/67 [02:02<16:56, 17.53s/it][A
 15%|█▍        | 10/67 [02:11<14:12, 14.95s/it][A
 16%|█▋        | 11/67 [02:35<16:37, 17.82s/it][A
 18%|█▊        | 12/67 [02:44<13:50, 15.10s/it][A
 19%|█▉        | 13/67 [02:53<11:58, 13.30s/it][A
 21%|██        | 14/67 [03:01<10:17, 11.66s/it][A
 22%|██▏       | 15/67 [03:17<11:09, 12.88s/it][A
 24%|██▍       | 16/67 [03:25<09:40, 11.38s/it][A
 25%|██▌       | 17/67 [03:47<12:09, 14.58s/it][A
 27%|██▋       | 18/67 [03:58<11:05, 13.59s/it][A
 28%|██▊       | 19/67 [04:15<11:34, 14.47s/it][A
 30%|██▉       | 20/67 [04:27<10:57, 14.00s/it][A
 31%|███▏      | 21/67 [05:00<14:58, 19.54s/it][A
 33%|███▎      | 22/67 [05:16<13:52, 18.51s/it][A
 34%|███▍      | 23/67 [05:24<11:18, 15.41s/it][A
 36%|███▌      | 24/67 [05:58<14:54, 20.81s/it][A
 37%|███▋      | 25/67 [06:14<13:43, 19.62s/it][A
 39%|███▉      | 26/67 [06:23<11:05, 16.24s/it][A
 40%|████      | 27/67 [06:37<10:29, 15.75s/it][A
 42%|████▏     | 28/67 [06:57<11:01, 16.96s/it][A
 43%|████▎     | 29/67 [07:09<09:50, 15.53s/it][A
 45%|████▍     | 30/67 [07:17<08:11, 13.27s/it][A
 46%|████▋     | 31/67 [07:23<06:37, 11.04s/it][A
 48%|████▊     | 32/67 [07:36<06:42, 11.50s/it][A
 49%|████▉     | 33/67 [07:48<06:38, 11.73s/it][A
 51%|█████     | 34/67 [07:59<06:15, 11.38s/it][A
 52%|█████▏    | 35/67 [08:11<06:11, 11.62s/it][A
 54%|█████▎    | 36/67 [08:20<05:33, 10.75s/it][A
 55%|█████▌    | 37/67 [08:25<04:31,  9.07s/it][A
 57%|█████▋    | 38/67 [08:44<05:53, 12.19s/it][A
 58%|█████▊    | 39/67 [08:53<05:12, 11.16s/it][A
 60%|█████▉    | 40/67 [09:04<05:04, 11.28s/it][A
 61%|██████    | 41/67 [09:17<05:02, 11.65s/it][A
 63%|██████▎   | 42/67 [09:31<05:12, 12.48s/it][A
 64%|██████▍   | 43/67 [09:51<05:48, 14.50s/it][A
 66%|██████▌   | 44/67 [10:03<05:18, 13.87s/it][A
 67%|██████▋   | 45/67 [10:08<04:06, 11.22s/it][A
 69%|██████▊   | 46/67 [10:16<03:35, 10.27s/it][A
 70%|███████   | 47/67 [10:36<04:20, 13.03s/it][A
 72%|███████▏  | 48/67 [10:50<04:16, 13.49s/it][A
 73%|███████▎  | 49/67 [11:09<04:31, 15.09s/it][A
 75%|███████▍  | 50/67 [11:23<04:10, 14.75s/it][A
 76%|███████▌  | 51/67 [11:41<04:09, 15.61s/it][A
 78%|███████▊  | 52/67 [11:53<03:41, 14.79s/it][A
 79%|███████▉  | 53/67 [12:10<03:35, 15.39s/it][A
 81%|████████  | 54/67 [12:18<02:49, 13.04s/it][A
 82%|████████▏ | 55/67 [12:33<02:42, 13.57s/it][A
 84%|████████▎ | 56/67 [12:52<02:49, 15.37s/it][A
 85%|████████▌ | 57/67 [13:22<03:16, 19.62s/it][A
 87%|████████▋ | 58/67 [13:33<02:34, 17.21s/it][A
 88%|████████▊ | 59/67 [13:54<02:27, 18.42s/it][A
 90%|████████▉ | 60/67 [14:14<02:10, 18.71s/it][A
 91%|█████████ | 61/67 [14:27<01:42, 17.09s/it][A
 93%|█████████▎| 62/67 [14:35<01:12, 14.41s/it][A
 94%|█████████▍| 63/67 [14:44<00:50, 12.65s/it][A
 96%|█████████▌| 64/67 [14:53<00:34, 11.66s/it][A
 97%|█████████▋| 65/67 [15:00<00:20, 10.13s/it][A
 99%|█████████▊| 66/67 [15:17<00:12, 12.10s/it][A
100%|██████████| 67/67 [15:18<00:00,  9.01s/it][A                                                      
                                               [A 20%|██        | 342/1710 [3:22:41<6:47:55, 17.89s/it]
100%|██████████| 67/67 [15:20<00:00,  9.01s/it][A
                                               [A{'f1_1': 0.382262996941896, 'precision': 0.37537537537537535, 'recall': 0.3894080996884735}
{'f1': 0.35881753312945974, 'precision': 0.35235235235235235, 'recall': 0.3655244029075805}
{'eval_f1': 0.35881753312945974, 'eval_precision': 0.35235235235235235, 'eval_recall': 0.3655244029075805, 'eval_runtime': 979.5592, 'eval_samples_per_second': 0.405, 'eval_steps_per_second': 0.068, 'epoch': 6.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 20%|██        | 343/1710 [3:23:02<118:45:35, 312.75s/it] 20%|██        | 344/1710 [3:23:18<84:52:15, 223.67s/it]  20%|██        | 345/1710 [3:23:40<61:52:12, 163.17s/it] 20%|██        | 346/1710 [3:23:58<45:23:07, 119.79s/it] 20%|██        | 347/1710 [3:24:17<33:54:22, 89.55s/it]  20%|██        | 348/1710 [3:24:34<25:41:13, 67.90s/it] 20%|██        | 349/1710 [3:24:52<19:56:12, 52.74s/it] 20%|██        | 350/1710 [3:25:13<16:19:34, 43.22s/it]                                                        20%|██        | 350/1710 [3:25:13<16:19:34, 43.22s/it] 21%|██        | 351/1710 [3:25:31<13:27:45, 35.66s/it] 21%|██        | 352/1710 [3:25:51<11:41:40, 31.00s/it] 21%|██        | 353/1710 [3:26:12<10:32:17, 27.96s/it] 21%|██        | 354/1710 [3:26:28<9:13:28, 24.49s/it]  21%|██        | 355/1710 [3:26:48<8:37:54, 22.93s/it] 21%|██        | 356/1710 [3:27:18<9:28:02, 25.17s/it] 21%|██        | 357/1710 [3:27:35<8:35:57, 22.88s/it] 21%|██        | 358/1710 [3:27:55<8:14:44, 21.96s/it] 21%|██        | 359/1710 [3:28:17<8:09:51, 21.76s/it] 21%|██        | 360/1710 [3:28:39<8:16:06, 22.05s/it]                                                       21%|██        | 360/1710 [3:28:39<8:16:06, 22.05s/it] 21%|██        | 361/1710 [3:28:58<7:49:53, 20.90s/it] 21%|██        | 362/1710 [3:29:17<7:42:43, 20.60s/it] 21%|██        | 363/1710 [3:29:34<7:18:11, 19.52s/it] 21%|██▏       | 364/1710 [3:29:51<6:58:45, 18.67s/it] 21%|██▏       | 365/1710 [3:30:07<6:39:23, 17.82s/it] 21%|██▏       | 366/1710 [3:30:25<6:38:38, 17.80s/it] 21%|██▏       | 367/1710 [3:30:44<6:47:24, 18.20s/it] 22%|██▏       | 368/1710 [3:31:05<7:03:55, 18.95s/it] 22%|██▏       | 369/1710 [3:31:22<6:55:40, 18.60s/it] 22%|██▏       | 370/1710 [3:31:41<6:53:06, 18.50s/it]                                                       22%|██▏       | 370/1710 [3:31:41<6:53:06, 18.50s/it] 22%|██▏       | 371/1710 [3:32:02<7:12:02, 19.36s/it] 22%|██▏       | 372/1710 [3:32:20<7:04:57, 19.06s/it] 22%|██▏       | 373/1710 [3:32:43<7:27:26, 20.08s/it] 22%|██▏       | 374/1710 [3:33:00<7:05:50, 19.12s/it] 22%|██▏       | 375/1710 [3:33:20<7:12:05, 19.42s/it] 22%|██▏       | 376/1710 [3:33:39<7:07:37, 19.23s/it] 22%|██▏       | 377/1710 [3:33:58<7:07:06, 19.23s/it] 22%|██▏       | 378/1710 [3:34:16<7:02:46, 19.04s/it] 22%|██▏       | 379/1710 [3:34:40<7:36:08, 20.56s/it] 22%|██▏       | 380/1710 [3:35:04<7:54:38, 21.41s/it]                                                       22%|██▏       | 380/1710 [3:35:04<7:54:38, 21.41s/it] 22%|██▏       | 381/1710 [3:35:23<7:36:24, 20.61s/it] 22%|██▏       | 382/1710 [3:35:42<7:27:14, 20.21s/it] 22%|██▏       | 383/1710 [3:35:59<7:03:25, 19.15s/it] 22%|██▏       | 384/1710 [3:36:14<6:38:54, 18.05s/it] 23%|██▎       | 385/1710 [3:36:37<7:08:55, 19.42s/it] 23%|██▎       | 386/1710 [3:36:56<7:04:47, 19.25s/it] 23%|██▎       | 387/1710 [3:37:13<6:52:08, 18.69s/it] 23%|██▎       | 388/1710 [3:37:32<6:54:47, 18.83s/it] 23%|██▎       | 389/1710 [3:37:51<6:55:10, 18.86s/it] 23%|██▎       | 390/1710 [3:38:07<6:35:44, 17.99s/it]                                                       23%|██▎       | 390/1710 [3:38:07<6:35:44, 17.99s/it] 23%|██▎       | 391/1710 [3:38:25<6:37:33, 18.08s/it] 23%|██▎       | 392/1710 [3:38:44<6:39:37, 18.19s/it] 23%|██▎       | 393/1710 [3:39:09<7:24:45, 20.26s/it] 23%|██▎       | 394/1710 [3:39:26<7:04:01, 19.33s/it] 23%|██▎       | 395/1710 [3:39:47<7:13:27, 19.78s/it] 23%|██▎       | 396/1710 [3:40:05<6:59:52, 19.17s/it] 23%|██▎       | 397/1710 [3:40:21<6:43:26, 18.44s/it] 23%|██▎       | 398/1710 [3:40:45<7:17:47, 20.02s/it] 23%|██▎       | 399/1710 [3:41:05<7:19:47, 20.13s/it]{'loss': 0.1973, 'learning_rate': 9.298682951052328e-05, 'epoch': 6.14}
{'loss': 0.1846, 'learning_rate': 9.249009430984908e-05, 'epoch': 6.32}
{'loss': 0.187, 'learning_rate': 9.197778665670706e-05, 'epoch': 6.49}
{'loss': 0.1975, 'learning_rate': 9.145009430983739e-05, 'epoch': 6.67}
{'loss': 0.2101, 'learning_rate': 9.090721066641003e-05, 'epoch': 6.84}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:56,  5.48s/it][A
  4%|▍         | 3/67 [00:22<08:20,  7.81s/it][A
  6%|▌         | 4/67 [00:28<07:40,  7.31s/it][A
  7%|▋         | 5/67 [00:48<11:56, 11.55s/it][A
  9%|▉         | 6/67 [00:59<11:47, 11.60s/it][A
 10%|█         | 7/67 [01:13<12:20, 12.35s/it][A
 12%|█▏        | 8/67 [01:34<14:43, 14.98s/it][A
 13%|█▎        | 9/67 [01:43<12:45, 13.19s/it][A
 15%|█▍        | 10/67 [01:53<11:29, 12.10s/it][A
 16%|█▋        | 11/67 [02:11<12:56, 13.86s/it][A
 18%|█▊        | 12/67 [02:22<12:04, 13.18s/it][A
 19%|█▉        | 13/67 [02:30<10:17, 11.44s/it][A
 21%|██        | 14/67 [02:55<13:53, 15.74s/it][A
 22%|██▏       | 15/67 [03:13<14:01, 16.18s/it][A
 24%|██▍       | 16/67 [03:22<11:55, 14.03s/it][A
 25%|██▌       | 17/67 [03:39<12:35, 15.11s/it][A
 27%|██▋       | 18/67 [03:52<11:50, 14.50s/it][A
 28%|██▊       | 19/67 [04:09<12:06, 15.14s/it][A
 30%|██▉       | 20/67 [04:28<12:44, 16.26s/it][A
 31%|███▏      | 21/67 [04:45<12:47, 16.70s/it][A
 33%|███▎      | 22/67 [05:04<12:56, 17.26s/it][A
 34%|███▍      | 23/67 [05:12<10:42, 14.60s/it][A
 36%|███▌      | 24/67 [05:48<14:52, 20.76s/it][A
 37%|███▋      | 25/67 [06:09<14:44, 21.06s/it][A
 39%|███▉      | 26/67 [06:19<12:07, 17.74s/it][A
 40%|████      | 27/67 [06:37<11:47, 17.69s/it][A
 42%|████▏     | 28/67 [06:51<10:52, 16.73s/it][A
 43%|████▎     | 29/67 [06:59<08:55, 14.08s/it][A
 45%|████▍     | 30/67 [07:12<08:24, 13.63s/it][A
 46%|████▋     | 31/67 [07:18<06:49, 11.37s/it][A
 48%|████▊     | 32/67 [07:34<07:23, 12.68s/it][A
 49%|████▉     | 33/67 [07:51<08:00, 14.13s/it][A
 51%|█████     | 34/67 [08:04<07:33, 13.74s/it][A
 52%|█████▏    | 35/67 [08:19<07:29, 14.06s/it][A
 54%|█████▎    | 36/67 [08:29<06:42, 12.99s/it][A
 55%|█████▌    | 37/67 [08:34<05:17, 10.58s/it][A
 57%|█████▋    | 38/67 [08:50<05:53, 12.17s/it][A
 58%|█████▊    | 39/67 [08:59<05:11, 11.13s/it][A
 60%|█████▉    | 40/67 [09:08<04:46, 10.62s/it][A
 61%|██████    | 41/67 [09:18<04:31, 10.44s/it][A
 63%|██████▎   | 42/67 [09:28<04:15, 10.21s/it][A
 64%|██████▍   | 43/67 [09:44<04:43, 11.80s/it][A
 66%|██████▌   | 44/67 [09:54<04:22, 11.43s/it][A
 67%|██████▋   | 45/67 [10:00<03:34,  9.74s/it][A
 69%|██████▊   | 46/67 [10:08<03:15,  9.31s/it][A
 70%|███████   | 47/67 [10:24<03:46, 11.35s/it][A
 72%|███████▏  | 48/67 [10:35<03:30, 11.06s/it][A
 73%|███████▎  | 49/67 [10:52<03:55, 13.09s/it][A
 75%|███████▍  | 50/67 [11:03<03:27, 12.23s/it][A
 76%|███████▌  | 51/67 [11:18<03:28, 13.03s/it][A
 78%|███████▊  | 52/67 [11:28<03:03, 12.20s/it][A
 79%|███████▉  | 53/67 [11:41<02:53, 12.38s/it][A
 81%|████████  | 54/67 [11:54<02:45, 12.75s/it][A
 82%|████████▏ | 55/67 [12:11<02:45, 13.79s/it][A
 84%|████████▎ | 56/67 [12:22<02:22, 12.99s/it][A
 85%|████████▌ | 57/67 [12:45<02:40, 16.03s/it][A
 87%|████████▋ | 58/67 [13:03<02:29, 16.62s/it][A
 88%|████████▊ | 59/67 [13:28<02:34, 19.29s/it][A
 90%|████████▉ | 60/67 [13:48<02:15, 19.42s/it][A
 91%|█████████ | 61/67 [13:58<01:38, 16.45s/it][A
 93%|█████████▎| 62/67 [14:08<01:12, 14.58s/it][A
 94%|█████████▍| 63/67 [14:16<00:51, 12.79s/it][A
 96%|█████████▌| 64/67 [14:26<00:35, 11.77s/it][A
 97%|█████████▋| 65/67 [14:33<00:20, 10.28s/it][A
 99%|█████████▊| 66/67 [14:45<00:10, 10.94s/it][A
100%|██████████| 67/67 [14:47<00:00,  8.19s/it][A                                                      
                                               [A 23%|██▎       | 399/1710 [3:56:09<7:19:47, 20.13s/it]
100%|██████████| 67/67 [14:48<00:00,  8.19s/it][A
                                               [A{'f1_1': 0.4012441679626749, 'precision': 0.40062111801242234, 'recall': 0.40186915887850466}
{'f1': 0.3691031622602384, 'precision': 0.36853002070393376, 'recall': 0.36967808930425755}
{'eval_f1': 0.3691031622602384, 'eval_precision': 0.36853002070393376, 'eval_recall': 0.36967808930425755, 'eval_runtime': 903.4962, 'eval_samples_per_second': 0.439, 'eval_steps_per_second': 0.074, 'epoch': 7.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 23%|██▎       | 400/1710 [3:56:28<105:52:16, 290.94s/it]                                                          23%|██▎       | 400/1710 [3:56:28<105:52:16, 290.94s/it] 23%|██▎       | 401/1710 [3:56:46<75:57:56, 208.92s/it]  24%|██▎       | 402/1710 [3:57:03<54:58:50, 151.32s/it] 24%|██▎       | 403/1710 [3:57:19<40:13:19, 110.79s/it] 24%|██▎       | 404/1710 [3:57:40<30:29:11, 84.04s/it]  24%|██▎       | 405/1710 [3:58:03<23:44:56, 65.51s/it] 24%|██▎       | 406/1710 [3:58:22<18:44:23, 51.74s/it] 24%|██▍       | 407/1710 [3:58:39<14:55:54, 41.25s/it] 24%|██▍       | 408/1710 [3:58:57<12:23:51, 34.28s/it] 24%|██▍       | 409/1710 [3:59:18<10:54:46, 30.20s/it] 24%|██▍       | 410/1710 [3:59:39<9:56:25, 27.53s/it]                                                        24%|██▍       | 410/1710 [3:59:39<9:56:25, 27.53s/it] 24%|██▍       | 411/1710 [4:00:00<9:13:10, 25.55s/it] 24%|██▍       | 412/1710 [4:00:17<8:13:52, 22.83s/it] 24%|██▍       | 413/1710 [4:00:33<7:34:48, 21.04s/it] 24%|██▍       | 414/1710 [4:00:58<7:57:15, 22.10s/it] 24%|██▍       | 415/1710 [4:01:15<7:26:13, 20.67s/it] 24%|██▍       | 416/1710 [4:01:39<7:42:52, 21.46s/it] 24%|██▍       | 417/1710 [4:01:59<7:37:48, 21.24s/it] 24%|██▍       | 418/1710 [4:02:18<7:19:05, 20.39s/it] 25%|██▍       | 419/1710 [4:02:39<7:27:01, 20.78s/it] 25%|██▍       | 420/1710 [4:02:57<7:08:01, 19.91s/it]                                                       25%|██▍       | 420/1710 [4:02:57<7:08:01, 19.91s/it] 25%|██▍       | 421/1710 [4:03:13<6:42:05, 18.72s/it] 25%|██▍       | 422/1710 [4:03:31<6:35:36, 18.43s/it] 25%|██▍       | 423/1710 [4:03:49<6:34:46, 18.40s/it] 25%|██▍       | 424/1710 [4:04:08<6:34:33, 18.41s/it] 25%|██▍       | 425/1710 [4:04:27<6:41:45, 18.76s/it] 25%|██▍       | 426/1710 [4:04:48<6:51:32, 19.23s/it] 25%|██▍       | 427/1710 [4:05:07<6:51:28, 19.24s/it] 25%|██▌       | 428/1710 [4:05:29<7:11:09, 20.18s/it] 25%|██▌       | 429/1710 [4:05:47<6:53:23, 19.36s/it] 25%|██▌       | 430/1710 [4:06:05<6:47:42, 19.11s/it]                                                       25%|██▌       | 430/1710 [4:06:05<6:47:42, 19.11s/it] 25%|██▌       | 431/1710 [4:06:26<6:55:42, 19.50s/it] 25%|██▌       | 432/1710 [4:06:45<6:57:09, 19.58s/it] 25%|██▌       | 433/1710 [4:07:05<6:53:28, 19.43s/it] 25%|██▌       | 434/1710 [4:07:25<6:59:19, 19.72s/it] 25%|██▌       | 435/1710 [4:07:42<6:41:37, 18.90s/it] 25%|██▌       | 436/1710 [4:08:00<6:33:24, 18.53s/it] 26%|██▌       | 437/1710 [4:08:25<7:18:04, 20.65s/it] 26%|██▌       | 438/1710 [4:08:44<7:06:15, 20.11s/it] 26%|██▌       | 439/1710 [4:09:03<6:57:51, 19.73s/it] 26%|██▌       | 440/1710 [4:09:23<7:01:13, 19.90s/it]                                                       26%|██▌       | 440/1710 [4:09:23<7:01:13, 19.90s/it] 26%|██▌       | 441/1710 [4:09:46<7:21:27, 20.87s/it] 26%|██▌       | 442/1710 [4:10:08<7:23:10, 20.97s/it] 26%|██▌       | 443/1710 [4:10:24<6:56:22, 19.72s/it] 26%|██▌       | 444/1710 [4:10:41<6:36:17, 18.78s/it] 26%|██▌       | 445/1710 [4:11:00<6:37:33, 18.86s/it] 26%|██▌       | 446/1710 [4:11:17<6:24:17, 18.24s/it] 26%|██▌       | 447/1710 [4:11:33<6:14:32, 17.79s/it] 26%|██▌       | 448/1710 [4:11:51<6:10:56, 17.64s/it] 26%|██▋       | 449/1710 [4:12:15<6:49:25, 19.48s/it] 26%|██▋       | 450/1710 [4:12:33<6:42:29, 19.17s/it]                                                       26%|██▋       | 450/1710 [4:12:33<6:42:29, 19.17s/it] 26%|██▋       | 451/1710 [4:12:51<6:38:00, 18.97s/it] 26%|██▋       | 452/1710 [4:13:11<6:40:42, 19.11s/it] 26%|██▋       | 453/1710 [4:13:31<6:44:29, 19.31s/it] 27%|██▋       | 454/1710 [4:13:49<6:38:05, 19.02s/it] 27%|██▋       | 455/1710 [4:14:07<6:30:05, 18.65s/it] 27%|██▋       | 456/1710 [4:14:24<6:18:40, 18.12s/it]{'loss': 0.2141, 'learning_rate': 9.034933469114532e-05, 'epoch': 7.02}
{'loss': 0.1381, 'learning_rate': 8.977667084339429e-05, 'epoch': 7.19}
{'loss': 0.1661, 'learning_rate': 8.918942900220509e-05, 'epoch': 7.37}
{'loss': 0.1746, 'learning_rate': 8.858782438940312e-05, 'epoch': 7.54}
{'loss': 0.1424, 'learning_rate': 8.797207749071308e-05, 'epoch': 7.72}
{'loss': 0.1691, 'learning_rate': 8.734241397495188e-05, 'epoch': 7.89}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:12<06:50,  6.32s/it][A
  4%|▍         | 3/67 [00:19<07:07,  6.68s/it][A
  6%|▌         | 4/67 [00:26<06:50,  6.51s/it][A
  7%|▋         | 5/67 [00:42<10:12,  9.88s/it][A
  9%|▉         | 6/67 [00:53<10:31, 10.35s/it][A
 10%|█         | 7/67 [01:07<11:23, 11.39s/it][A
 12%|█▏        | 8/67 [01:45<19:41, 20.02s/it][A
 13%|█▎        | 9/67 [02:04<18:48, 19.46s/it][A
 15%|█▍        | 10/67 [02:11<15:05, 15.88s/it][A
 16%|█▋        | 11/67 [02:24<13:55, 14.92s/it][A
 18%|█▊        | 12/67 [02:36<12:40, 13.83s/it][A
 19%|█▉        | 13/67 [02:43<10:39, 11.84s/it][A
 21%|██        | 14/67 [03:05<13:14, 14.99s/it][A
 22%|██▏       | 15/67 [03:22<13:26, 15.52s/it][A
 24%|██▍       | 16/67 [03:29<11:00, 12.95s/it][A
 25%|██▌       | 17/67 [03:51<13:01, 15.63s/it][A
 27%|██▋       | 18/67 [04:01<11:26, 14.01s/it][A
 28%|██▊       | 19/67 [04:18<11:51, 14.83s/it][A
 30%|██▉       | 20/67 [04:31<11:10, 14.26s/it][A
 31%|███▏      | 21/67 [05:14<17:36, 22.98s/it][A
 33%|███▎      | 22/67 [05:31<15:51, 21.15s/it][A
 34%|███▍      | 23/67 [05:43<13:28, 18.38s/it][A
 36%|███▌      | 24/67 [06:11<15:12, 21.23s/it][A
 37%|███▋      | 25/67 [06:34<15:24, 22.01s/it][A
 39%|███▉      | 26/67 [06:44<12:30, 18.30s/it][A
 40%|████      | 27/67 [06:57<11:12, 16.82s/it][A
 42%|████▏     | 28/67 [07:15<11:01, 16.96s/it][A
 43%|████▎     | 29/67 [07:24<09:22, 14.80s/it][A
 45%|████▍     | 30/67 [07:32<07:53, 12.79s/it][A
 46%|████▋     | 31/67 [07:41<06:57, 11.59s/it][A
 48%|████▊     | 32/67 [07:50<06:14, 10.70s/it][A
 49%|████▉     | 33/67 [08:08<07:15, 12.82s/it][A
 51%|█████     | 34/67 [08:17<06:28, 11.76s/it][A
 52%|█████▏    | 35/67 [08:32<06:47, 12.73s/it][A
 54%|█████▎    | 36/67 [08:42<06:06, 11.81s/it][A
 55%|█████▌    | 37/67 [08:48<05:06, 10.23s/it][A
 57%|█████▋    | 38/67 [09:02<05:29, 11.37s/it][A
 58%|█████▊    | 39/67 [09:11<04:56, 10.58s/it][A
 60%|█████▉    | 40/67 [09:22<04:53, 10.86s/it][A
 61%|██████    | 41/67 [09:44<06:09, 14.21s/it][A
 63%|██████▎   | 42/67 [09:59<05:57, 14.30s/it][A
 64%|██████▍   | 43/67 [10:23<06:54, 17.26s/it][A
 66%|██████▌   | 44/67 [10:37<06:12, 16.20s/it][A
 67%|██████▋   | 45/67 [10:43<04:47, 13.08s/it][A
 69%|██████▊   | 46/67 [10:53<04:18, 12.29s/it][A
 70%|███████   | 47/67 [11:06<04:12, 12.61s/it][A
 72%|███████▏  | 48/67 [11:20<04:05, 12.90s/it][A
 73%|███████▎  | 49/67 [11:38<04:20, 14.45s/it][A
 75%|███████▍  | 50/67 [11:50<03:51, 13.60s/it][A
 76%|███████▌  | 51/67 [12:02<03:29, 13.07s/it][A
 78%|███████▊  | 52/67 [12:17<03:27, 13.85s/it][A
 79%|███████▉  | 53/67 [12:31<03:15, 13.97s/it][A
 81%|████████  | 54/67 [12:39<02:36, 12.04s/it][A
 82%|████████▏ | 55/67 [12:49<02:17, 11.43s/it][A
 84%|████████▎ | 56/67 [13:09<02:32, 13.88s/it][A
 85%|████████▌ | 57/67 [13:27<02:33, 15.36s/it][A
 87%|████████▋ | 58/67 [13:53<02:46, 18.53s/it][A
 88%|████████▊ | 59/67 [14:29<03:08, 23.56s/it][A
 90%|████████▉ | 60/67 [14:46<02:31, 21.62s/it][A
 91%|█████████ | 61/67 [14:57<01:51, 18.64s/it][A
 93%|█████████▎| 62/67 [15:05<01:17, 15.46s/it][A
 94%|█████████▍| 63/67 [15:18<00:57, 14.45s/it][A
 96%|█████████▌| 64/67 [15:30<00:41, 13.78s/it][A
 97%|█████████▋| 65/67 [15:39<00:24, 12.36s/it][A
 99%|█████████▊| 66/67 [15:55<00:13, 13.47s/it][A
100%|██████████| 67/67 [15:57<00:00, 10.05s/it][A                                                      
                                               [A 27%|██▋       | 456/1710 [4:30:40<6:18:40, 18.12s/it]
100%|██████████| 67/67 [15:58<00:00, 10.05s/it][A
                                               [A{'f1_1': 0.40160240360540816, 'precision': 0.38781431334622823, 'recall': 0.4164070612668744}
{'f1': 0.3785678517776665, 'precision': 0.3655705996131528, 'recall': 0.3925233644859813}
{'eval_f1': 0.3785678517776665, 'eval_precision': 0.3655705996131528, 'eval_recall': 0.3925233644859813, 'eval_runtime': 976.3177, 'eval_samples_per_second': 0.407, 'eval_steps_per_second': 0.069, 'epoch': 8.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 27%|██▋       | 457/1710 [4:31:06<109:04:17, 313.37s/it] 27%|██▋       | 458/1710 [4:31:24<78:12:00, 224.86s/it]  27%|██▋       | 459/1710 [4:31:40<56:21:25, 162.18s/it] 27%|██▋       | 460/1710 [4:32:04<41:50:36, 120.51s/it]                                                         27%|██▋       | 460/1710 [4:32:04<41:50:36, 120.51s/it] 27%|██▋       | 461/1710 [4:32:22<31:13:45, 90.01s/it]  27%|██▋       | 462/1710 [4:32:41<23:43:49, 68.45s/it] 27%|██▋       | 463/1710 [4:33:00<18:38:10, 53.80s/it] 27%|██▋       | 464/1710 [4:33:22<15:20:06, 44.31s/it] 27%|██▋       | 465/1710 [4:33:38<12:23:47, 35.85s/it] 27%|██▋       | 466/1710 [4:33:59<10:45:56, 31.15s/it] 27%|██▋       | 467/1710 [4:34:25<10:16:56, 29.78s/it] 27%|██▋       | 468/1710 [4:34:43<9:03:44, 26.27s/it]  27%|██▋       | 469/1710 [4:34:59<7:59:59, 23.21s/it] 27%|██▋       | 470/1710 [4:35:17<7:27:02, 21.63s/it]                                                       27%|██▋       | 470/1710 [4:35:17<7:27:02, 21.63s/it] 28%|██▊       | 471/1710 [4:35:37<7:13:13, 20.98s/it] 28%|██▊       | 472/1710 [4:36:09<8:20:06, 24.24s/it] 28%|██▊       | 473/1710 [4:36:26<7:39:37, 22.29s/it] 28%|██▊       | 474/1710 [4:36:49<7:38:32, 22.26s/it] 28%|██▊       | 475/1710 [4:37:06<7:09:01, 20.84s/it] 28%|██▊       | 476/1710 [4:37:27<7:12:16, 21.02s/it] 28%|██▊       | 477/1710 [4:37:48<7:08:48, 20.87s/it] 28%|██▊       | 478/1710 [4:38:13<7:31:00, 21.96s/it] 28%|██▊       | 479/1710 [4:38:32<7:13:02, 21.11s/it] 28%|██▊       | 480/1710 [4:38:51<7:00:12, 20.50s/it]                                                       28%|██▊       | 480/1710 [4:38:51<7:00:12, 20.50s/it] 28%|██▊       | 481/1710 [4:39:08<6:41:02, 19.58s/it] 28%|██▊       | 482/1710 [4:39:25<6:21:45, 18.65s/it] 28%|██▊       | 483/1710 [4:39:47<6:45:18, 19.82s/it] 28%|██▊       | 484/1710 [4:40:03<6:19:05, 18.55s/it] 28%|██▊       | 485/1710 [4:40:22<6:21:03, 18.66s/it] 28%|██▊       | 486/1710 [4:40:42<6:31:08, 19.17s/it] 28%|██▊       | 487/1710 [4:41:02<6:34:26, 19.35s/it] 29%|██▊       | 488/1710 [4:41:21<6:33:42, 19.33s/it] 29%|██▊       | 489/1710 [4:41:38<6:20:27, 18.70s/it] 29%|██▊       | 490/1710 [4:41:56<6:16:16, 18.51s/it]                                                       29%|██▊       | 490/1710 [4:41:56<6:16:16, 18.51s/it] 29%|██▊       | 491/1710 [4:42:15<6:14:53, 18.45s/it] 29%|██▉       | 492/1710 [4:42:30<5:58:23, 17.65s/it] 29%|██▉       | 493/1710 [4:42:50<6:08:32, 18.17s/it] 29%|██▉       | 494/1710 [4:43:08<6:10:39, 18.29s/it] 29%|██▉       | 495/1710 [4:43:25<6:01:46, 17.87s/it] 29%|██▉       | 496/1710 [4:43:43<5:59:35, 17.77s/it] 29%|██▉       | 497/1710 [4:44:00<5:54:32, 17.54s/it] 29%|██▉       | 498/1710 [4:44:18<5:58:54, 17.77s/it] 29%|██▉       | 499/1710 [4:44:36<5:56:53, 17.68s/it] 29%|██▉       | 500/1710 [4:44:52<5:48:25, 17.28s/it]                                                       29%|██▉       | 500/1710 [4:44:52<5:48:25, 17.28s/it] 29%|██▉       | 501/1710 [4:45:10<5:50:18, 17.39s/it] 29%|██▉       | 502/1710 [4:45:30<6:08:11, 18.29s/it] 29%|██▉       | 503/1710 [4:45:50<6:18:39, 18.82s/it] 29%|██▉       | 504/1710 [4:46:11<6:32:57, 19.55s/it] 30%|██▉       | 505/1710 [4:46:31<6:34:25, 19.64s/it] 30%|██▉       | 506/1710 [4:46:49<6:24:57, 19.18s/it] 30%|██▉       | 507/1710 [4:47:05<6:00:42, 17.99s/it] 30%|██▉       | 508/1710 [4:47:22<5:54:30, 17.70s/it] 30%|██▉       | 509/1710 [4:47:43<6:17:50, 18.88s/it] 30%|██▉       | 510/1710 [4:48:01<6:10:18, 18.52s/it]                                                       30%|██▉       | 510/1710 [4:48:01<6:10:18, 18.52s/it] 30%|██▉       | 511/1710 [4:48:23<6:30:56, 19.56s/it] 30%|██▉       | 512/1710 [4:48:41<6:23:41, 19.22s/it] 30%|███       | 513/1710 [4:48:59<6:14:37, 18.78s/it]{'loss': 0.1649, 'learning_rate': 8.669906461132182e-05, 'epoch': 8.07}
{'loss': 0.1356, 'learning_rate': 8.604226518483462e-05, 'epoch': 8.25}
{'loss': 0.1051, 'learning_rate': 8.537225640989716e-05, 'epoch': 8.42}
{'loss': 0.1167, 'learning_rate': 8.46892838420906e-05, 'epoch': 8.6}
{'loss': 0.1068, 'learning_rate': 8.399359778817516e-05, 'epoch': 8.77}
{'loss': 0.1494, 'learning_rate': 8.32854532143537e-05, 'epoch': 8.95}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:06<03:28,  3.21s/it][A
  4%|▍         | 3/67 [00:14<05:38,  5.29s/it][A
  6%|▌         | 4/67 [00:22<06:35,  6.28s/it][A
  7%|▋         | 5/67 [00:40<10:40, 10.34s/it][A
  9%|▉         | 6/67 [00:55<12:08, 11.94s/it][A
 10%|█         | 7/67 [01:13<13:44, 13.75s/it][A
 12%|█▏        | 8/67 [01:37<16:53, 17.17s/it][A
 13%|█▎        | 9/67 [01:56<16:54, 17.48s/it][A
 15%|█▍        | 10/67 [02:06<14:26, 15.21s/it][A
 16%|█▋        | 11/67 [02:26<15:32, 16.65s/it][A
 18%|█▊        | 12/67 [02:37<13:45, 15.01s/it][A
 19%|█▉        | 13/67 [02:44<11:22, 12.65s/it][A
 21%|██        | 14/67 [03:09<14:25, 16.33s/it][A
 22%|██▏       | 15/67 [03:26<14:15, 16.46s/it][A
 24%|██▍       | 16/67 [03:34<11:49, 13.92s/it][A
 25%|██▌       | 17/67 [03:54<13:06, 15.73s/it][A
 27%|██▋       | 18/67 [04:06<12:00, 14.70s/it][A
 28%|██▊       | 19/67 [04:22<12:09, 15.19s/it][A
 30%|██▉       | 20/67 [04:35<11:16, 14.40s/it][A
 31%|███▏      | 21/67 [05:01<13:39, 17.82s/it][A
 33%|███▎      | 22/67 [05:17<13:09, 17.54s/it][A
 34%|███▍      | 23/67 [05:27<11:00, 15.01s/it][A
 36%|███▌      | 24/67 [05:52<12:58, 18.09s/it][A
 37%|███▋      | 25/67 [06:10<12:43, 18.19s/it][A
 39%|███▉      | 26/67 [06:22<11:12, 16.41s/it][A
 40%|████      | 27/67 [06:36<10:16, 15.41s/it][A
 42%|████▏     | 28/67 [06:53<10:28, 16.10s/it][A
 43%|████▎     | 29/67 [07:00<08:29, 13.42s/it][A
 45%|████▍     | 30/67 [07:09<07:22, 11.95s/it][A
 46%|████▋     | 31/67 [07:15<06:08, 10.24s/it][A
 48%|████▊     | 32/67 [07:27<06:12, 10.64s/it][A
 49%|████▉     | 33/67 [07:45<07:14, 12.79s/it][A
 51%|█████     | 34/67 [07:56<06:51, 12.47s/it][A
 52%|█████▏    | 35/67 [08:07<06:17, 11.81s/it][A
 54%|█████▎    | 36/67 [08:17<05:56, 11.49s/it][A
 55%|█████▌    | 37/67 [08:24<05:02, 10.10s/it][A
 57%|█████▋    | 38/67 [08:38<05:22, 11.14s/it][A
 58%|█████▊    | 39/67 [08:50<05:19, 11.40s/it][A
 60%|█████▉    | 40/67 [08:59<04:52, 10.84s/it][A
 61%|██████    | 41/67 [09:17<05:34, 12.87s/it][A
 63%|██████▎   | 42/67 [09:36<06:05, 14.63s/it][A
 64%|██████▍   | 43/67 [09:55<06:26, 16.10s/it][A
 66%|██████▌   | 44/67 [10:14<06:27, 16.85s/it][A
 67%|██████▋   | 45/67 [10:19<04:51, 13.26s/it][A
 69%|██████▊   | 46/67 [10:27<04:05, 11.70s/it][A
 70%|███████   | 47/67 [10:44<04:26, 13.32s/it][A
 72%|███████▏  | 48/67 [10:54<03:57, 12.49s/it][A
 73%|███████▎  | 49/67 [11:13<04:15, 14.22s/it][A
 75%|███████▍  | 50/67 [11:31<04:22, 15.47s/it][A
 76%|███████▌  | 51/67 [11:47<04:10, 15.66s/it][A
 78%|███████▊  | 52/67 [12:03<03:54, 15.62s/it][A
 79%|███████▉  | 53/67 [12:16<03:28, 14.87s/it][A
 81%|████████  | 54/67 [12:30<03:09, 14.58s/it][A
 82%|████████▏ | 55/67 [12:40<02:40, 13.36s/it][A
 84%|████████▎ | 56/67 [13:00<02:47, 15.21s/it][A
 85%|████████▌ | 57/67 [13:22<02:54, 17.44s/it][A
 87%|████████▋ | 58/67 [13:42<02:43, 18.21s/it][A
 88%|████████▊ | 59/67 [14:03<02:32, 19.07s/it][A
 90%|████████▉ | 60/67 [14:23<02:13, 19.14s/it][A
 91%|█████████ | 61/67 [14:32<01:37, 16.21s/it][A
 93%|█████████▎| 62/67 [14:39<01:07, 13.40s/it][A
 94%|█████████▍| 63/67 [14:50<00:51, 12.80s/it][A
 96%|█████████▌| 64/67 [15:00<00:35, 11.74s/it][A
 97%|█████████▋| 65/67 [15:06<00:20, 10.23s/it][A
 99%|█████████▊| 66/67 [15:29<00:13, 13.84s/it][A
100%|██████████| 67/67 [15:32<00:00, 10.58s/it][A                                                      
                                               [A 30%|███       | 513/1710 [5:04:52<6:14:37, 18.78s/it]
100%|██████████| 67/67 [15:33<00:00, 10.58s/it][A
                                               [A{'f1_1': 0.4153769345981029, 'precision': 0.4, 'recall': 0.43198338525441327}
{'f1': 0.3894158761857214, 'precision': 0.375, 'recall': 0.40498442367601245}
{'eval_f1': 0.3894158761857214, 'eval_precision': 0.375, 'eval_recall': 0.40498442367601245, 'eval_runtime': 952.86, 'eval_samples_per_second': 0.417, 'eval_steps_per_second': 0.07, 'epoch': 9.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 30%|███       | 514/1710 [5:05:14<101:34:56, 305.77s/it] 30%|███       | 515/1710 [5:05:32<72:47:51, 219.31s/it]  30%|███       | 516/1710 [5:05:52<52:56:39, 159.63s/it] 30%|███       | 517/1710 [5:06:09<38:40:37, 116.71s/it] 30%|███       | 518/1710 [5:06:27<28:53:11, 87.24s/it]  30%|███       | 519/1710 [5:06:44<21:53:29, 66.17s/it] 30%|███       | 520/1710 [5:07:01<16:55:24, 51.20s/it]                                                        30%|███       | 520/1710 [5:07:01<16:55:24, 51.20s/it] 30%|███       | 521/1710 [5:07:19<13:38:52, 41.32s/it] 31%|███       | 522/1710 [5:07:38<11:23:40, 34.53s/it] 31%|███       | 523/1710 [5:08:01<10:18:49, 31.28s/it] 31%|███       | 524/1710 [5:08:17<8:45:38, 26.59s/it]  31%|███       | 525/1710 [5:08:35<7:57:11, 24.16s/it] 31%|███       | 526/1710 [5:08:53<7:19:19, 22.26s/it] 31%|███       | 527/1710 [5:09:15<7:14:09, 22.02s/it] 31%|███       | 528/1710 [5:09:31<6:41:56, 20.40s/it] 31%|███       | 529/1710 [5:09:53<6:47:41, 20.71s/it] 31%|███       | 530/1710 [5:10:14<6:49:20, 20.81s/it]                                                       31%|███       | 530/1710 [5:10:14<6:49:20, 20.81s/it] 31%|███       | 531/1710 [5:10:31<6:28:40, 19.78s/it] 31%|███       | 532/1710 [5:10:48<6:12:00, 18.95s/it] 31%|███       | 533/1710 [5:11:05<5:55:55, 18.14s/it] 31%|███       | 534/1710 [5:11:25<6:07:14, 18.74s/it] 31%|███▏      | 535/1710 [5:11:43<6:03:17, 18.55s/it] 31%|███▏      | 536/1710 [5:12:02<6:09:22, 18.88s/it] 31%|███▏      | 537/1710 [5:12:24<6:26:50, 19.79s/it] 31%|███▏      | 538/1710 [5:12:43<6:20:48, 19.50s/it] 32%|███▏      | 539/1710 [5:13:04<6:28:36, 19.91s/it] 32%|███▏      | 540/1710 [5:13:23<6:20:27, 19.51s/it]                                                       32%|███▏      | 540/1710 [5:13:23<6:20:27, 19.51s/it] 32%|███▏      | 541/1710 [5:13:44<6:29:21, 19.98s/it] 32%|███▏      | 542/1710 [5:14:00<6:08:31, 18.93s/it] 32%|███▏      | 543/1710 [5:14:28<7:00:14, 21.61s/it] 32%|███▏      | 544/1710 [5:14:45<6:35:03, 20.33s/it] 32%|███▏      | 545/1710 [5:15:04<6:22:48, 19.72s/it] 32%|███▏      | 546/1710 [5:15:24<6:29:02, 20.05s/it] 32%|███▏      | 547/1710 [5:15:41<6:10:00, 19.09s/it] 32%|███▏      | 548/1710 [5:16:01<6:11:51, 19.20s/it] 32%|███▏      | 549/1710 [5:16:22<6:23:24, 19.81s/it] 32%|███▏      | 550/1710 [5:16:40<6:14:36, 19.38s/it]                                                       32%|███▏      | 550/1710 [5:16:40<6:14:36, 19.38s/it] 32%|███▏      | 551/1710 [5:16:59<6:07:34, 19.03s/it] 32%|███▏      | 552/1710 [5:17:17<6:04:52, 18.91s/it] 32%|███▏      | 553/1710 [5:17:35<5:59:23, 18.64s/it] 32%|███▏      | 554/1710 [5:17:52<5:49:05, 18.12s/it] 32%|███▏      | 555/1710 [5:18:09<5:40:29, 17.69s/it] 33%|███▎      | 556/1710 [5:18:27<5:45:23, 17.96s/it] 33%|███▎      | 557/1710 [5:18:51<6:14:56, 19.51s/it] 33%|███▎      | 558/1710 [5:19:08<6:01:54, 18.85s/it] 33%|███▎      | 559/1710 [5:19:29<6:16:02, 19.60s/it] 33%|███▎      | 560/1710 [5:19:50<6:23:00, 19.98s/it]                                                       33%|███▎      | 560/1710 [5:19:50<6:23:00, 19.98s/it] 33%|███▎      | 561/1710 [5:20:09<6:16:52, 19.68s/it] 33%|███▎      | 562/1710 [5:20:32<6:36:16, 20.71s/it] 33%|███▎      | 563/1710 [5:20:49<6:15:35, 19.65s/it] 33%|███▎      | 564/1710 [5:21:06<6:00:09, 18.86s/it] 33%|███▎      | 565/1710 [5:21:27<6:12:11, 19.50s/it] 33%|███▎      | 566/1710 [5:21:48<6:17:27, 19.80s/it] 33%|███▎      | 567/1710 [5:22:06<6:10:00, 19.42s/it] 33%|███▎      | 568/1710 [5:22:35<7:03:22, 22.24s/it] 33%|███▎      | 569/1710 [5:22:51<6:27:45, 20.39s/it] 33%|███▎      | 570/1710 [5:23:11<6:26:25, 20.34s/it]                                                       33%|███▎      | 570/1710 [5:23:11<6:26:25, 20.34s/it]{'loss': 0.1056, 'learning_rate': 8.256510965282776e-05, 'epoch': 9.12}
{'loss': 0.0937, 'learning_rate': 8.183283110667972e-05, 'epoch': 9.3}
{'loss': 0.0986, 'learning_rate': 8.108888595311706e-05, 'epoch': 9.47}
{'loss': 0.0843, 'learning_rate': 8.033354684511287e-05, 'epoch': 9.65}
{'loss': 0.0923, 'learning_rate': 7.95670906114798e-05, 'epoch': 9.82}
{'loss': 0.0889, 'learning_rate': 7.878979815541332e-05, 'epoch': 10.0}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:06<03:41,  3.41s/it][A
  4%|▍         | 3/67 [00:11<04:16,  4.01s/it][A
  6%|▌         | 4/67 [00:18<05:29,  5.22s/it][A
  7%|▋         | 5/67 [00:34<09:13,  8.93s/it][A
  9%|▉         | 6/67 [00:46<09:52,  9.72s/it][A
 10%|█         | 7/67 [00:59<11:00, 11.01s/it][A
 12%|█▏        | 8/67 [01:24<15:05, 15.35s/it][A
 13%|█▎        | 9/67 [01:37<13:56, 14.43s/it][A
 15%|█▍        | 10/67 [01:46<12:10, 12.81s/it][A
 16%|█▋        | 11/67 [02:03<13:18, 14.26s/it][A
 18%|█▊        | 12/67 [02:13<11:44, 12.81s/it][A
 19%|█▉        | 13/67 [02:19<09:38, 10.72s/it][A
 21%|██        | 14/67 [02:27<08:43,  9.87s/it][A
 22%|██▏       | 15/67 [02:42<10:06, 11.66s/it][A
 24%|██▍       | 16/67 [02:48<08:23,  9.88s/it][A
 25%|██▌       | 17/67 [03:09<10:56, 13.12s/it][A
 27%|██▋       | 18/67 [03:21<10:30, 12.86s/it][A
 28%|██▊       | 19/67 [03:34<10:21, 12.96s/it][A
 30%|██▉       | 20/67 [03:43<09:11, 11.74s/it][A
 31%|███▏      | 21/67 [04:15<13:37, 17.77s/it][A
 33%|███▎      | 22/67 [04:31<12:53, 17.18s/it][A
 34%|███▍      | 23/67 [04:39<10:40, 14.55s/it][A
 36%|███▌      | 24/67 [05:07<13:11, 18.41s/it][A
 37%|███▋      | 25/67 [05:21<12:05, 17.27s/it][A
 39%|███▉      | 26/67 [05:29<09:57, 14.57s/it][A
 40%|████      | 27/67 [05:44<09:40, 14.52s/it][A
 42%|████▏     | 28/67 [05:51<08:02, 12.38s/it][A
 43%|████▎     | 29/67 [05:58<06:46, 10.71s/it][A
 45%|████▍     | 30/67 [06:03<05:36,  9.10s/it][A
 46%|████▋     | 31/67 [06:09<04:50,  8.06s/it][A
 48%|████▊     | 32/67 [06:18<04:53,  8.37s/it][A
 49%|████▉     | 33/67 [06:36<06:22, 11.24s/it][A
 51%|█████     | 34/67 [06:47<06:09, 11.21s/it][A
 52%|█████▏    | 35/67 [06:56<05:38, 10.59s/it][A
 54%|█████▎    | 36/67 [07:05<05:06,  9.90s/it][A
 55%|█████▌    | 37/67 [07:09<04:09,  8.30s/it][A
 57%|█████▋    | 38/67 [07:19<04:15,  8.80s/it][A
 58%|█████▊    | 39/67 [07:26<03:51,  8.25s/it][A
 60%|█████▉    | 40/67 [07:34<03:37,  8.05s/it][A
 61%|██████    | 41/67 [07:49<04:22, 10.11s/it][A
 63%|██████▎   | 42/67 [08:01<04:27, 10.72s/it][A
 64%|██████▍   | 43/67 [08:13<04:27, 11.14s/it][A
 66%|██████▌   | 44/67 [08:22<04:01, 10.51s/it][A
 67%|██████▋   | 45/67 [08:28<03:20,  9.09s/it][A
 69%|██████▊   | 46/67 [08:36<03:04,  8.79s/it][A
 70%|███████   | 47/67 [08:50<03:29, 10.49s/it][A
 72%|███████▏  | 48/67 [09:05<03:41, 11.67s/it][A
 73%|███████▎  | 49/67 [09:23<04:04, 13.57s/it][A
 75%|███████▍  | 50/67 [09:34<03:40, 12.97s/it][A
 76%|███████▌  | 51/67 [09:50<03:39, 13.74s/it][A
 78%|███████▊  | 52/67 [10:03<03:22, 13.52s/it][A
 79%|███████▉  | 53/67 [10:15<03:01, 13.00s/it][A
 81%|████████  | 54/67 [10:26<02:42, 12.52s/it][A
 82%|████████▏ | 55/67 [10:41<02:38, 13.23s/it][A
 84%|████████▎ | 56/67 [11:01<02:46, 15.16s/it][A
 85%|████████▌ | 57/67 [11:27<03:05, 18.54s/it][A
 87%|████████▋ | 58/67 [12:07<03:43, 24.83s/it][A
 88%|████████▊ | 59/67 [12:27<03:09, 23.63s/it][A
 90%|████████▉ | 60/67 [12:47<02:37, 22.46s/it][A
 91%|█████████ | 61/67 [12:58<01:54, 19.14s/it][A
 93%|█████████▎| 62/67 [13:06<01:17, 15.53s/it][A
 94%|█████████▍| 63/67 [13:17<00:57, 14.36s/it][A
 96%|█████████▌| 64/67 [13:26<00:38, 12.84s/it][A
 97%|█████████▋| 65/67 [13:33<00:22, 11.01s/it][A
 99%|█████████▊| 66/67 [13:48<00:12, 12.17s/it][A
100%|██████████| 67/67 [13:53<00:00,  9.95s/it][A                                                      
                                               [A 33%|███▎      | 570/1710 [5:37:20<6:26:25, 20.34s/it]
100%|██████████| 67/67 [13:54<00:00,  9.95s/it][A
                                               [A{'f1_1': 0.4200426439232409, 'precision': 0.4315443592552026, 'recall': 0.4091381100726895}
{'f1': 0.40191897654584224, 'precision': 0.4129244249726177, 'recall': 0.39148494288681207}
{'eval_f1': 0.40191897654584224, 'eval_precision': 0.4129244249726177, 'eval_recall': 0.39148494288681207, 'eval_runtime': 848.0921, 'eval_samples_per_second': 0.468, 'eval_steps_per_second': 0.079, 'epoch': 10.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 33%|███▎      | 571/1710 [5:37:39<86:50:40, 274.49s/it] 33%|███▎      | 572/1710 [5:37:56<62:23:39, 197.38s/it] 34%|███▎      | 573/1710 [5:38:26<46:24:20, 146.93s/it] 34%|███▎      | 574/1710 [5:38:44<34:09:03, 108.22s/it] 34%|███▎      | 575/1710 [5:39:05<25:54:57, 82.20s/it]  34%|███▎      | 576/1710 [5:39:23<19:50:56, 63.01s/it] 34%|███▎      | 577/1710 [5:39:44<15:50:00, 50.31s/it] 34%|███▍      | 578/1710 [5:40:01<12:41:29, 40.36s/it] 34%|███▍      | 579/1710 [5:40:19<10:31:06, 33.48s/it] 34%|███▍      | 580/1710 [5:40:35<8:54:25, 28.38s/it]                                                        34%|███▍      | 580/1710 [5:40:35<8:54:25, 28.38s/it] 34%|███▍      | 581/1710 [5:40:53<7:52:53, 25.13s/it] 34%|███▍      | 582/1710 [5:41:10<7:06:30, 22.69s/it] 34%|███▍      | 583/1710 [5:41:25<6:27:34, 20.63s/it] 34%|███▍      | 584/1710 [5:41:43<6:12:30, 19.85s/it] 34%|███▍      | 585/1710 [5:42:01<6:01:49, 19.30s/it] 34%|███▍      | 586/1710 [5:42:19<5:50:31, 18.71s/it] 34%|███▍      | 587/1710 [5:42:46<6:36:21, 21.18s/it] 34%|███▍      | 588/1710 [5:43:03<6:16:45, 20.15s/it] 34%|███▍      | 589/1710 [5:43:20<5:58:16, 19.18s/it] 35%|███▍      | 590/1710 [5:43:41<6:07:30, 19.69s/it]                                                       35%|███▍      | 590/1710 [5:43:41<6:07:30, 19.69s/it] 35%|███▍      | 591/1710 [5:44:01<6:07:58, 19.73s/it] 35%|███▍      | 592/1710 [5:44:18<5:52:58, 18.94s/it] 35%|███▍      | 593/1710 [5:44:38<5:59:21, 19.30s/it] 35%|███▍      | 594/1710 [5:44:54<5:37:56, 18.17s/it] 35%|███▍      | 595/1710 [5:45:14<5:49:54, 18.83s/it] 35%|███▍      | 596/1710 [5:45:35<6:02:10, 19.51s/it] 35%|███▍      | 597/1710 [5:45:55<6:05:16, 19.69s/it] 35%|███▍      | 598/1710 [5:46:14<5:59:30, 19.40s/it] 35%|███▌      | 599/1710 [5:46:32<5:52:05, 19.01s/it] 35%|███▌      | 600/1710 [5:46:51<5:50:08, 18.93s/it]                                                       35%|███▌      | 600/1710 [5:46:51<5:50:08, 18.93s/it] 35%|███▌      | 601/1710 [5:47:11<5:57:31, 19.34s/it] 35%|███▌      | 602/1710 [5:47:34<6:17:02, 20.42s/it] 35%|███▌      | 603/1710 [5:47:56<6:26:11, 20.93s/it] 35%|███▌      | 604/1710 [5:48:17<6:22:41, 20.76s/it] 35%|███▌      | 605/1710 [5:48:33<5:55:40, 19.31s/it] 35%|███▌      | 606/1710 [5:48:51<5:50:52, 19.07s/it] 35%|███▌      | 607/1710 [5:49:10<5:47:17, 18.89s/it] 36%|███▌      | 608/1710 [5:49:34<6:18:39, 20.62s/it] 36%|███▌      | 609/1710 [5:49:53<6:09:30, 20.14s/it] 36%|███▌      | 610/1710 [5:50:13<6:08:10, 20.08s/it]                                                       36%|███▌      | 610/1710 [5:50:13<6:08:10, 20.08s/it] 36%|███▌      | 611/1710 [5:50:31<5:52:55, 19.27s/it] 36%|███▌      | 612/1710 [5:50:47<5:39:16, 18.54s/it] 36%|███▌      | 613/1710 [5:51:11<6:05:59, 20.02s/it] 36%|███▌      | 614/1710 [5:51:30<6:01:35, 19.80s/it] 36%|███▌      | 615/1710 [5:51:50<6:01:23, 19.80s/it] 36%|███▌      | 616/1710 [5:52:07<5:47:16, 19.05s/it] 36%|███▌      | 617/1710 [5:52:28<5:56:44, 19.58s/it] 36%|███▌      | 618/1710 [5:52:45<5:43:05, 18.85s/it] 36%|███▌      | 619/1710 [5:53:02<5:33:50, 18.36s/it] 36%|███▋      | 620/1710 [5:53:25<5:58:57, 19.76s/it]                                                       36%|███▋      | 620/1710 [5:53:26<5:58:57, 19.76s/it] 36%|███▋      | 621/1710 [5:53:43<5:48:40, 19.21s/it] 36%|███▋      | 622/1710 [5:54:01<5:37:13, 18.60s/it] 36%|███▋      | 623/1710 [5:54:22<5:49:36, 19.30s/it] 36%|███▋      | 624/1710 [5:54:41<5:51:05, 19.40s/it] 37%|███▋      | 625/1710 [5:54:57<5:32:59, 18.41s/it] 37%|███▋      | 626/1710 [5:55:16<5:35:48, 18.59s/it] 37%|███▋      | 627/1710 [5:55:37<5:47:18, 19.24s/it]{'loss': 0.0664, 'learning_rate': 7.800195435154178e-05, 'epoch': 10.18}
{'loss': 0.0799, 'learning_rate': 7.720384794152101e-05, 'epoch': 10.35}
{'loss': 0.0756, 'learning_rate': 7.639577142821164e-05, 'epoch': 10.53}
{'loss': 0.0658, 'learning_rate': 7.557802096847799e-05, 'epoch': 10.7}
{'loss': 0.0826, 'learning_rate': 7.475089626464764e-05, 'epoch': 10.88}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:08<04:25,  4.09s/it][A
  4%|▍         | 3/67 [00:15<05:43,  5.37s/it][A
  6%|▌         | 4/67 [00:25<07:20,  6.99s/it][A
  7%|▋         | 5/67 [00:45<11:56, 11.55s/it][A
  9%|▉         | 6/67 [00:56<11:40, 11.49s/it][A
 10%|█         | 7/67 [01:12<12:47, 12.80s/it][A
 12%|█▏        | 8/67 [01:36<16:15, 16.53s/it][A
 13%|█▎        | 9/67 [01:49<14:53, 15.41s/it][A
 15%|█▍        | 10/67 [01:58<12:50, 13.51s/it][A
 16%|█▋        | 11/67 [02:15<13:37, 14.60s/it][A
 18%|█▊        | 12/67 [02:27<12:27, 13.59s/it][A
 19%|█▉        | 13/67 [02:33<10:07, 11.25s/it][A
 21%|██        | 14/67 [02:40<09:02, 10.24s/it][A
 22%|██▏       | 15/67 [02:56<10:16, 11.86s/it][A
 24%|██▍       | 16/67 [03:02<08:30, 10.01s/it][A
 25%|██▌       | 17/67 [03:22<10:48, 12.98s/it][A
 27%|██▋       | 18/67 [03:35<10:45, 13.18s/it][A
 28%|██▊       | 19/67 [03:51<11:10, 13.96s/it][A
 30%|██▉       | 20/67 [04:00<09:44, 12.44s/it][A
 31%|███▏      | 21/67 [04:27<12:51, 16.78s/it][A
 33%|███▎      | 22/67 [04:43<12:26, 16.60s/it][A
 34%|███▍      | 23/67 [04:51<10:18, 14.06s/it][A
 36%|███▌      | 24/67 [05:10<10:59, 15.34s/it][A
 37%|███▋      | 25/67 [05:27<11:07, 15.88s/it][A
 39%|███▉      | 26/67 [05:39<10:06, 14.80s/it][A
 40%|████      | 27/67 [05:54<09:48, 14.71s/it][A
 42%|████▏     | 28/67 [06:03<08:37, 13.28s/it][A
 43%|████▎     | 29/67 [06:12<07:27, 11.77s/it][A
 45%|████▍     | 30/67 [06:20<06:31, 10.59s/it][A
 46%|████▋     | 31/67 [06:25<05:28,  9.13s/it][A
 48%|████▊     | 32/67 [06:37<05:44,  9.83s/it][A
 49%|████▉     | 33/67 [06:55<06:57, 12.28s/it][A
 51%|█████     | 34/67 [07:06<06:35, 11.99s/it][A
 52%|█████▏    | 35/67 [07:21<06:52, 12.90s/it][A
 54%|█████▎    | 36/67 [07:31<06:10, 11.95s/it][A
 55%|█████▌    | 37/67 [07:37<05:10, 10.34s/it][A
 57%|█████▋    | 38/67 [07:53<05:47, 11.98s/it][A
 58%|█████▊    | 39/67 [08:03<05:13, 11.18s/it][A
 60%|█████▉    | 40/67 [08:11<04:43, 10.51s/it][A
 61%|██████    | 41/67 [08:25<04:58, 11.49s/it][A
 63%|██████▎   | 42/67 [08:40<05:08, 12.34s/it][A
 64%|██████▍   | 43/67 [08:54<05:11, 12.99s/it][A
 66%|██████▌   | 44/67 [09:11<05:28, 14.27s/it][A
 67%|██████▋   | 45/67 [09:19<04:30, 12.27s/it][A
 69%|██████▊   | 46/67 [09:27<03:52, 11.05s/it][A
 70%|███████   | 47/67 [09:40<03:54, 11.70s/it][A
 72%|███████▏  | 48/67 [09:52<03:43, 11.78s/it][A
 73%|███████▎  | 49/67 [10:11<04:07, 13.73s/it][A
 75%|███████▍  | 50/67 [10:28<04:10, 14.72s/it][A
 76%|███████▌  | 51/67 [10:44<04:01, 15.11s/it][A
 78%|███████▊  | 52/67 [10:54<03:24, 13.62s/it][A
 79%|███████▉  | 53/67 [11:02<02:48, 12.06s/it][A
 81%|████████  | 54/67 [11:16<02:42, 12.48s/it][A
 82%|████████▏ | 55/67 [11:31<02:40, 13.35s/it][A
 84%|████████▎ | 56/67 [11:51<02:48, 15.30s/it][A
 85%|████████▌ | 57/67 [12:16<03:01, 18.14s/it][A
 87%|████████▋ | 58/67 [12:56<03:42, 24.68s/it][A
 88%|████████▊ | 59/67 [13:09<02:50, 21.31s/it][A
 90%|████████▉ | 60/67 [13:29<02:25, 20.79s/it][A
 91%|█████████ | 61/67 [13:38<01:44, 17.41s/it][A
 93%|█████████▎| 62/67 [13:47<01:14, 14.92s/it][A
 94%|█████████▍| 63/67 [13:56<00:52, 13.13s/it][A
 96%|█████████▌| 64/67 [14:06<00:35, 11.98s/it][A
 97%|█████████▋| 65/67 [14:14<00:21, 10.96s/it][A
 99%|█████████▊| 66/67 [14:26<00:11, 11.37s/it][A
100%|██████████| 67/67 [14:29<00:00,  8.79s/it][A                                                      
                                               [A 37%|███▋      | 627/1710 [6:10:19<5:47:18, 19.24s/it]
100%|██████████| 67/67 [14:30<00:00,  8.79s/it][A
                                               [A{'f1_1': 0.42319430315361145, 'precision': 0.4147557328015952, 'recall': 0.43198338525441327}
{'f1': 0.3997965412004069, 'precision': 0.3918245264207378, 'recall': 0.40809968847352024}
{'eval_f1': 0.3997965412004069, 'eval_precision': 0.3918245264207378, 'eval_recall': 0.40809968847352024, 'eval_runtime': 882.0583, 'eval_samples_per_second': 0.45, 'eval_steps_per_second': 0.076, 'epoch': 11.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 37%|███▋      | 628/1710 [6:10:40<85:30:31, 284.50s/it] 37%|███▋      | 629/1710 [6:10:57<61:17:33, 204.12s/it] 37%|███▋      | 630/1710 [6:11:16<44:31:44, 148.43s/it]                                                         37%|███▋      | 630/1710 [6:11:16<44:31:44, 148.43s/it] 37%|███▋      | 631/1710 [6:11:34<32:50:35, 109.58s/it] 37%|███▋      | 632/1710 [6:11:51<24:27:09, 81.66s/it]  37%|███▋      | 633/1710 [6:12:14<19:12:35, 64.21s/it] 37%|███▋      | 634/1710 [6:12:39<15:37:06, 52.25s/it] 37%|███▋      | 635/1710 [6:12:59<12:43:35, 42.62s/it] 37%|███▋      | 636/1710 [6:13:21<10:51:00, 36.37s/it] 37%|███▋      | 637/1710 [6:13:39<9:13:05, 30.93s/it]  37%|███▋      | 638/1710 [6:13:57<8:04:51, 27.14s/it] 37%|███▋      | 639/1710 [6:14:16<7:17:49, 24.53s/it] 37%|███▋      | 640/1710 [6:14:41<7:19:27, 24.64s/it]                                                       37%|███▋      | 640/1710 [6:14:41<7:19:27, 24.64s/it] 37%|███▋      | 641/1710 [6:14:59<6:46:14, 22.80s/it] 38%|███▊      | 642/1710 [6:15:16<6:13:41, 20.99s/it] 38%|███▊      | 643/1710 [6:15:41<6:36:14, 22.28s/it] 38%|███▊      | 644/1710 [6:16:00<6:18:20, 21.29s/it] 38%|███▊      | 645/1710 [6:16:21<6:17:19, 21.26s/it] 38%|███▊      | 646/1710 [6:16:40<6:02:44, 20.45s/it] 38%|███▊      | 647/1710 [6:16:57<5:47:10, 19.60s/it] 38%|███▊      | 648/1710 [6:17:15<5:36:44, 19.03s/it] 38%|███▊      | 649/1710 [6:17:36<5:44:16, 19.47s/it] 38%|███▊      | 650/1710 [6:17:54<5:39:55, 19.24s/it]                                                       38%|███▊      | 650/1710 [6:17:54<5:39:55, 19.24s/it] 38%|███▊      | 651/1710 [6:18:14<5:42:19, 19.40s/it] 38%|███▊      | 652/1710 [6:18:34<5:42:47, 19.44s/it] 38%|███▊      | 653/1710 [6:18:53<5:39:06, 19.25s/it] 38%|███▊      | 654/1710 [6:19:09<5:22:20, 18.32s/it] 38%|███▊      | 655/1710 [6:19:27<5:20:31, 18.23s/it] 38%|███▊      | 656/1710 [6:19:46<5:24:27, 18.47s/it] 38%|███▊      | 657/1710 [6:20:02<5:14:13, 17.90s/it] 38%|███▊      | 658/1710 [6:20:19<5:08:22, 17.59s/it] 39%|███▊      | 659/1710 [6:20:37<5:11:53, 17.81s/it] 39%|███▊      | 660/1710 [6:20:54<5:07:19, 17.56s/it]                                                       39%|███▊      | 660/1710 [6:20:54<5:07:19, 17.56s/it] 39%|███▊      | 661/1710 [6:21:11<5:02:00, 17.27s/it] 39%|███▊      | 662/1710 [6:21:29<5:05:16, 17.48s/it] 39%|███▉      | 663/1710 [6:21:46<5:02:06, 17.31s/it] 39%|███▉      | 664/1710 [6:22:06<5:17:55, 18.24s/it] 39%|███▉      | 665/1710 [6:22:26<5:25:49, 18.71s/it] 39%|███▉      | 666/1710 [6:22:49<5:48:15, 20.02s/it] 39%|███▉      | 667/1710 [6:23:09<5:44:44, 19.83s/it] 39%|███▉      | 668/1710 [6:23:29<5:49:24, 20.12s/it] 39%|███▉      | 669/1710 [6:23:50<5:53:46, 20.39s/it] 39%|███▉      | 670/1710 [6:24:09<5:44:58, 19.90s/it]                                                       39%|███▉      | 670/1710 [6:24:09<5:44:58, 19.90s/it] 39%|███▉      | 671/1710 [6:24:26<5:31:02, 19.12s/it] 39%|███▉      | 672/1710 [6:24:43<5:19:36, 18.47s/it] 39%|███▉      | 673/1710 [6:25:01<5:15:40, 18.27s/it] 39%|███▉      | 674/1710 [6:25:23<5:31:27, 19.20s/it] 39%|███▉      | 675/1710 [6:25:42<5:34:19, 19.38s/it] 40%|███▉      | 676/1710 [6:26:04<5:47:48, 20.18s/it] 40%|███▉      | 677/1710 [6:26:27<6:02:02, 21.03s/it] 40%|███▉      | 678/1710 [6:26:46<5:48:47, 20.28s/it] 40%|███▉      | 679/1710 [6:27:03<5:31:19, 19.28s/it] 40%|███▉      | 680/1710 [6:27:21<5:23:25, 18.84s/it]                                                       40%|███▉      | 680/1710 [6:27:21<5:23:25, 18.84s/it] 40%|███▉      | 681/1710 [6:27:40<5:23:46, 18.88s/it] 40%|███▉      | 682/1710 [6:27:57<5:14:34, 18.36s/it] 40%|███▉      | 683/1710 [6:28:19<5:33:49, 19.50s/it] 40%|████      | 684/1710 [6:28:36<5:18:02, 18.60s/it]{'loss': 0.0827, 'learning_rate': 7.391470045467179e-05, 'epoch': 11.05}
{'loss': 0.0462, 'learning_rate': 7.306974000102636e-05, 'epoch': 11.23}
{'loss': 0.0662, 'learning_rate': 7.221632457839473e-05, 'epoch': 11.4}
{'loss': 0.0445, 'learning_rate': 7.135476696017314e-05, 'epoch': 11.58}
{'loss': 0.07, 'learning_rate': 7.048538290384051e-05, 'epoch': 11.75}
{'loss': 0.0622, 'learning_rate': 6.960849103523454e-05, 'epoch': 11.93}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:08<04:23,  4.05s/it][A
  4%|▍         | 3/67 [00:15<05:45,  5.39s/it][A
  6%|▌         | 4/67 [00:21<06:00,  5.73s/it][A
  7%|▋         | 5/67 [00:36<09:11,  8.90s/it][A
  9%|▉         | 6/67 [00:48<10:08,  9.98s/it][A
 10%|█         | 7/67 [00:57<09:32,  9.54s/it][A
 12%|█▏        | 8/67 [01:21<14:03, 14.29s/it][A
 13%|█▎        | 9/67 [01:35<13:28, 13.94s/it][A
 15%|█▍        | 10/67 [01:44<11:51, 12.48s/it][A
 16%|█▋        | 11/67 [02:01<13:05, 14.03s/it][A
 18%|█▊        | 12/67 [02:11<11:31, 12.57s/it][A
 19%|█▉        | 13/67 [02:16<09:28, 10.53s/it][A
 21%|██        | 14/67 [02:26<08:57, 10.15s/it][A
 22%|██▏       | 15/67 [02:42<10:18, 11.90s/it][A
 24%|██▍       | 16/67 [02:49<08:52, 10.44s/it][A
 25%|██▌       | 17/67 [03:13<12:14, 14.69s/it][A
 27%|██▋       | 18/67 [03:26<11:29, 14.08s/it][A
 28%|██▊       | 19/67 [03:39<10:59, 13.75s/it][A
 30%|██▉       | 20/67 [03:49<09:59, 12.75s/it][A
 31%|███▏      | 21/67 [04:07<10:56, 14.28s/it][A
 33%|███▎      | 22/67 [04:19<10:14, 13.65s/it][A
 34%|███▍      | 23/67 [04:27<08:46, 11.95s/it][A
 36%|███▌      | 24/67 [04:54<11:38, 16.25s/it][A
 37%|███▋      | 25/67 [05:03<10:00, 14.31s/it][A
 39%|███▉      | 26/67 [05:13<08:48, 12.90s/it][A
 40%|████      | 27/67 [05:24<08:17, 12.43s/it][A
 42%|████▏     | 28/67 [05:36<08:00, 12.32s/it][A
 43%|████▎     | 29/67 [05:44<06:57, 11.00s/it][A
 45%|████▍     | 30/67 [05:51<06:04,  9.85s/it][A
 46%|████▋     | 31/67 [05:57<05:09,  8.60s/it][A
 48%|████▊     | 32/67 [06:06<05:00,  8.59s/it][A
 49%|████▉     | 33/67 [06:24<06:26, 11.36s/it][A
 51%|█████     | 34/67 [06:34<06:02, 10.98s/it][A
 52%|█████▏    | 35/67 [06:45<05:55, 11.12s/it][A
 54%|█████▎    | 36/67 [06:53<05:19, 10.30s/it][A
 55%|█████▌    | 37/67 [06:58<04:17,  8.58s/it][A
 57%|█████▋    | 38/67 [07:08<04:21,  9.01s/it][A
 58%|█████▊    | 39/67 [07:17<04:14,  9.08s/it][A
 60%|█████▉    | 40/67 [07:27<04:07,  9.15s/it][A
 61%|██████    | 41/67 [07:39<04:20, 10.01s/it][A
 63%|██████▎   | 42/67 [07:51<04:27, 10.69s/it][A
 64%|██████▍   | 43/67 [08:08<05:00, 12.53s/it][A
 66%|██████▌   | 44/67 [08:18<04:36, 12.01s/it][A
 67%|██████▋   | 45/67 [08:23<03:38,  9.91s/it][A
 69%|██████▊   | 46/67 [08:32<03:18,  9.44s/it][A
 70%|███████   | 47/67 [08:44<03:23, 10.18s/it][A
 72%|███████▏  | 48/67 [08:53<03:06,  9.82s/it][A
 73%|███████▎  | 49/67 [09:11<03:41, 12.32s/it][A
 75%|███████▍  | 50/67 [09:22<03:20, 11.81s/it][A
 76%|███████▌  | 51/67 [09:31<02:57, 11.08s/it][A
 78%|███████▊  | 52/67 [09:44<02:54, 11.64s/it][A
 79%|███████▉  | 53/67 [09:57<02:48, 12.02s/it][A
 81%|████████  | 54/67 [10:03<02:15, 10.39s/it][A
 82%|████████▏ | 55/67 [10:18<02:20, 11.73s/it][A
 84%|████████▎ | 56/67 [10:29<02:07, 11.57s/it][A
 85%|████████▌ | 57/67 [10:52<02:28, 14.85s/it][A
 87%|████████▋ | 58/67 [11:04<02:06, 14.07s/it][A
 88%|████████▊ | 59/67 [11:17<01:49, 13.66s/it][A
 90%|████████▉ | 60/67 [11:32<01:37, 13.99s/it][A
 91%|█████████ | 61/67 [11:41<01:15, 12.64s/it][A
 93%|█████████▎| 62/67 [11:49<00:55, 11.12s/it][A
 94%|█████████▍| 63/67 [11:57<00:41, 10.29s/it][A
 96%|█████████▌| 64/67 [12:06<00:29,  9.96s/it][A
 97%|█████████▋| 65/67 [12:13<00:17,  9.00s/it][A
 99%|█████████▊| 66/67 [12:25<00:09,  9.96s/it][A
100%|██████████| 67/67 [12:27<00:00,  7.49s/it][A                                                      
                                               [A 40%|████      | 684/1710 [6:41:13<5:18:02, 18.60s/it]
100%|██████████| 67/67 [12:28<00:00,  7.49s/it][A
                                               [A{'f1_1': 0.4101433296582139, 'precision': 0.4371327849588719, 'recall': 0.3862928348909657}
{'f1': 0.3803748621830209, 'precision': 0.40540540540540543, 'recall': 0.3582554517133956}
{'eval_f1': 0.3803748621830209, 'eval_precision': 0.40540540540540543, 'eval_recall': 0.3582554517133956, 'eval_runtime': 757.8934, 'eval_samples_per_second': 0.524, 'eval_steps_per_second': 0.088, 'epoch': 12.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 40%|████      | 685/1710 [6:41:33<70:07:26, 246.29s/it] 40%|████      | 686/1710 [6:41:49<50:23:38, 177.17s/it] 40%|████      | 687/1710 [6:42:09<36:56:39, 130.01s/it] 40%|████      | 688/1710 [6:42:27<27:24:56, 96.57s/it]  40%|████      | 689/1710 [6:42:47<20:51:17, 73.53s/it] 40%|████      | 690/1710 [6:43:04<16:02:49, 56.64s/it]                                                        40%|████      | 690/1710 [6:43:04<16:02:49, 56.64s/it] 40%|████      | 691/1710 [6:43:23<12:48:43, 45.26s/it] 40%|████      | 692/1710 [6:43:48<11:02:24, 39.04s/it] 41%|████      | 693/1710 [6:44:08<9:27:13, 33.46s/it]  41%|████      | 694/1710 [6:44:27<8:13:55, 29.17s/it] 41%|████      | 695/1710 [6:44:42<7:02:02, 24.95s/it] 41%|████      | 696/1710 [6:45:00<6:23:13, 22.68s/it] 41%|████      | 697/1710 [6:45:20<6:11:18, 21.99s/it] 41%|████      | 698/1710 [6:45:39<5:55:31, 21.08s/it] 41%|████      | 699/1710 [6:45:58<5:42:35, 20.33s/it] 41%|████      | 700/1710 [6:46:16<5:31:23, 19.69s/it]                                                       41%|████      | 700/1710 [6:46:16<5:31:23, 19.69s/it] 41%|████      | 701/1710 [6:46:42<6:02:40, 21.57s/it] 41%|████      | 702/1710 [6:47:01<5:48:29, 20.74s/it] 41%|████      | 703/1710 [6:47:19<5:37:32, 20.11s/it] 41%|████      | 704/1710 [6:47:38<5:31:47, 19.79s/it] 41%|████      | 705/1710 [6:47:57<5:23:36, 19.32s/it] 41%|████▏     | 706/1710 [6:48:17<5:30:19, 19.74s/it] 41%|████▏     | 707/1710 [6:48:37<5:27:35, 19.60s/it] 41%|████▏     | 708/1710 [6:48:57<5:31:58, 19.88s/it] 41%|████▏     | 709/1710 [6:49:17<5:33:35, 20.00s/it] 42%|████▏     | 710/1710 [6:49:35<5:20:05, 19.21s/it]                                                       42%|████▏     | 710/1710 [6:49:35<5:20:05, 19.21s/it] 42%|████▏     | 711/1710 [6:50:00<5:48:38, 20.94s/it] 42%|████▏     | 712/1710 [6:50:17<5:27:42, 19.70s/it] 42%|████▏     | 713/1710 [6:50:33<5:11:20, 18.74s/it] 42%|████▏     | 714/1710 [6:50:53<5:17:20, 19.12s/it] 42%|████▏     | 715/1710 [6:51:16<5:38:22, 20.40s/it] 42%|████▏     | 716/1710 [6:51:41<5:56:14, 21.50s/it] 42%|████▏     | 717/1710 [6:51:56<5:25:21, 19.66s/it] 42%|████▏     | 718/1710 [6:52:13<5:11:25, 18.84s/it] 42%|████▏     | 719/1710 [6:52:32<5:13:48, 19.00s/it] 42%|████▏     | 720/1710 [6:52:54<5:27:56, 19.88s/it]                                                       42%|████▏     | 720/1710 [6:52:54<5:27:56, 19.88s/it] 42%|████▏     | 721/1710 [6:53:16<5:37:13, 20.46s/it] 42%|████▏     | 722/1710 [6:53:34<5:25:53, 19.79s/it] 42%|████▏     | 723/1710 [6:53:50<5:06:40, 18.64s/it] 42%|████▏     | 724/1710 [6:54:10<5:10:49, 18.91s/it] 42%|████▏     | 725/1710 [6:54:30<5:16:48, 19.30s/it] 42%|████▏     | 726/1710 [6:54:51<5:26:11, 19.89s/it] 43%|████▎     | 727/1710 [6:55:10<5:21:55, 19.65s/it] 43%|████▎     | 728/1710 [6:55:30<5:22:29, 19.70s/it] 43%|████▎     | 729/1710 [6:55:47<5:09:32, 18.93s/it] 43%|████▎     | 730/1710 [6:56:06<5:08:41, 18.90s/it]                                                       43%|████▎     | 730/1710 [6:56:06<5:08:41, 18.90s/it] 43%|████▎     | 731/1710 [6:56:24<5:06:25, 18.78s/it] 43%|████▎     | 732/1710 [6:56:44<5:09:20, 18.98s/it] 43%|████▎     | 733/1710 [6:57:00<4:56:24, 18.20s/it] 43%|████▎     | 734/1710 [6:57:21<5:07:06, 18.88s/it] 43%|████▎     | 735/1710 [6:57:38<4:59:43, 18.44s/it] 43%|████▎     | 736/1710 [6:57:59<5:11:27, 19.19s/it] 43%|████▎     | 737/1710 [6:58:16<4:58:02, 18.38s/it] 43%|████▎     | 738/1710 [6:58:34<4:58:34, 18.43s/it] 43%|████▎     | 739/1710 [6:58:54<5:07:13, 18.98s/it] 43%|████▎     | 740/1710 [6:59:11<4:54:48, 18.24s/it]                                                       43%|████▎     | 740/1710 [6:59:11<4:54:48, 18.24s/it] 43%|████▎     | 741/1710 [6:59:32<5:06:34, 18.98s/it]{'loss': 0.048, 'learning_rate': 6.87244127317766e-05, 'epoch': 12.11}
{'loss': 0.0425, 'learning_rate': 6.783347200468817e-05, 'epoch': 12.28}
{'loss': 0.0442, 'learning_rate': 6.693599538024204e-05, 'epoch': 12.46}
{'loss': 0.0367, 'learning_rate': 6.603231178009162e-05, 'epoch': 12.63}
{'loss': 0.0535, 'learning_rate': 6.512275240072253e-05, 'epoch': 12.81}
{'loss': 0.0369, 'learning_rate': 6.42076505920704e-05, 'epoch': 12.98}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:46,  5.32s/it][A
  4%|▍         | 3/67 [00:15<05:27,  5.12s/it][A
  6%|▌         | 4/67 [00:22<06:17,  5.99s/it][A
  7%|▋         | 5/67 [00:38<09:42,  9.40s/it][A
  9%|▉         | 6/67 [00:54<11:32, 11.35s/it][A
 10%|█         | 7/67 [01:07<11:57, 11.95s/it][A
 12%|█▏        | 8/67 [01:29<15:01, 15.27s/it][A
 13%|█▎        | 9/67 [01:48<15:50, 16.38s/it][A
 15%|█▍        | 10/67 [01:57<13:28, 14.18s/it][A
 16%|█▋        | 11/67 [02:15<14:07, 15.13s/it][A
 18%|█▊        | 12/67 [02:22<11:40, 12.73s/it][A
 19%|█▉        | 13/67 [02:28<09:34, 10.64s/it][A
 21%|██        | 14/67 [02:37<09:09, 10.37s/it][A
 22%|██▏       | 15/67 [02:53<10:20, 11.93s/it][A
 24%|██▍       | 16/67 [02:59<08:32, 10.04s/it][A
 25%|██▌       | 17/67 [03:18<10:49, 12.99s/it][A
 27%|██▋       | 18/67 [03:28<09:42, 11.88s/it][A
 28%|██▊       | 19/67 [03:40<09:43, 12.15s/it][A
 30%|██▉       | 20/67 [03:49<08:44, 11.16s/it][A
 31%|███▏      | 21/67 [04:16<12:08, 15.83s/it][A
 33%|███▎      | 22/67 [04:32<11:58, 15.98s/it][A
 34%|███▍      | 23/67 [04:40<09:55, 13.55s/it][A
 36%|███▌      | 24/67 [05:07<12:29, 17.43s/it][A
 37%|███▋      | 25/67 [05:24<12:07, 17.33s/it][A
 39%|███▉      | 26/67 [05:32<09:57, 14.58s/it][A
 40%|████      | 27/67 [05:45<09:22, 14.07s/it][A
 42%|████▏     | 28/67 [05:53<08:02, 12.36s/it][A
 43%|████▎     | 29/67 [05:59<06:36, 10.44s/it][A
 45%|████▍     | 30/67 [06:04<05:26,  8.82s/it][A
 46%|████▋     | 31/67 [06:08<04:25,  7.38s/it][A
 48%|████▊     | 32/67 [06:17<04:35,  7.88s/it][A
 49%|████▉     | 33/67 [06:35<06:06, 10.79s/it][A
 51%|█████     | 34/67 [06:46<05:59, 10.89s/it][A
 52%|█████▏    | 35/67 [06:58<05:56, 11.13s/it][A
 54%|█████▎    | 36/67 [07:05<05:09,  9.98s/it][A
 55%|█████▌    | 37/67 [07:10<04:10,  8.34s/it][A
 57%|█████▋    | 38/67 [07:19<04:15,  8.79s/it][A
 58%|█████▊    | 39/67 [07:31<04:31,  9.71s/it][A
 60%|█████▉    | 40/67 [07:39<04:04,  9.06s/it][A
 61%|██████    | 41/67 [07:55<04:52, 11.25s/it][A
 63%|██████▎   | 42/67 [08:09<05:02, 12.11s/it][A
 64%|██████▍   | 43/67 [08:21<04:45, 11.91s/it][A
 66%|██████▌   | 44/67 [08:32<04:32, 11.87s/it][A
 67%|██████▋   | 45/67 [08:37<03:35,  9.81s/it][A
 69%|██████▊   | 46/67 [08:46<03:14,  9.28s/it][A
 70%|███████   | 47/67 [09:00<03:34, 10.70s/it][A
 72%|███████▏  | 48/67 [09:11<03:28, 11.00s/it][A
 73%|███████▎  | 49/67 [09:29<03:56, 13.13s/it][A
 75%|███████▍  | 50/67 [09:42<03:42, 13.09s/it][A
 76%|███████▌  | 51/67 [09:58<03:40, 13.76s/it][A
 78%|███████▊  | 52/67 [10:10<03:18, 13.20s/it][A
 79%|███████▉  | 53/67 [10:18<02:44, 11.73s/it][A
 81%|████████  | 54/67 [10:29<02:31, 11.67s/it][A
 82%|████████▏ | 55/67 [10:46<02:36, 13.07s/it][A
 84%|████████▎ | 56/67 [11:05<02:44, 14.98s/it][A
 85%|████████▌ | 57/67 [11:35<03:13, 19.39s/it][A
 87%|████████▋ | 58/67 [11:57<03:01, 20.11s/it][A
 88%|████████▊ | 59/67 [12:12<02:29, 18.65s/it][A
 90%|████████▉ | 60/67 [12:31<02:11, 18.86s/it][A
 91%|█████████ | 61/67 [12:41<01:36, 16.02s/it][A
 93%|█████████▎| 62/67 [12:52<01:13, 14.61s/it][A
 94%|█████████▍| 63/67 [13:02<00:52, 13.16s/it][A
 96%|█████████▌| 64/67 [13:13<00:37, 12.45s/it][A
 97%|█████████▋| 65/67 [13:17<00:20, 10.10s/it][A
 99%|█████████▊| 66/67 [13:29<00:10, 10.77s/it][A
100%|██████████| 67/67 [13:31<00:00,  8.07s/it][A                                                      
                                               [A 43%|████▎     | 741/1710 [7:13:20<5:06:34, 18.98s/it]
100%|██████████| 67/67 [13:32<00:00,  8.07s/it][A
                                               [A{'f1_1': 0.4299889746416759, 'precision': 0.4582843713278496, 'recall': 0.40498442367601245}
{'f1': 0.412348401323043, 'precision': 0.4394829612220917, 'recall': 0.3883696780893043}
{'eval_f1': 0.412348401323043, 'eval_precision': 0.4394829612220917, 'eval_recall': 0.3883696780893043, 'eval_runtime': 828.0381, 'eval_samples_per_second': 0.479, 'eval_steps_per_second': 0.081, 'epoch': 13.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 43%|████▎     | 742/1710 [7:13:44<72:21:18, 269.09s/it] 43%|████▎     | 743/1710 [7:14:05<52:15:14, 194.53s/it] 44%|████▎     | 744/1710 [7:14:22<37:56:59, 141.43s/it] 44%|████▎     | 745/1710 [7:14:44<28:16:03, 105.45s/it] 44%|████▎     | 746/1710 [7:15:03<21:18:17, 79.56s/it]  44%|████▎     | 747/1710 [7:15:19<16:11:14, 60.51s/it] 44%|████▎     | 748/1710 [7:15:35<12:36:17, 47.17s/it] 44%|████▍     | 749/1710 [7:15:55<10:23:03, 38.90s/it] 44%|████▍     | 750/1710 [7:16:12<8:36:39, 32.29s/it]                                                        44%|████▍     | 750/1710 [7:16:12<8:36:39, 32.29s/it] 44%|████▍     | 751/1710 [7:16:35<7:54:05, 29.66s/it] 44%|████▍     | 752/1710 [7:16:52<6:54:24, 25.95s/it] 44%|████▍     | 753/1710 [7:17:08<6:04:26, 22.85s/it] 44%|████▍     | 754/1710 [7:17:25<5:37:46, 21.20s/it] 44%|████▍     | 755/1710 [7:17:43<5:21:22, 20.19s/it] 44%|████▍     | 756/1710 [7:18:01<5:07:00, 19.31s/it] 44%|████▍     | 757/1710 [7:18:20<5:06:05, 19.27s/it] 44%|████▍     | 758/1710 [7:18:37<4:58:40, 18.82s/it] 44%|████▍     | 759/1710 [7:18:59<5:12:44, 19.73s/it] 44%|████▍     | 760/1710 [7:19:25<5:39:04, 21.41s/it]                                                       44%|████▍     | 760/1710 [7:19:25<5:39:04, 21.41s/it] 45%|████▍     | 761/1710 [7:19:52<6:06:02, 23.14s/it] 45%|████▍     | 762/1710 [7:20:11<5:47:06, 21.97s/it] 45%|████▍     | 763/1710 [7:20:36<5:59:35, 22.78s/it] 45%|████▍     | 764/1710 [7:20:55<5:42:49, 21.74s/it] 45%|████▍     | 765/1710 [7:21:16<5:36:42, 21.38s/it] 45%|████▍     | 766/1710 [7:21:36<5:31:46, 21.09s/it] 45%|████▍     | 767/1710 [7:21:54<5:19:06, 20.30s/it] 45%|████▍     | 768/1710 [7:22:19<5:38:42, 21.57s/it] 45%|████▍     | 769/1710 [7:22:39<5:28:28, 20.94s/it] 45%|████▌     | 770/1710 [7:22:58<5:19:00, 20.36s/it]                                                       45%|████▌     | 770/1710 [7:22:58<5:19:00, 20.36s/it] 45%|████▌     | 771/1710 [7:23:18<5:18:41, 20.36s/it] 45%|████▌     | 772/1710 [7:23:37<5:11:14, 19.91s/it] 45%|████▌     | 773/1710 [7:23:56<5:08:31, 19.76s/it] 45%|████▌     | 774/1710 [7:24:14<5:00:42, 19.28s/it] 45%|████▌     | 775/1710 [7:24:31<4:49:40, 18.59s/it] 45%|████▌     | 776/1710 [7:24:52<4:57:23, 19.10s/it] 45%|████▌     | 777/1710 [7:25:10<4:52:26, 18.81s/it] 45%|████▌     | 778/1710 [7:25:28<4:49:47, 18.66s/it] 46%|████▌     | 779/1710 [7:25:46<4:47:03, 18.50s/it] 46%|████▌     | 780/1710 [7:26:04<4:45:03, 18.39s/it]                                                       46%|████▌     | 780/1710 [7:26:04<4:45:03, 18.39s/it] 46%|████▌     | 781/1710 [7:26:26<5:01:13, 19.45s/it] 46%|████▌     | 782/1710 [7:26:43<4:46:58, 18.55s/it] 46%|████▌     | 783/1710 [7:27:00<4:41:40, 18.23s/it] 46%|████▌     | 784/1710 [7:27:20<4:46:56, 18.59s/it] 46%|████▌     | 785/1710 [7:27:37<4:41:38, 18.27s/it] 46%|████▌     | 786/1710 [7:27:56<4:45:59, 18.57s/it] 46%|████▌     | 787/1710 [7:28:16<4:51:07, 18.92s/it] 46%|████▌     | 788/1710 [7:28:33<4:41:36, 18.33s/it] 46%|████▌     | 789/1710 [7:28:53<4:48:30, 18.80s/it] 46%|████▌     | 790/1710 [7:29:11<4:44:43, 18.57s/it]                                                       46%|████▌     | 790/1710 [7:29:11<4:44:43, 18.57s/it] 46%|████▋     | 791/1710 [7:29:28<4:38:04, 18.16s/it] 46%|████▋     | 792/1710 [7:29:46<4:36:42, 18.09s/it] 46%|████▋     | 793/1710 [7:30:06<4:45:27, 18.68s/it] 46%|████▋     | 794/1710 [7:30:23<4:34:43, 18.00s/it] 46%|████▋     | 795/1710 [7:30:42<4:39:26, 18.32s/it] 47%|████▋     | 796/1710 [7:31:03<4:51:05, 19.11s/it] 47%|████▋     | 797/1710 [7:31:21<4:47:10, 18.87s/it] 47%|████▋     | 798/1710 [7:31:42<4:55:13, 19.42s/it]{'loss': 0.0398, 'learning_rate': 6.328734173534933e-05, 'epoch': 13.16}
{'loss': 0.0328, 'learning_rate': 6.236216312013614e-05, 'epoch': 13.33}
{'loss': 0.0352, 'learning_rate': 6.143245382075492e-05, 'epoch': 13.51}
{'loss': 0.0401, 'learning_rate': 6.0498554572007724e-05, 'epoch': 13.68}
{'loss': 0.0334, 'learning_rate': 5.956080764429653e-05, 'epoch': 13.86}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:09<05:22,  4.97s/it][A
  4%|▍         | 3/67 [00:14<05:14,  4.91s/it][A
  6%|▌         | 4/67 [00:22<06:09,  5.87s/it][A
  7%|▋         | 5/67 [00:40<10:41, 10.34s/it][A
  9%|▉         | 6/67 [00:56<12:12, 12.01s/it][A
 10%|█         | 7/67 [01:09<12:24, 12.40s/it][A
 12%|█▏        | 8/67 [01:35<16:18, 16.58s/it][A
 13%|█▎        | 9/67 [01:50<15:29, 16.03s/it][A
 15%|█▍        | 10/67 [01:59<13:16, 13.97s/it][A
 16%|█▋        | 11/67 [02:12<12:40, 13.58s/it][A
 18%|█▊        | 12/67 [02:20<11:00, 12.01s/it][A
 19%|█▉        | 13/67 [02:27<09:29, 10.55s/it][A
 21%|██        | 14/67 [02:52<13:11, 14.93s/it][A
 22%|██▏       | 15/67 [03:08<13:08, 15.16s/it][A
 24%|██▍       | 16/67 [03:14<10:31, 12.37s/it][A
 25%|██▌       | 17/67 [03:34<12:12, 14.66s/it][A
 27%|██▋       | 18/67 [03:45<11:11, 13.71s/it][A
 28%|██▊       | 19/67 [03:58<10:46, 13.47s/it][A
 30%|██▉       | 20/67 [04:11<10:20, 13.20s/it][A
 31%|███▏      | 21/67 [04:29<11:12, 14.63s/it][A
 33%|███▎      | 22/67 [04:48<12:00, 16.00s/it][A
 34%|███▍      | 23/67 [04:57<10:12, 13.93s/it][A
 36%|███▌      | 24/67 [05:15<10:54, 15.22s/it][A
 37%|███▋      | 25/67 [05:34<11:20, 16.20s/it][A
 39%|███▉      | 26/67 [05:42<09:27, 13.84s/it][A
 40%|████      | 27/67 [05:57<09:20, 14.02s/it][A
 42%|████▏     | 28/67 [06:13<09:41, 14.90s/it][A
 43%|████▎     | 29/67 [06:23<08:20, 13.18s/it][A
 45%|████▍     | 30/67 [06:29<06:55, 11.22s/it][A
 46%|████▋     | 31/67 [06:35<05:45,  9.59s/it][A
 48%|████▊     | 32/67 [06:50<06:31, 11.18s/it][A
 49%|████▉     | 33/67 [07:12<08:15, 14.57s/it][A
 51%|█████     | 34/67 [07:24<07:28, 13.58s/it][A
 52%|█████▏    | 35/67 [07:42<08:00, 15.01s/it][A
 54%|█████▎    | 36/67 [07:55<07:27, 14.42s/it][A
 55%|█████▌    | 37/67 [08:03<06:15, 12.50s/it][A
 57%|█████▋    | 38/67 [08:22<06:59, 14.47s/it][A
 58%|█████▊    | 39/67 [08:36<06:41, 14.35s/it][A
 60%|█████▉    | 40/67 [08:47<05:58, 13.29s/it][A
 61%|██████    | 41/67 [09:02<05:59, 13.85s/it][A
 63%|██████▎   | 42/67 [09:18<06:02, 14.51s/it][A
 64%|██████▍   | 43/67 [09:34<05:57, 14.89s/it][A
 66%|██████▌   | 44/67 [09:48<05:36, 14.65s/it][A
 67%|██████▋   | 45/67 [09:53<04:18, 11.75s/it][A
 69%|██████▊   | 46/67 [10:01<03:43, 10.66s/it][A
 70%|███████   | 47/67 [10:29<05:14, 15.72s/it][A
 72%|███████▏  | 48/67 [10:39<04:29, 14.20s/it][A
 73%|███████▎  | 49/67 [10:57<04:36, 15.35s/it][A
 75%|███████▍  | 50/67 [11:14<04:28, 15.77s/it][A
 76%|███████▌  | 51/67 [11:27<03:56, 14.81s/it][A
 78%|███████▊  | 52/67 [11:40<03:34, 14.27s/it][A
 79%|███████▉  | 53/67 [11:53<03:13, 13.83s/it][A
 81%|████████  | 54/67 [12:04<02:50, 13.13s/it][A
 82%|████████▏ | 55/67 [12:15<02:28, 12.40s/it][A
 84%|████████▎ | 56/67 [12:34<02:39, 14.51s/it][A
 85%|████████▌ | 57/67 [13:07<03:18, 19.86s/it][A
 87%|████████▋ | 58/67 [13:37<03:27, 23.01s/it][A
 88%|████████▊ | 59/67 [13:52<02:44, 20.60s/it][A
 90%|████████▉ | 60/67 [14:11<02:21, 20.22s/it][A
 91%|█████████ | 61/67 [14:21<01:43, 17.19s/it][A
 93%|█████████▎| 62/67 [14:30<01:13, 14.62s/it][A
 94%|█████████▍| 63/67 [14:42<00:54, 13.69s/it][A
 96%|█████████▌| 64/67 [14:51<00:37, 12.34s/it][A
 97%|█████████▋| 65/67 [14:57<00:20, 10.46s/it][A
 99%|█████████▊| 66/67 [15:13<00:12, 12.31s/it][A
100%|██████████| 67/67 [15:16<00:00,  9.43s/it][A                                                      
                                               [A 47%|████▋     | 798/1710 [7:47:14<4:55:13, 19.42s/it]
100%|██████████| 67/67 [15:17<00:00,  9.43s/it][A
                                               [A{'f1_1': 0.42418032786885246, 'precision': 0.4186046511627907, 'recall': 0.42990654205607476}
{'f1': 0.40471311475409844, 'precision': 0.3993933265925177, 'recall': 0.4101765316718588}
{'eval_f1': 0.40471311475409844, 'eval_precision': 0.3993933265925177, 'eval_recall': 0.4101765316718588, 'eval_runtime': 932.0806, 'eval_samples_per_second': 0.426, 'eval_steps_per_second': 0.072, 'epoch': 14.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 47%|████▋     | 799/1710 [7:47:36<75:53:33, 299.90s/it] 47%|████▋     | 800/1710 [7:47:53<54:20:50, 215.00s/it]                                                         47%|████▋     | 800/1710 [7:47:53<54:20:50, 215.00s/it] 47%|████▋     | 801/1710 [7:48:12<39:27:26, 156.27s/it] 47%|████▋     | 802/1710 [7:48:32<29:04:20, 115.26s/it] 47%|████▋     | 803/1710 [7:48:57<22:12:57, 88.18s/it]  47%|████▋     | 804/1710 [7:49:14<16:49:58, 66.89s/it] 47%|████▋     | 805/1710 [7:49:32<13:07:39, 52.22s/it] 47%|████▋     | 806/1710 [7:49:49<10:29:59, 41.81s/it] 47%|████▋     | 807/1710 [7:50:06<8:37:38, 34.39s/it]  47%|████▋     | 808/1710 [7:50:27<7:34:38, 30.24s/it] 47%|████▋     | 809/1710 [7:50:47<6:46:56, 27.10s/it] 47%|████▋     | 810/1710 [7:51:16<6:54:11, 27.61s/it]                                                       47%|████▋     | 810/1710 [7:51:16<6:54:11, 27.61s/it] 47%|████▋     | 811/1710 [7:51:34<6:10:58, 24.76s/it] 47%|████▋     | 812/1710 [7:51:57<6:02:46, 24.24s/it] 48%|████▊     | 813/1710 [7:52:15<5:37:24, 22.57s/it] 48%|████▊     | 814/1710 [7:52:35<5:22:50, 21.62s/it] 48%|████▊     | 815/1710 [7:52:54<5:13:26, 21.01s/it] 48%|████▊     | 816/1710 [7:53:11<4:51:30, 19.56s/it] 48%|████▊     | 817/1710 [7:53:26<4:34:24, 18.44s/it] 48%|████▊     | 818/1710 [7:53:45<4:35:30, 18.53s/it] 48%|████▊     | 819/1710 [7:54:10<5:04:39, 20.52s/it] 48%|████▊     | 820/1710 [7:54:28<4:51:25, 19.65s/it]                                                       48%|████▊     | 820/1710 [7:54:28<4:51:25, 19.65s/it] 48%|████▊     | 821/1710 [7:54:52<5:09:09, 20.87s/it] 48%|████▊     | 822/1710 [7:55:12<5:08:50, 20.87s/it] 48%|████▊     | 823/1710 [7:55:31<4:58:06, 20.16s/it] 48%|████▊     | 824/1710 [7:55:48<4:44:29, 19.27s/it] 48%|████▊     | 825/1710 [7:56:06<4:37:04, 18.78s/it] 48%|████▊     | 826/1710 [7:56:33<5:13:38, 21.29s/it] 48%|████▊     | 827/1710 [7:56:56<5:22:12, 21.89s/it] 48%|████▊     | 828/1710 [7:57:16<5:10:06, 21.10s/it] 48%|████▊     | 829/1710 [7:57:37<5:11:19, 21.20s/it] 49%|████▊     | 830/1710 [7:57:55<4:55:00, 20.11s/it]                                                       49%|████▊     | 830/1710 [7:57:55<4:55:00, 20.11s/it] 49%|████▊     | 831/1710 [7:58:16<4:58:54, 20.40s/it] 49%|████▊     | 832/1710 [7:58:34<4:50:23, 19.84s/it] 49%|████▊     | 833/1710 [7:58:55<4:55:25, 20.21s/it] 49%|████▉     | 834/1710 [7:59:14<4:46:58, 19.66s/it] 49%|████▉     | 835/1710 [7:59:30<4:31:13, 18.60s/it] 49%|████▉     | 836/1710 [7:59:48<4:28:47, 18.45s/it] 49%|████▉     | 837/1710 [8:00:04<4:17:13, 17.68s/it] 49%|████▉     | 838/1710 [8:00:24<4:30:03, 18.58s/it] 49%|████▉     | 839/1710 [8:00:40<4:18:52, 17.83s/it] 49%|████▉     | 840/1710 [8:00:58<4:18:58, 17.86s/it]                                                       49%|████▉     | 840/1710 [8:00:58<4:18:58, 17.86s/it] 49%|████▉     | 841/1710 [8:01:21<4:37:45, 19.18s/it] 49%|████▉     | 842/1710 [8:01:40<4:36:26, 19.11s/it] 49%|████▉     | 843/1710 [8:02:01<4:46:09, 19.80s/it] 49%|████▉     | 844/1710 [8:02:19<4:35:56, 19.12s/it] 49%|████▉     | 845/1710 [8:02:35<4:25:41, 18.43s/it] 49%|████▉     | 846/1710 [8:02:59<4:46:07, 19.87s/it] 50%|████▉     | 847/1710 [8:03:21<4:54:51, 20.50s/it] 50%|████▉     | 848/1710 [8:03:38<4:39:51, 19.48s/it] 50%|████▉     | 849/1710 [8:03:56<4:36:10, 19.25s/it] 50%|████▉     | 850/1710 [8:04:16<4:37:03, 19.33s/it]                                                       50%|████▉     | 850/1710 [8:04:16<4:37:03, 19.33s/it] 50%|████▉     | 851/1710 [8:04:35<4:34:26, 19.17s/it] 50%|████▉     | 852/1710 [8:04:52<4:25:18, 18.55s/it] 50%|████▉     | 853/1710 [8:05:08<4:13:03, 17.72s/it] 50%|████▉     | 854/1710 [8:05:24<4:06:17, 17.26s/it] 50%|█████     | 855/1710 [8:05:41<4:04:35, 17.16s/it]{'loss': 0.0274, 'learning_rate': 5.861955671818259e-05, 'epoch': 14.04}
{'loss': 0.0235, 'learning_rate': 5.767514675842875e-05, 'epoch': 14.21}
{'loss': 0.0238, 'learning_rate': 5.6727923887571265e-05, 'epoch': 14.39}
{'loss': 0.0245, 'learning_rate': 5.5778235259067246e-05, 'epoch': 14.56}
{'loss': 0.016, 'learning_rate': 5.482642893006431e-05, 'epoch': 14.74}
{'loss': 0.021, 'learning_rate': 5.387285373383892e-05, 'epoch': 14.91}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:41,  5.26s/it][A
  4%|▍         | 3/67 [00:15<05:24,  5.07s/it][A
  6%|▌         | 4/67 [00:21<05:44,  5.47s/it][A
  7%|▋         | 5/67 [00:32<07:34,  7.33s/it][A
  9%|▉         | 6/67 [00:42<08:24,  8.27s/it][A
 10%|█         | 7/67 [00:57<10:30, 10.51s/it][A
 12%|█▏        | 8/67 [01:19<13:58, 14.22s/it][A
 13%|█▎        | 9/67 [01:25<11:10, 11.55s/it][A
 15%|█▍        | 10/67 [01:34<10:16, 10.82s/it][A
 16%|█▋        | 11/67 [01:50<11:23, 12.21s/it][A
 18%|█▊        | 12/67 [01:58<10:06, 11.02s/it][A
 19%|█▉        | 13/67 [02:04<08:28,  9.42s/it][A
 21%|██        | 14/67 [02:13<08:14,  9.33s/it][A
 22%|██▏       | 15/67 [02:23<08:21,  9.64s/it][A
 24%|██▍       | 16/67 [02:33<08:14,  9.69s/it][A
 25%|██▌       | 17/67 [02:53<10:35, 12.71s/it][A
 27%|██▋       | 18/67 [03:05<10:13, 12.53s/it][A
 28%|██▊       | 19/67 [03:18<10:05, 12.61s/it][A
 30%|██▉       | 20/67 [03:26<08:59, 11.49s/it][A
 31%|███▏      | 21/67 [03:52<12:06, 15.79s/it][A
 33%|███▎      | 22/67 [04:10<12:17, 16.40s/it][A
 34%|███▍      | 23/67 [04:18<10:11, 13.89s/it][A
 36%|███▌      | 24/67 [04:40<11:43, 16.37s/it][A
 37%|███▋      | 25/67 [04:58<11:40, 16.69s/it][A
 39%|███▉      | 26/67 [05:06<09:42, 14.21s/it][A
 40%|████      | 27/67 [05:18<08:54, 13.37s/it][A
 42%|████▏     | 28/67 [05:28<08:10, 12.57s/it][A
 43%|████▎     | 29/67 [05:35<06:47, 10.73s/it][A
 45%|████▍     | 30/67 [05:42<06:03,  9.82s/it][A
 46%|████▋     | 31/67 [05:49<05:13,  8.72s/it][A
 48%|████▊     | 32/67 [05:57<05:05,  8.74s/it][A
 49%|████▉     | 33/67 [06:20<07:15, 12.80s/it][A
 51%|█████     | 34/67 [06:31<06:52, 12.49s/it][A
 52%|█████▏    | 35/67 [06:44<06:39, 12.49s/it][A
 54%|█████▎    | 36/67 [06:54<06:03, 11.73s/it][A
 55%|█████▌    | 37/67 [07:00<05:04, 10.15s/it][A
 57%|█████▋    | 38/67 [07:14<05:21, 11.09s/it][A
 58%|█████▊    | 39/67 [07:23<04:56, 10.59s/it][A
 60%|█████▉    | 40/67 [07:32<04:36, 10.25s/it][A
 61%|██████    | 41/67 [07:58<06:24, 14.80s/it][A
 63%|██████▎   | 42/67 [08:13<06:11, 14.88s/it][A
 64%|██████▍   | 43/67 [08:31<06:18, 15.76s/it][A
 66%|██████▌   | 44/67 [08:45<05:51, 15.28s/it][A
 67%|██████▋   | 45/67 [08:52<04:42, 12.83s/it][A
 69%|██████▊   | 46/67 [09:02<04:13, 12.06s/it][A
 70%|███████   | 47/67 [09:21<04:42, 14.14s/it][A
 72%|███████▏  | 48/67 [09:32<04:07, 13.02s/it][A
 73%|███████▎  | 49/67 [09:46<04:03, 13.54s/it][A
 75%|███████▍  | 50/67 [09:58<03:40, 12.96s/it][A
 76%|███████▌  | 51/67 [10:14<03:42, 13.89s/it][A
 78%|███████▊  | 52/67 [10:21<02:55, 11.72s/it][A
 79%|███████▉  | 53/67 [10:34<02:50, 12.17s/it][A
 81%|████████  | 54/67 [10:42<02:22, 10.96s/it][A
 82%|████████▏ | 55/67 [10:57<02:26, 12.21s/it][A
 84%|████████▎ | 56/67 [11:17<02:39, 14.47s/it][A
 85%|████████▌ | 57/67 [11:42<02:56, 17.68s/it][A
 87%|████████▋ | 58/67 [12:22<03:39, 24.40s/it][A
 88%|████████▊ | 59/67 [12:39<02:55, 21.99s/it][A
 90%|████████▉ | 60/67 [12:58<02:28, 21.21s/it][A
 91%|█████████ | 61/67 [13:07<01:46, 17.67s/it][A
 93%|█████████▎| 62/67 [13:15<01:13, 14.74s/it][A
 94%|█████████▍| 63/67 [13:26<00:53, 13.41s/it][A
 96%|█████████▌| 64/67 [13:35<00:36, 12.11s/it][A
 97%|█████████▋| 65/67 [13:43<00:21, 11.00s/it][A
 99%|█████████▊| 66/67 [13:55<00:11, 11.36s/it][A
100%|██████████| 67/67 [13:57<00:00,  8.47s/it][A                                                      
                                               [A 50%|█████     | 855/1710 [8:19:54<4:04:35, 17.16s/it]
100%|██████████| 67/67 [13:58<00:00,  8.47s/it][A
                                               [A{'f1_1': 0.4164882226980728, 'precision': 0.4298342541436464, 'recall': 0.4039460020768432}
{'f1': 0.4014989293361884, 'precision': 0.4143646408839779, 'recall': 0.3894080996884735}
{'eval_f1': 0.4014989293361884, 'eval_precision': 0.4143646408839779, 'eval_recall': 0.3894080996884735, 'eval_runtime': 852.9764, 'eval_samples_per_second': 0.465, 'eval_steps_per_second': 0.079, 'epoch': 15.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 50%|█████     | 856/1710 [8:20:13<64:56:47, 273.78s/it] 50%|█████     | 857/1710 [8:20:33<46:49:38, 197.63s/it] 50%|█████     | 858/1710 [8:20:51<33:58:32, 143.56s/it] 50%|█████     | 859/1710 [8:21:10<25:08:15, 106.34s/it] 50%|█████     | 860/1710 [8:21:30<18:58:38, 80.37s/it]                                                         50%|█████     | 860/1710 [8:21:30<18:58:38, 80.37s/it] 50%|█████     | 861/1710 [8:21:53<14:54:49, 63.24s/it] 50%|█████     | 862/1710 [8:22:15<11:58:36, 50.85s/it] 50%|█████     | 863/1710 [8:22:34<9:43:23, 41.33s/it]  51%|█████     | 864/1710 [8:22:53<8:08:10, 34.62s/it] 51%|█████     | 865/1710 [8:23:21<7:37:09, 32.46s/it] 51%|█████     | 866/1710 [8:23:44<6:56:38, 29.62s/it] 51%|█████     | 867/1710 [8:24:00<6:01:58, 25.76s/it] 51%|█████     | 868/1710 [8:24:22<5:43:42, 24.49s/it] 51%|█████     | 869/1710 [8:24:44<5:34:32, 23.87s/it] 51%|█████     | 870/1710 [8:25:03<5:13:44, 22.41s/it]                                                       51%|█████     | 870/1710 [8:25:03<5:13:44, 22.41s/it] 51%|█████     | 871/1710 [8:25:19<4:46:28, 20.49s/it] 51%|█████     | 872/1710 [8:25:38<4:38:31, 19.94s/it] 51%|█████     | 873/1710 [8:25:58<4:39:17, 20.02s/it] 51%|█████     | 874/1710 [8:26:16<4:29:09, 19.32s/it] 51%|█████     | 875/1710 [8:26:34<4:22:48, 18.88s/it] 51%|█████     | 876/1710 [8:26:50<4:10:52, 18.05s/it] 51%|█████▏    | 877/1710 [8:27:09<4:17:04, 18.52s/it] 51%|█████▏    | 878/1710 [8:27:26<4:07:57, 17.88s/it] 51%|█████▏    | 879/1710 [8:27:43<4:06:18, 17.78s/it] 51%|█████▏    | 880/1710 [8:27:59<3:56:07, 17.07s/it]                                                       51%|█████▏    | 880/1710 [8:27:59<3:56:07, 17.07s/it] 52%|█████▏    | 881/1710 [8:28:18<4:04:24, 17.69s/it] 52%|█████▏    | 882/1710 [8:28:36<4:07:43, 17.95s/it] 52%|█████▏    | 883/1710 [8:28:57<4:18:44, 18.77s/it] 52%|█████▏    | 884/1710 [8:29:20<4:33:57, 19.90s/it] 52%|█████▏    | 885/1710 [8:29:41<4:38:28, 20.25s/it] 52%|█████▏    | 886/1710 [8:29:58<4:25:54, 19.36s/it] 52%|█████▏    | 887/1710 [8:30:22<4:43:09, 20.64s/it] 52%|█████▏    | 888/1710 [8:30:40<4:31:39, 19.83s/it] 52%|█████▏    | 889/1710 [8:31:02<4:41:08, 20.55s/it] 52%|█████▏    | 890/1710 [8:31:22<4:39:03, 20.42s/it]                                                       52%|█████▏    | 890/1710 [8:31:22<4:39:03, 20.42s/it] 52%|█████▏    | 891/1710 [8:31:41<4:34:33, 20.11s/it] 52%|█████▏    | 892/1710 [8:32:01<4:33:36, 20.07s/it] 52%|█████▏    | 893/1710 [8:32:23<4:39:04, 20.49s/it] 52%|█████▏    | 894/1710 [8:32:39<4:20:28, 19.15s/it] 52%|█████▏    | 895/1710 [8:32:55<4:09:10, 18.34s/it] 52%|█████▏    | 896/1710 [8:33:13<4:06:18, 18.16s/it] 52%|█████▏    | 897/1710 [8:33:34<4:17:41, 19.02s/it] 53%|█████▎    | 898/1710 [8:33:51<4:07:33, 18.29s/it] 53%|█████▎    | 899/1710 [8:34:11<4:17:14, 19.03s/it] 53%|█████▎    | 900/1710 [8:34:28<4:07:49, 18.36s/it]                                                       53%|█████▎    | 900/1710 [8:34:28<4:07:49, 18.36s/it] 53%|█████▎    | 901/1710 [8:34:56<4:44:12, 21.08s/it] 53%|█████▎    | 902/1710 [8:35:12<4:26:41, 19.80s/it] 53%|█████▎    | 903/1710 [8:35:32<4:25:55, 19.77s/it] 53%|█████▎    | 904/1710 [8:35:52<4:25:50, 19.79s/it] 53%|█████▎    | 905/1710 [8:36:07<4:06:46, 18.39s/it] 53%|█████▎    | 906/1710 [8:36:29<4:19:43, 19.38s/it] 53%|█████▎    | 907/1710 [8:36:48<4:16:57, 19.20s/it] 53%|█████▎    | 908/1710 [8:37:03<4:02:02, 18.11s/it] 53%|█████▎    | 909/1710 [8:37:22<4:02:55, 18.20s/it] 53%|█████▎    | 910/1710 [8:37:39<4:01:46, 18.13s/it]                                                       53%|█████▎    | 910/1710 [8:37:40<4:01:46, 18.13s/it] 53%|█████▎    | 911/1710 [8:38:00<4:10:33, 18.82s/it] 53%|█████▎    | 912/1710 [8:38:19<4:12:25, 18.98s/it]{'loss': 0.0313, 'learning_rate': 5.2917859151950485e-05, 'epoch': 15.09}
{'loss': 0.0148, 'learning_rate': 5.1961795186157656e-05, 'epoch': 15.26}
{'loss': 0.0127, 'learning_rate': 5.100501223014408e-05, 'epoch': 15.44}
{'loss': 0.018, 'learning_rate': 5.0047860941100445e-05, 'epoch': 15.61}
{'loss': 0.0222, 'learning_rate': 4.909069211121012e-05, 'epoch': 15.79}
{'loss': 0.0156, 'learning_rate': 4.8133856539085096e-05, 'epoch': 15.96}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:42,  5.27s/it][A
  4%|▍         | 3/67 [00:17<06:25,  6.02s/it][A
  6%|▌         | 4/67 [00:25<06:51,  6.54s/it][A
  7%|▋         | 5/67 [00:40<10:02,  9.71s/it][A
  9%|▉         | 6/67 [00:51<10:13, 10.06s/it][A
 10%|█         | 7/67 [01:05<11:22, 11.37s/it][A
 12%|█▏        | 8/67 [01:27<14:34, 14.82s/it][A
 13%|█▎        | 9/67 [01:46<15:18, 15.83s/it][A
 15%|█▍        | 10/67 [01:54<13:02, 13.73s/it][A
 16%|█▋        | 11/67 [02:10<13:17, 14.24s/it][A
 18%|█▊        | 12/67 [02:23<12:45, 13.91s/it][A
 19%|█▉        | 13/67 [02:29<10:18, 11.45s/it][A
 21%|██        | 14/67 [02:38<09:31, 10.78s/it][A
 22%|██▏       | 15/67 [02:52<10:17, 11.87s/it][A
 24%|██▍       | 16/67 [03:00<09:05, 10.70s/it][A
 25%|██▌       | 17/67 [03:20<11:13, 13.47s/it][A
 27%|██▋       | 18/67 [03:31<10:18, 12.63s/it][A
 28%|██▊       | 19/67 [03:47<10:51, 13.57s/it][A
 30%|██▉       | 20/67 [03:59<10:23, 13.26s/it][A
 31%|███▏      | 21/67 [04:15<10:37, 13.87s/it][A
 33%|███▎      | 22/67 [04:31<10:59, 14.66s/it][A
 34%|███▍      | 23/67 [04:39<09:18, 12.68s/it][A
 36%|███▌      | 24/67 [04:52<09:03, 12.65s/it][A
 37%|███▋      | 25/67 [05:09<09:51, 14.08s/it][A
 39%|███▉      | 26/67 [05:17<08:25, 12.33s/it][A
 40%|████      | 27/67 [05:32<08:37, 12.95s/it][A
 42%|████▏     | 28/67 [05:44<08:12, 12.63s/it][A
 43%|████▎     | 29/67 [05:53<07:17, 11.53s/it][A
 45%|████▍     | 30/67 [06:00<06:24, 10.38s/it][A
 46%|████▋     | 31/67 [06:07<05:28,  9.12s/it][A
 48%|████▊     | 32/67 [06:18<05:42,  9.79s/it][A
 49%|████▉     | 33/67 [06:40<07:40, 13.53s/it][A
 51%|█████     | 34/67 [06:53<07:19, 13.32s/it][A
 52%|█████▏    | 35/67 [07:05<06:51, 12.86s/it][A
 54%|█████▎    | 36/67 [07:13<05:56, 11.49s/it][A
 55%|█████▌    | 37/67 [07:19<04:59,  9.97s/it][A
 57%|█████▋    | 38/67 [07:30<04:52, 10.07s/it][A
 58%|█████▊    | 39/67 [07:39<04:34,  9.81s/it][A
 60%|█████▉    | 40/67 [07:49<04:26,  9.88s/it][A
 61%|██████    | 41/67 [08:06<05:10, 11.93s/it][A
 63%|██████▎   | 42/67 [08:20<05:15, 12.61s/it][A
 64%|██████▍   | 43/67 [08:39<05:50, 14.61s/it][A
 66%|██████▌   | 44/67 [08:53<05:32, 14.47s/it][A
 67%|██████▋   | 45/67 [08:59<04:20, 11.84s/it][A
 69%|██████▊   | 46/67 [09:07<03:44, 10.71s/it][A
 70%|███████   | 47/67 [09:21<03:53, 11.66s/it][A
 72%|███████▏  | 48/67 [09:33<03:41, 11.68s/it][A
 73%|███████▎  | 49/67 [09:51<04:04, 13.58s/it][A
 75%|███████▍  | 50/67 [10:02<03:40, 12.95s/it][A
 76%|███████▌  | 51/67 [10:18<03:39, 13.69s/it][A
 78%|███████▊  | 52/67 [10:30<03:18, 13.22s/it][A
 79%|███████▉  | 53/67 [10:42<02:59, 12.81s/it][A
 81%|████████  | 54/67 [10:49<02:26, 11.25s/it][A
 82%|████████▏ | 55/67 [11:04<02:27, 12.33s/it][A
 84%|████████▎ | 56/67 [11:24<02:40, 14.56s/it][A
 85%|████████▌ | 57/67 [11:47<02:51, 17.16s/it][A
 87%|████████▋ | 58/67 [11:59<02:21, 15.72s/it][A
 88%|████████▊ | 59/67 [12:23<02:24, 18.03s/it][A
 90%|████████▉ | 60/67 [12:42<02:09, 18.49s/it][A
 91%|█████████ | 61/67 [12:52<01:34, 15.78s/it][A
 93%|█████████▎| 62/67 [13:02<01:10, 14.01s/it][A
 94%|█████████▍| 63/67 [13:12<00:51, 12.87s/it][A
 96%|█████████▌| 64/67 [13:23<00:36, 12.32s/it][A
 97%|█████████▋| 65/67 [13:30<00:21, 10.60s/it][A
 99%|█████████▊| 66/67 [13:42<00:11, 11.12s/it][A
100%|██████████| 67/67 [13:45<00:00,  8.61s/it][A                                                      
                                               [A 53%|█████▎    | 912/1710 [8:52:43<4:12:25, 18.98s/it]
100%|██████████| 67/67 [13:46<00:00,  8.61s/it][A
                                               [A{'f1_1': 0.43099025141098, 'precision': 0.4259634888438134, 'recall': 0.43613707165109034}
{'f1': 0.40328373524884553, 'precision': 0.39858012170385393, 'recall': 0.40809968847352024}
{'eval_f1': 0.40328373524884553, 'eval_precision': 0.39858012170385393, 'eval_recall': 0.40809968847352024, 'eval_runtime': 863.5283, 'eval_samples_per_second': 0.46, 'eval_steps_per_second': 0.078, 'epoch': 16.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 53%|█████▎    | 913/1710 [8:53:10<62:05:57, 280.50s/it] 53%|█████▎    | 914/1710 [8:53:29<44:40:40, 202.06s/it] 54%|█████▎    | 915/1710 [8:53:52<32:45:09, 148.31s/it] 54%|█████▎    | 916/1710 [8:54:11<24:08:10, 109.43s/it] 54%|█████▎    | 917/1710 [8:54:32<18:17:08, 83.01s/it]  54%|█████▎    | 918/1710 [8:54:53<14:10:14, 64.41s/it] 54%|█████▎    | 919/1710 [8:55:10<11:00:17, 50.09s/it] 54%|█████▍    | 920/1710 [8:55:31<9:05:57, 41.46s/it]                                                        54%|█████▍    | 920/1710 [8:55:31<9:05:57, 41.46s/it] 54%|█████▍    | 921/1710 [8:55:50<7:38:18, 34.85s/it] 54%|█████▍    | 922/1710 [8:56:10<6:36:14, 30.17s/it] 54%|█████▍    | 923/1710 [8:56:29<5:52:47, 26.90s/it] 54%|█████▍    | 924/1710 [8:56:52<5:38:57, 25.88s/it] 54%|█████▍    | 925/1710 [8:57:13<5:16:04, 24.16s/it] 54%|█████▍    | 926/1710 [8:57:29<4:46:41, 21.94s/it] 54%|█████▍    | 927/1710 [8:57:50<4:41:26, 21.57s/it] 54%|█████▍    | 928/1710 [8:58:07<4:21:39, 20.08s/it] 54%|█████▍    | 929/1710 [8:58:22<4:03:43, 18.72s/it] 54%|█████▍    | 930/1710 [8:58:38<3:51:20, 17.79s/it]                                                       54%|█████▍    | 930/1710 [8:58:38<3:51:20, 17.79s/it] 54%|█████▍    | 931/1710 [8:58:58<4:00:17, 18.51s/it] 55%|█████▍    | 932/1710 [8:59:20<4:15:25, 19.70s/it] 55%|█████▍    | 933/1710 [8:59:46<4:36:17, 21.33s/it] 55%|█████▍    | 934/1710 [9:00:03<4:22:27, 20.29s/it] 55%|█████▍    | 935/1710 [9:00:22<4:16:24, 19.85s/it] 55%|█████▍    | 936/1710 [9:00:45<4:25:15, 20.56s/it] 55%|█████▍    | 937/1710 [9:01:03<4:17:07, 19.96s/it] 55%|█████▍    | 938/1710 [9:01:19<3:59:35, 18.62s/it] 55%|█████▍    | 939/1710 [9:01:36<3:53:57, 18.21s/it] 55%|█████▍    | 940/1710 [9:01:53<3:50:43, 17.98s/it]                                                       55%|█████▍    | 940/1710 [9:01:53<3:50:43, 17.98s/it] 55%|█████▌    | 941/1710 [9:02:16<4:07:40, 19.32s/it] 55%|█████▌    | 942/1710 [9:02:36<4:12:00, 19.69s/it] 55%|█████▌    | 943/1710 [9:02:57<4:15:18, 19.97s/it] 55%|█████▌    | 944/1710 [9:03:18<4:20:39, 20.42s/it] 55%|█████▌    | 945/1710 [9:03:37<4:13:33, 19.89s/it] 55%|█████▌    | 946/1710 [9:03:54<4:02:35, 19.05s/it] 55%|█████▌    | 947/1710 [9:04:18<4:20:46, 20.51s/it] 55%|█████▌    | 948/1710 [9:04:35<4:08:53, 19.60s/it] 55%|█████▌    | 949/1710 [9:04:52<3:56:58, 18.68s/it] 56%|█████▌    | 950/1710 [9:05:16<4:18:25, 20.40s/it]                                                       56%|█████▌    | 950/1710 [9:05:16<4:18:25, 20.40s/it] 56%|█████▌    | 951/1710 [9:05:37<4:17:47, 20.38s/it] 56%|█████▌    | 952/1710 [9:05:55<4:08:43, 19.69s/it] 56%|█████▌    | 953/1710 [9:06:12<3:58:59, 18.94s/it] 56%|█████▌    | 954/1710 [9:06:29<3:51:41, 18.39s/it] 56%|█████▌    | 955/1710 [9:06:50<3:59:12, 19.01s/it] 56%|█████▌    | 956/1710 [9:07:06<3:47:46, 18.13s/it] 56%|█████▌    | 957/1710 [9:07:21<3:37:44, 17.35s/it] 56%|█████▌    | 958/1710 [9:07:42<3:51:57, 18.51s/it] 56%|█████▌    | 959/1710 [9:08:01<3:53:08, 18.63s/it] 56%|█████▌    | 960/1710 [9:08:19<3:49:02, 18.32s/it]                                                       56%|█████▌    | 960/1710 [9:08:19<3:49:02, 18.32s/it] 56%|█████▌    | 961/1710 [9:08:35<3:41:51, 17.77s/it] 56%|█████▋    | 962/1710 [9:08:55<3:46:58, 18.21s/it] 56%|█████▋    | 963/1710 [9:09:15<3:55:41, 18.93s/it] 56%|█████▋    | 964/1710 [9:09:36<4:01:50, 19.45s/it] 56%|█████▋    | 965/1710 [9:09:54<3:54:36, 18.89s/it] 56%|█████▋    | 966/1710 [9:10:11<3:49:03, 18.47s/it] 57%|█████▋    | 967/1710 [9:10:30<3:49:07, 18.50s/it] 57%|█████▋    | 968/1710 [9:10:48<3:48:33, 18.48s/it] 57%|█████▋    | 969/1710 [9:11:06<3:45:57, 18.30s/it]{'loss': 0.0148, 'learning_rate': 4.7177704901199686e-05, 'epoch': 16.14}
{'loss': 0.0101, 'learning_rate': 4.622258762336903e-05, 'epoch': 16.32}
{'loss': 0.0123, 'learning_rate': 4.5268854752319326e-05, 'epoch': 16.49}
{'loss': 0.0051, 'learning_rate': 4.431685582739718e-05, 'epoch': 16.67}
{'loss': 0.0182, 'learning_rate': 4.336693975246473e-05, 'epoch': 16.84}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:09<05:20,  4.93s/it][A
  4%|▍         | 3/67 [00:14<05:12,  4.88s/it][A
  6%|▌         | 4/67 [00:22<06:08,  5.85s/it][A
  7%|▋         | 5/67 [00:40<10:27, 10.12s/it][A
  9%|▉         | 6/67 [00:53<11:11, 11.00s/it][A
 10%|█         | 7/67 [01:07<12:03, 12.06s/it][A
 12%|█▏        | 8/67 [01:29<15:04, 15.33s/it][A
 13%|█▎        | 9/67 [01:47<15:38, 16.18s/it][A
 15%|█▍        | 10/67 [01:58<13:49, 14.56s/it][A
 16%|█▋        | 11/67 [02:11<13:02, 13.98s/it][A
 18%|█▊        | 12/67 [02:18<10:56, 11.93s/it][A
 19%|█▉        | 13/67 [02:25<09:26, 10.50s/it][A
 21%|██        | 14/67 [02:33<08:33,  9.69s/it][A
 22%|██▏       | 15/67 [02:49<09:56, 11.47s/it][A
 24%|██▍       | 16/67 [02:57<08:48, 10.36s/it][A
 25%|██▌       | 17/67 [03:16<10:58, 13.17s/it][A
 27%|██▋       | 18/67 [03:28<10:31, 12.88s/it][A
 28%|██▊       | 19/67 [03:44<11:00, 13.76s/it][A
 30%|██▉       | 20/67 [03:53<09:38, 12.31s/it][A
 31%|███▏      | 21/67 [04:17<11:59, 15.63s/it][A
 33%|███▎      | 22/67 [04:36<12:41, 16.92s/it][A
 34%|███▍      | 23/67 [04:45<10:27, 14.27s/it][A
 36%|███▌      | 24/67 [04:59<10:21, 14.46s/it][A
 37%|███▋      | 25/67 [05:19<11:06, 15.88s/it][A
 39%|███▉      | 26/67 [05:27<09:17, 13.61s/it][A
 40%|████      | 27/67 [05:41<09:14, 13.85s/it][A
 42%|████▏     | 28/67 [05:53<08:35, 13.21s/it][A
 43%|████▎     | 29/67 [06:02<07:34, 11.96s/it][A
 45%|████▍     | 30/67 [06:10<06:35, 10.68s/it][A
 46%|████▋     | 31/67 [06:15<05:29,  9.17s/it][A
 48%|████▊     | 32/67 [06:22<04:56,  8.48s/it][A
 49%|████▉     | 33/67 [06:45<07:11, 12.68s/it][A
 51%|█████     | 34/67 [06:56<06:38, 12.08s/it][A
 52%|█████▏    | 35/67 [07:07<06:24, 12.00s/it][A
 54%|█████▎    | 36/67 [07:17<05:47, 11.19s/it][A
 55%|█████▌    | 37/67 [07:21<04:36,  9.20s/it][A
 57%|█████▋    | 38/67 [07:31<04:34,  9.46s/it][A
 58%|█████▊    | 39/67 [07:38<04:03,  8.71s/it][A
 60%|█████▉    | 40/67 [07:48<04:01,  8.93s/it][A
 61%|██████    | 41/67 [08:03<04:39, 10.77s/it][A
 63%|██████▎   | 42/67 [08:17<04:55, 11.80s/it][A
 64%|██████▍   | 43/67 [08:31<05:02, 12.59s/it][A
 66%|██████▌   | 44/67 [08:48<05:19, 13.91s/it][A
 67%|██████▋   | 45/67 [08:54<04:12, 11.48s/it][A
 69%|██████▊   | 46/67 [09:02<03:39, 10.46s/it][A
 70%|███████   | 47/67 [09:18<04:02, 12.12s/it][A
 72%|███████▏  | 48/67 [09:29<03:40, 11.62s/it][A
 73%|███████▎  | 49/67 [09:47<04:03, 13.54s/it][A
 75%|███████▍  | 50/67 [09:58<03:39, 12.93s/it][A
 76%|███████▌  | 51/67 [10:14<03:42, 13.90s/it][A
 78%|███████▊  | 52/67 [10:27<03:24, 13.63s/it][A
 79%|███████▉  | 53/67 [10:40<03:07, 13.42s/it][A
 81%|████████  | 54/67 [10:48<02:32, 11.77s/it][A
 82%|████████▏ | 55/67 [11:05<02:38, 13.17s/it][A
 84%|████████▎ | 56/67 [11:24<02:46, 15.14s/it][A
 85%|████████▌ | 57/67 [11:45<02:49, 16.92s/it][A
 87%|████████▋ | 58/67 [12:08<02:48, 18.72s/it][A
 88%|████████▊ | 59/67 [12:30<02:37, 19.65s/it][A
 90%|████████▉ | 60/67 [12:50<02:17, 19.68s/it][A
 91%|█████████ | 61/67 [13:00<01:39, 16.64s/it][A
 93%|█████████▎| 62/67 [13:05<01:06, 13.35s/it][A
 94%|█████████▍| 63/67 [13:15<00:48, 12.24s/it][A
 96%|█████████▌| 64/67 [13:29<00:38, 12.77s/it][A
 97%|█████████▋| 65/67 [13:37<00:23, 11.51s/it][A
 99%|█████████▊| 66/67 [13:50<00:11, 11.78s/it][A
100%|██████████| 67/67 [13:52<00:00,  8.77s/it][A                                                      
                                               [A 57%|█████▋    | 969/1710 [9:25:18<3:45:57, 18.30s/it]
100%|██████████| 67/67 [13:53<00:00,  8.77s/it][A
                                               [A{'f1_1': 0.4366952789699571, 'precision': 0.45172031076581576, 'recall': 0.4226375908618899}
{'f1': 0.4184549356223176, 'precision': 0.4328523862375139, 'recall': 0.40498442367601245}
{'eval_f1': 0.4184549356223176, 'eval_precision': 0.4328523862375139, 'eval_recall': 0.40498442367601245, 'eval_runtime': 852.1909, 'eval_samples_per_second': 0.466, 'eval_steps_per_second': 0.079, 'epoch': 17.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 57%|█████▋    | 970/1710 [9:25:37<56:22:18, 274.24s/it]                                                         57%|█████▋    | 970/1710 [9:25:37<56:22:18, 274.24s/it] 57%|█████▋    | 971/1710 [9:25:58<40:41:15, 198.21s/it] 57%|█████▋    | 972/1710 [9:26:16<29:31:46, 144.05s/it] 57%|█████▋    | 973/1710 [9:26:32<21:37:41, 105.65s/it] 57%|█████▋    | 974/1710 [9:26:53<16:24:18, 80.24s/it]  57%|█████▋    | 975/1710 [9:27:13<12:42:34, 62.25s/it] 57%|█████▋    | 976/1710 [9:27:30<9:56:31, 48.76s/it]  57%|█████▋    | 977/1710 [9:27:50<8:08:25, 39.98s/it] 57%|█████▋    | 978/1710 [9:28:07<6:44:23, 33.15s/it] 57%|█████▋    | 979/1710 [9:28:25<5:49:28, 28.69s/it] 57%|█████▋    | 980/1710 [9:28:44<5:13:26, 25.76s/it]                                                       57%|█████▋    | 980/1710 [9:28:44<5:13:26, 25.76s/it] 57%|█████▋    | 981/1710 [9:29:06<4:58:48, 24.59s/it] 57%|█████▋    | 982/1710 [9:29:22<4:27:45, 22.07s/it] 57%|█████▋    | 983/1710 [9:29:42<4:16:59, 21.21s/it] 58%|█████▊    | 984/1710 [9:29:58<3:57:48, 19.65s/it] 58%|█████▊    | 985/1710 [9:30:19<4:02:30, 20.07s/it] 58%|█████▊    | 986/1710 [9:30:37<3:56:23, 19.59s/it] 58%|█████▊    | 987/1710 [9:31:00<4:07:32, 20.54s/it] 58%|█████▊    | 988/1710 [9:31:22<4:11:30, 20.90s/it] 58%|█████▊    | 989/1710 [9:31:41<4:05:51, 20.46s/it] 58%|█████▊    | 990/1710 [9:31:58<3:53:08, 19.43s/it]                                                       58%|█████▊    | 990/1710 [9:31:58<3:53:08, 19.43s/it] 58%|█████▊    | 991/1710 [9:32:17<3:52:18, 19.39s/it] 58%|█████▊    | 992/1710 [9:32:39<3:58:35, 19.94s/it] 58%|█████▊    | 993/1710 [9:33:04<4:18:02, 21.59s/it] 58%|█████▊    | 994/1710 [9:33:23<4:07:06, 20.71s/it] 58%|█████▊    | 995/1710 [9:33:41<3:58:35, 20.02s/it] 58%|█████▊    | 996/1710 [9:33:59<3:49:32, 19.29s/it] 58%|█████▊    | 997/1710 [9:34:15<3:37:45, 18.33s/it] 58%|█████▊    | 998/1710 [9:34:34<3:40:39, 18.59s/it] 58%|█████▊    | 999/1710 [9:35:02<4:12:52, 21.34s/it] 58%|█████▊    | 1000/1710 [9:35:21<4:04:54, 20.70s/it]                                                        58%|█████▊    | 1000/1710 [9:35:21<4:04:54, 20.70s/it] 59%|█████▊    | 1001/1710 [9:35:40<3:58:07, 20.15s/it] 59%|█████▊    | 1002/1710 [9:36:00<3:57:50, 20.16s/it] 59%|█████▊    | 1003/1710 [9:36:17<3:48:01, 19.35s/it] 59%|█████▊    | 1004/1710 [9:36:39<3:56:03, 20.06s/it] 59%|█████▉    | 1005/1710 [9:37:01<4:02:01, 20.60s/it] 59%|█████▉    | 1006/1710 [9:37:20<3:56:01, 20.12s/it] 59%|█████▉    | 1007/1710 [9:37:38<3:47:34, 19.42s/it] 59%|█████▉    | 1008/1710 [9:37:58<3:49:11, 19.59s/it] 59%|█████▉    | 1009/1710 [9:38:17<3:48:23, 19.55s/it] 59%|█████▉    | 1010/1710 [9:38:37<3:47:52, 19.53s/it]                                                        59%|█████▉    | 1010/1710 [9:38:37<3:47:52, 19.53s/it] 59%|█████▉    | 1011/1710 [9:38:54<3:39:33, 18.85s/it] 59%|█████▉    | 1012/1710 [9:39:11<3:33:09, 18.32s/it] 59%|█████▉    | 1013/1710 [9:39:31<3:39:15, 18.87s/it] 59%|█████▉    | 1014/1710 [9:39:54<3:53:57, 20.17s/it] 59%|█████▉    | 1015/1710 [9:40:13<3:49:00, 19.77s/it] 59%|█████▉    | 1016/1710 [9:40:31<3:40:00, 19.02s/it] 59%|█████▉    | 1017/1710 [9:40:50<3:39:55, 19.04s/it] 60%|█████▉    | 1018/1710 [9:41:08<3:38:54, 18.98s/it] 60%|█████▉    | 1019/1710 [9:41:33<3:59:16, 20.78s/it] 60%|█████▉    | 1020/1710 [9:41:51<3:47:24, 19.77s/it]                                                        60%|█████▉    | 1020/1710 [9:41:51<3:47:24, 19.77s/it] 60%|█████▉    | 1021/1710 [9:42:07<3:35:39, 18.78s/it] 60%|█████▉    | 1022/1710 [9:42:24<3:28:03, 18.14s/it] 60%|█████▉    | 1023/1710 [9:42:43<3:31:50, 18.50s/it] 60%|█████▉    | 1024/1710 [9:43:02<3:31:34, 18.50s/it] 60%|█████▉    | 1025/1710 [9:43:21<3:33:54, 18.74s/it] 60%|██████    | 1026/1710 [9:43:37<3:22:38, 17.78s/it]{'loss': 0.0097, 'learning_rate': 4.241945466802779e-05, 'epoch': 17.02}
{'loss': 0.006, 'learning_rate': 4.147474782364373e-05, 'epoch': 17.19}
{'loss': 0.0093, 'learning_rate': 4.053316545065585e-05, 'epoch': 17.37}
{'loss': 0.0062, 'learning_rate': 3.9595052635301e-05, 'epoch': 17.54}
{'loss': 0.0077, 'learning_rate': 3.866075319223676e-05, 'epoch': 17.72}
{'loss': 0.012, 'learning_rate': 3.773060953853479e-05, 'epoch': 17.89}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:43,  5.28s/it][A
  4%|▍         | 3/67 [00:18<06:46,  6.35s/it][A
  6%|▌         | 4/67 [00:25<07:03,  6.71s/it][A
  7%|▋         | 5/67 [00:44<11:11, 10.83s/it][A
  9%|▉         | 6/67 [00:56<11:38, 11.45s/it][A
 10%|█         | 7/67 [01:12<12:43, 12.73s/it][A
 12%|█▏        | 8/67 [01:34<15:29, 15.75s/it][A
 13%|█▎        | 9/67 [01:47<14:16, 14.77s/it][A
 15%|█▍        | 10/67 [01:56<12:25, 13.07s/it][A
 16%|█▋        | 11/67 [02:16<14:13, 15.24s/it][A
 18%|█▊        | 12/67 [02:26<12:21, 13.49s/it][A
 19%|█▉        | 13/67 [02:33<10:25, 11.58s/it][A
 21%|██        | 14/67 [02:43<09:54, 11.21s/it][A
 22%|██▏       | 15/67 [02:59<10:50, 12.51s/it][A
 24%|██▍       | 16/67 [03:06<09:17, 10.92s/it][A
 25%|██▌       | 17/67 [03:26<11:20, 13.60s/it][A
 27%|██▋       | 18/67 [03:38<10:45, 13.17s/it][A
 28%|██▊       | 19/67 [03:51<10:28, 13.09s/it][A
 30%|██▉       | 20/67 [04:00<09:16, 11.84s/it][A
 31%|███▏      | 21/67 [04:26<12:18, 16.06s/it][A
 33%|███▎      | 22/67 [04:42<12:07, 16.17s/it][A
 34%|███▍      | 23/67 [04:51<10:16, 14.01s/it][A
 36%|███▌      | 24/67 [05:20<13:10, 18.37s/it][A
 37%|███▋      | 25/67 [05:34<12:02, 17.19s/it][A
 39%|███▉      | 26/67 [05:42<09:55, 14.53s/it][A
 40%|████      | 27/67 [05:57<09:39, 14.50s/it][A
 42%|████▏     | 28/67 [06:07<08:33, 13.16s/it][A
 43%|████▎     | 29/67 [06:14<07:16, 11.47s/it][A
 45%|████▍     | 30/67 [06:20<06:01,  9.78s/it][A
 46%|████▋     | 31/67 [06:24<04:51,  8.10s/it][A
 48%|████▊     | 32/67 [06:31<04:29,  7.71s/it][A
 49%|████▉     | 33/67 [06:53<06:48, 12.03s/it][A
 51%|█████     | 34/67 [07:04<06:22, 11.58s/it][A
 52%|█████▏    | 35/67 [07:16<06:11, 11.62s/it][A
 54%|█████▎    | 36/67 [07:25<05:37, 10.90s/it][A
 55%|█████▌    | 37/67 [07:31<04:47,  9.57s/it][A
 57%|█████▋    | 38/67 [07:41<04:39,  9.65s/it][A
 58%|█████▊    | 39/67 [07:50<04:26,  9.50s/it][A
 60%|█████▉    | 40/67 [07:59<04:08,  9.20s/it][A
 61%|██████    | 41/67 [08:12<04:29, 10.38s/it][A
 63%|██████▎   | 42/67 [08:26<04:47, 11.50s/it][A
 64%|██████▍   | 43/67 [08:38<04:40, 11.69s/it][A
 66%|██████▌   | 44/67 [08:51<04:38, 12.11s/it][A
 67%|██████▋   | 45/67 [08:57<03:44, 10.20s/it][A
 69%|██████▊   | 46/67 [09:05<03:21,  9.61s/it][A
 70%|███████   | 47/67 [09:21<03:47, 11.40s/it][A
 72%|███████▏  | 48/67 [09:31<03:30, 11.08s/it][A
 73%|███████▎  | 49/67 [09:49<03:56, 13.14s/it][A
 75%|███████▍  | 50/67 [10:02<03:44, 13.20s/it][A
 76%|███████▌  | 51/67 [10:18<03:43, 13.96s/it][A
 78%|███████▊  | 52/67 [10:31<03:23, 13.59s/it][A
 79%|███████▉  | 53/67 [10:43<03:02, 13.02s/it][A
 81%|████████  | 54/67 [10:56<02:49, 13.04s/it][A
 82%|████████▏ | 55/67 [11:12<02:47, 13.99s/it][A
 84%|████████▎ | 56/67 [11:31<02:51, 15.61s/it][A
 85%|████████▌ | 57/67 [12:04<03:26, 20.66s/it][A
 87%|████████▋ | 58/67 [12:24<03:04, 20.45s/it][A
 88%|████████▊ | 59/67 [12:39<02:30, 18.84s/it][A
 90%|████████▉ | 60/67 [12:58<02:12, 18.96s/it][A
 91%|█████████ | 61/67 [13:07<01:36, 16.09s/it][A
 93%|█████████▎| 62/67 [13:17<01:10, 14.18s/it][A
 94%|█████████▍| 63/67 [13:27<00:51, 12.89s/it][A
 96%|█████████▌| 64/67 [13:38<00:36, 12.32s/it][A
 97%|█████████▋| 65/67 [13:46<00:22, 11.13s/it][A
 99%|█████████▊| 66/67 [13:59<00:11, 11.47s/it][A
100%|██████████| 67/67 [14:00<00:00,  8.54s/it][A                                                       
                                               [A 60%|██████    | 1026/1710 [9:57:49<3:22:38, 17.78s/it]
100%|██████████| 67/67 [14:01<00:00,  8.54s/it][A
                                               [A{'f1_1': 0.44432882414151925, 'precision': 0.44525547445255476, 'recall': 0.4434060228452752}
{'f1': 0.42455775234131116, 'precision': 0.4254431699687174, 'recall': 0.4236760124610592}
{'eval_f1': 0.42455775234131116, 'eval_precision': 0.4254431699687174, 'eval_recall': 0.4236760124610592, 'eval_runtime': 852.1803, 'eval_samples_per_second': 0.466, 'eval_steps_per_second': 0.079, 'epoch': 18.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 60%|██████    | 1027/1710 [9:58:16<52:25:42, 276.34s/it] 60%|██████    | 1028/1710 [9:58:32<37:33:54, 198.29s/it] 60%|██████    | 1029/1710 [9:58:51<27:19:31, 144.45s/it] 60%|██████    | 1030/1710 [9:59:09<20:05:24, 106.36s/it]                                                          60%|██████    | 1030/1710 [9:59:09<20:05:24, 106.36s/it] 60%|██████    | 1031/1710 [9:59:28<15:06:47, 80.13s/it]  60%|██████    | 1032/1710 [9:59:46<11:36:24, 61.63s/it] 60%|██████    | 1033/1710 [10:00:03<9:04:01, 48.22s/it] 60%|██████    | 1034/1710 [10:00:22<7:25:49, 39.57s/it] 61%|██████    | 1035/1710 [10:00:40<6:12:28, 33.11s/it] 61%|██████    | 1036/1710 [10:01:02<5:34:28, 29.77s/it] 61%|██████    | 1037/1710 [10:01:21<4:57:08, 26.49s/it] 61%|██████    | 1038/1710 [10:01:38<4:22:57, 23.48s/it] 61%|██████    | 1039/1710 [10:02:02<4:24:36, 23.66s/it] 61%|██████    | 1040/1710 [10:02:22<4:13:12, 22.68s/it]                                                         61%|██████    | 1040/1710 [10:02:22<4:13:12, 22.68s/it] 61%|██████    | 1041/1710 [10:02:40<3:56:33, 21.22s/it] 61%|██████    | 1042/1710 [10:02:57<3:40:25, 19.80s/it] 61%|██████    | 1043/1710 [10:03:17<3:42:46, 20.04s/it] 61%|██████    | 1044/1710 [10:03:35<3:34:56, 19.36s/it] 61%|██████    | 1045/1710 [10:03:55<3:35:42, 19.46s/it] 61%|██████    | 1046/1710 [10:04:11<3:26:36, 18.67s/it] 61%|██████    | 1047/1710 [10:04:32<3:33:11, 19.29s/it] 61%|██████▏   | 1048/1710 [10:04:51<3:31:03, 19.13s/it] 61%|██████▏   | 1049/1710 [10:05:09<3:28:49, 18.96s/it] 61%|██████▏   | 1050/1710 [10:05:28<3:27:53, 18.90s/it]                                                         61%|██████▏   | 1050/1710 [10:05:28<3:27:53, 18.90s/it] 61%|██████▏   | 1051/1710 [10:05:50<3:38:04, 19.86s/it] 62%|██████▏   | 1052/1710 [10:06:12<3:42:05, 20.25s/it] 62%|██████▏   | 1053/1710 [10:06:34<3:48:40, 20.88s/it] 62%|██████▏   | 1054/1710 [10:06:57<3:54:58, 21.49s/it] 62%|██████▏   | 1055/1710 [10:07:19<3:55:43, 21.59s/it] 62%|██████▏   | 1056/1710 [10:07:41<3:57:58, 21.83s/it] 62%|██████▏   | 1057/1710 [10:07:59<3:45:37, 20.73s/it] 62%|██████▏   | 1058/1710 [10:08:23<3:55:31, 21.67s/it] 62%|██████▏   | 1059/1710 [10:08:42<3:46:57, 20.92s/it] 62%|██████▏   | 1060/1710 [10:09:02<3:43:09, 20.60s/it]                                                         62%|██████▏   | 1060/1710 [10:09:02<3:43:09, 20.60s/it] 62%|██████▏   | 1061/1710 [10:09:20<3:35:22, 19.91s/it] 62%|██████▏   | 1062/1710 [10:09:39<3:30:45, 19.51s/it] 62%|██████▏   | 1063/1710 [10:09:56<3:23:58, 18.92s/it] 62%|██████▏   | 1064/1710 [10:10:13<3:17:14, 18.32s/it] 62%|██████▏   | 1065/1710 [10:10:30<3:10:55, 17.76s/it] 62%|██████▏   | 1066/1710 [10:10:47<3:09:49, 17.69s/it] 62%|██████▏   | 1067/1710 [10:11:04<3:05:22, 17.30s/it] 62%|██████▏   | 1068/1710 [10:11:23<3:09:50, 17.74s/it] 63%|██████▎   | 1069/1710 [10:11:47<3:31:24, 19.79s/it] 63%|██████▎   | 1070/1710 [10:12:07<3:30:51, 19.77s/it]                                                         63%|██████▎   | 1070/1710 [10:12:07<3:30:51, 19.77s/it] 63%|██████▎   | 1071/1710 [10:12:27<3:31:17, 19.84s/it] 63%|██████▎   | 1072/1710 [10:12:50<3:41:06, 20.79s/it] 63%|██████▎   | 1073/1710 [10:13:09<3:36:47, 20.42s/it] 63%|██████▎   | 1074/1710 [10:13:28<3:30:16, 19.84s/it] 63%|██████▎   | 1075/1710 [10:13:53<3:45:53, 21.34s/it] 63%|██████▎   | 1076/1710 [10:14:11<3:34:33, 20.30s/it] 63%|██████▎   | 1077/1710 [10:14:29<3:26:58, 19.62s/it] 63%|██████▎   | 1078/1710 [10:14:48<3:25:07, 19.47s/it] 63%|██████▎   | 1079/1710 [10:15:04<3:16:10, 18.65s/it] 63%|██████▎   | 1080/1710 [10:15:25<3:20:28, 19.09s/it]                                                         63%|██████▎   | 1080/1710 [10:15:25<3:20:28, 19.09s/it] 63%|██████▎   | 1081/1710 [10:15:45<3:22:45, 19.34s/it] 63%|██████▎   | 1082/1710 [10:16:01<3:13:21, 18.47s/it] 63%|██████▎   | 1083/1710 [10:16:17<3:04:43, 17.68s/it]{'loss': 0.0037, 'learning_rate': 3.6804962568186286e-05, 'epoch': 18.07}
{'loss': 0.0079, 'learning_rate': 3.5884151527165677e-05, 'epoch': 18.25}
{'loss': 0.0048, 'learning_rate': 3.4968513889098295e-05, 'epoch': 18.42}
{'loss': 0.0042, 'learning_rate': 3.4058385231577674e-05, 'epoch': 18.6}
{'loss': 0.005, 'learning_rate': 3.315409911317761e-05, 'epoch': 18.77}
{'loss': 0.0041, 'learning_rate': 3.2255986951204284e-05, 'epoch': 18.95}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:38,  5.21s/it][A
  4%|▍         | 3/67 [00:16<05:51,  5.49s/it][A
  6%|▌         | 4/67 [00:23<06:27,  6.14s/it][A
  7%|▋         | 5/67 [00:38<09:40,  9.37s/it][A
  9%|▉         | 6/67 [00:53<11:23, 11.20s/it][A
 10%|█         | 7/67 [01:08<12:26, 12.44s/it][A
 12%|█▏        | 8/67 [01:30<15:10, 15.43s/it][A
 13%|█▎        | 9/67 [01:49<15:45, 16.31s/it][A
 15%|█▍        | 10/67 [01:58<13:23, 14.09s/it][A
 16%|█▋        | 11/67 [02:13<13:28, 14.44s/it][A
 18%|█▊        | 12/67 [02:22<11:47, 12.87s/it][A
 19%|█▉        | 13/67 [02:28<09:37, 10.70s/it][A
 21%|██        | 14/67 [02:36<08:38,  9.78s/it][A
 22%|██▏       | 15/67 [02:51<09:53, 11.42s/it][A
 24%|██▍       | 16/67 [02:56<08:03,  9.48s/it][A
 25%|██▌       | 17/67 [03:15<10:24, 12.49s/it][A
 27%|██▋       | 18/67 [03:25<09:29, 11.62s/it][A
 28%|██▊       | 19/67 [03:37<09:28, 11.84s/it][A
 30%|██▉       | 20/67 [03:46<08:32, 10.91s/it][A
 31%|███▏      | 21/67 [04:08<10:53, 14.21s/it][A
 33%|███▎      | 22/67 [04:23<10:58, 14.63s/it][A
 34%|███▍      | 23/67 [04:35<10:02, 13.70s/it][A
 36%|███▌      | 24/67 [04:55<11:13, 15.67s/it][A
 37%|███▋      | 25/67 [05:11<10:54, 15.59s/it][A
 39%|███▉      | 26/67 [05:19<09:07, 13.36s/it][A
 40%|████      | 27/67 [05:33<09:03, 13.60s/it][A
 42%|████▏     | 28/67 [05:43<08:06, 12.48s/it][A
 43%|████▎     | 29/67 [05:50<06:58, 11.02s/it][A
 45%|████▍     | 30/67 [05:57<05:57,  9.66s/it][A
 46%|████▋     | 31/67 [06:01<04:48,  8.01s/it][A
 48%|████▊     | 32/67 [06:08<04:26,  7.61s/it][A
 49%|████▉     | 33/67 [06:30<06:44, 11.90s/it][A
 51%|█████     | 34/67 [06:40<06:18, 11.46s/it][A
 52%|█████▏    | 35/67 [06:52<06:08, 11.51s/it][A
 54%|█████▎    | 36/67 [07:07<06:32, 12.67s/it][A
 55%|█████▌    | 37/67 [07:13<05:23, 10.77s/it][A
 57%|█████▋    | 38/67 [07:27<05:32, 11.47s/it][A
 58%|█████▊    | 39/67 [07:33<04:42, 10.08s/it][A
 60%|█████▉    | 40/67 [07:41<04:11,  9.30s/it][A
 61%|██████    | 41/67 [07:52<04:18,  9.95s/it][A
 63%|██████▎   | 42/67 [08:04<04:24, 10.57s/it][A
 64%|██████▍   | 43/67 [08:17<04:32, 11.34s/it][A
 66%|██████▌   | 44/67 [08:34<04:57, 12.93s/it][A
 67%|██████▋   | 45/67 [08:40<03:57, 10.79s/it][A
 69%|██████▊   | 46/67 [08:48<03:31, 10.07s/it][A
 70%|███████   | 47/67 [09:04<03:57, 11.87s/it][A
 72%|███████▏  | 48/67 [09:15<03:36, 11.39s/it][A
 73%|███████▎  | 49/67 [09:32<03:59, 13.29s/it][A
 75%|███████▍  | 50/67 [09:44<03:36, 12.72s/it][A
 76%|███████▌  | 51/67 [09:56<03:21, 12.62s/it][A
 78%|███████▊  | 52/67 [10:03<02:43, 10.90s/it][A
 79%|███████▉  | 53/67 [10:16<02:40, 11.45s/it][A
 81%|████████  | 54/67 [10:23<02:13, 10.25s/it][A
 82%|████████▏ | 55/67 [10:39<02:24, 12.02s/it][A
 84%|████████▎ | 56/67 [10:59<02:36, 14.20s/it][A
 85%|████████▌ | 57/67 [11:23<02:53, 17.39s/it][A
 87%|████████▋ | 58/67 [11:43<02:42, 18.08s/it][A
 88%|████████▊ | 59/67 [11:58<02:17, 17.13s/it][A
 90%|████████▉ | 60/67 [12:17<02:04, 17.72s/it][A
 91%|█████████ | 61/67 [12:27<01:31, 15.21s/it][A
 93%|█████████▎| 62/67 [12:36<01:07, 13.46s/it][A
 94%|█████████▍| 63/67 [12:46<00:49, 12.31s/it][A
 96%|█████████▌| 64/67 [12:56<00:35, 11.84s/it][A
 97%|█████████▋| 65/67 [13:05<00:21, 10.78s/it][A
 99%|█████████▊| 66/67 [13:17<00:11, 11.17s/it][A
100%|██████████| 67/67 [13:18<00:00,  8.33s/it][A                                                        
                                               [A 63%|██████▎   | 1083/1710 [10:29:51<3:04:43, 17.68s/it]
100%|██████████| 67/67 [13:19<00:00,  8.33s/it][A
                                               [A{'f1_1': 0.4358018114011721, 'precision': 0.4474835886214442, 'recall': 0.42471443406022846}
{'f1': 0.4198188598827916, 'precision': 0.4310722100656455, 'recall': 0.4091381100726895}
{'eval_f1': 0.4198188598827916, 'eval_precision': 0.4310722100656455, 'eval_recall': 0.4091381100726895, 'eval_runtime': 814.2169, 'eval_samples_per_second': 0.488, 'eval_steps_per_second': 0.082, 'epoch': 19.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 63%|██████▎   | 1084/1710 [10:30:12<45:43:06, 262.92s/it] 63%|██████▎   | 1085/1710 [10:30:29<32:49:21, 189.06s/it] 64%|██████▎   | 1086/1710 [10:30:45<23:47:15, 137.24s/it] 64%|██████▎   | 1087/1710 [10:31:03<17:33:12, 101.43s/it] 64%|██████▎   | 1088/1710 [10:31:22<13:14:26, 76.63s/it]  64%|██████▎   | 1089/1710 [10:31:38<10:07:34, 58.70s/it] 64%|██████▎   | 1090/1710 [10:32:02<8:18:36, 48.25s/it]                                                          64%|██████▎   | 1090/1710 [10:32:02<8:18:36, 48.25s/it] 64%|██████▍   | 1091/1710 [10:32:25<6:59:59, 40.71s/it] 64%|██████▍   | 1092/1710 [10:32:45<5:52:23, 34.21s/it] 64%|██████▍   | 1093/1710 [10:33:04<5:05:16, 29.69s/it] 64%|██████▍   | 1094/1710 [10:33:21<4:25:39, 25.88s/it] 64%|██████▍   | 1095/1710 [10:33:42<4:10:39, 24.45s/it] 64%|██████▍   | 1096/1710 [10:34:03<3:58:55, 23.35s/it] 64%|██████▍   | 1097/1710 [10:34:26<3:58:47, 23.37s/it] 64%|██████▍   | 1098/1710 [10:34:45<3:46:10, 22.17s/it] 64%|██████▍   | 1099/1710 [10:35:04<3:35:14, 21.14s/it] 64%|██████▍   | 1100/1710 [10:35:27<3:41:45, 21.81s/it]                                                         64%|██████▍   | 1100/1710 [10:35:27<3:41:45, 21.81s/it] 64%|██████▍   | 1101/1710 [10:35:45<3:29:30, 20.64s/it] 64%|██████▍   | 1102/1710 [10:36:03<3:19:08, 19.65s/it] 65%|██████▍   | 1103/1710 [10:36:22<3:18:50, 19.66s/it] 65%|██████▍   | 1104/1710 [10:36:37<3:03:20, 18.15s/it] 65%|██████▍   | 1105/1710 [10:37:02<3:23:08, 20.15s/it] 65%|██████▍   | 1106/1710 [10:37:20<3:15:44, 19.45s/it] 65%|██████▍   | 1107/1710 [10:37:39<3:14:27, 19.35s/it] 65%|██████▍   | 1108/1710 [10:37:57<3:11:49, 19.12s/it] 65%|██████▍   | 1109/1710 [10:38:17<3:13:32, 19.32s/it] 65%|██████▍   | 1110/1710 [10:38:33<3:03:23, 18.34s/it]                                                         65%|██████▍   | 1110/1710 [10:38:33<3:03:23, 18.34s/it] 65%|██████▍   | 1111/1710 [10:38:51<3:00:39, 18.10s/it] 65%|██████▌   | 1112/1710 [10:39:11<3:05:28, 18.61s/it] 65%|██████▌   | 1113/1710 [10:39:30<3:06:24, 18.74s/it] 65%|██████▌   | 1114/1710 [10:39:52<3:16:38, 19.80s/it] 65%|██████▌   | 1115/1710 [10:40:12<3:18:24, 20.01s/it] 65%|██████▌   | 1116/1710 [10:40:33<3:20:32, 20.26s/it] 65%|██████▌   | 1117/1710 [10:40:52<3:15:31, 19.78s/it] 65%|██████▌   | 1118/1710 [10:41:13<3:19:21, 20.21s/it] 65%|██████▌   | 1119/1710 [10:41:33<3:18:47, 20.18s/it] 65%|██████▌   | 1120/1710 [10:41:52<3:13:50, 19.71s/it]                                                         65%|██████▌   | 1120/1710 [10:41:52<3:13:50, 19.71s/it] 66%|██████▌   | 1121/1710 [10:42:07<3:01:08, 18.45s/it] 66%|██████▌   | 1122/1710 [10:42:24<2:56:49, 18.04s/it] 66%|██████▌   | 1123/1710 [10:42:43<2:58:51, 18.28s/it] 66%|██████▌   | 1124/1710 [10:43:01<2:55:41, 17.99s/it] 66%|██████▌   | 1125/1710 [10:43:19<2:57:23, 18.19s/it] 66%|██████▌   | 1126/1710 [10:43:39<3:00:52, 18.58s/it] 66%|██████▌   | 1127/1710 [10:43:59<3:04:43, 19.01s/it] 66%|██████▌   | 1128/1710 [10:44:19<3:08:48, 19.47s/it] 66%|██████▌   | 1129/1710 [10:44:38<3:07:03, 19.32s/it] 66%|██████▌   | 1130/1710 [10:44:58<3:06:58, 19.34s/it]                                                         66%|██████▌   | 1130/1710 [10:44:58<3:06:58, 19.34s/it] 66%|██████▌   | 1131/1710 [10:45:17<3:06:54, 19.37s/it] 66%|██████▌   | 1132/1710 [10:45:34<2:59:46, 18.66s/it] 66%|██████▋   | 1133/1710 [10:45:57<3:10:39, 19.83s/it] 66%|██████▋   | 1134/1710 [10:46:15<3:05:29, 19.32s/it] 66%|██████▋   | 1135/1710 [10:46:33<3:00:58, 18.88s/it] 66%|██████▋   | 1136/1710 [10:46:54<3:08:02, 19.66s/it] 66%|██████▋   | 1137/1710 [10:47:15<3:11:49, 20.09s/it] 67%|██████▋   | 1138/1710 [10:47:36<3:12:40, 20.21s/it] 67%|██████▋   | 1139/1710 [10:47:56<3:12:24, 20.22s/it] 67%|██████▋   | 1140/1710 [10:48:12<3:00:48, 19.03s/it]                                                         67%|██████▋   | 1140/1710 [10:48:12<3:00:48, 19.03s/it]{'loss': 0.0045, 'learning_rate': 3.136437790023317e-05, 'epoch': 19.12}
{'loss': 0.0061, 'learning_rate': 3.0479598731475058e-05, 'epoch': 19.3}
{'loss': 0.0067, 'learning_rate': 2.960197371301584e-05, 'epoch': 19.47}
{'loss': 0.0035, 'learning_rate': 2.8731824490973446e-05, 'epoch': 19.65}
{'loss': 0.0028, 'learning_rate': 2.786946997161576e-05, 'epoch': 19.82}
{'loss': 0.004, 'learning_rate': 2.7015226204482857e-05, 'epoch': 20.0}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:09<05:16,  4.88s/it][A
  4%|▍         | 3/67 [00:17<06:24,  6.01s/it][A
  6%|▌         | 4/67 [00:24<06:48,  6.49s/it][A
  7%|▋         | 5/67 [00:40<10:00,  9.68s/it][A
  9%|▉         | 6/67 [00:51<10:18, 10.13s/it][A
 10%|█         | 7/67 [01:04<11:11, 11.20s/it][A
 12%|█▏        | 8/67 [01:26<14:22, 14.62s/it][A
 13%|█▎        | 9/67 [01:44<15:08, 15.66s/it][A
 15%|█▍        | 10/67 [01:55<13:28, 14.19s/it][A
 16%|█▋        | 11/67 [02:08<12:52, 13.80s/it][A
 18%|█▊        | 12/67 [02:15<10:44, 11.73s/it][A
 19%|█▉        | 13/67 [02:21<08:55,  9.92s/it][A
 21%|██        | 14/67 [02:30<08:31,  9.66s/it][A
 22%|██▏       | 15/67 [02:40<08:24,  9.69s/it][A
 24%|██▍       | 16/67 [02:47<07:32,  8.87s/it][A
 25%|██▌       | 17/67 [03:06<10:03, 12.08s/it][A
 27%|██▋       | 18/67 [03:18<09:48, 12.00s/it][A
 28%|██▊       | 19/67 [03:34<10:34, 13.23s/it][A
 30%|██▉       | 20/67 [03:43<09:18, 11.87s/it][A
 31%|███▏      | 21/67 [04:09<12:25, 16.22s/it][A
 33%|███▎      | 22/67 [04:25<12:01, 16.04s/it][A
 34%|███▍      | 23/67 [04:33<09:59, 13.62s/it][A
 36%|███▌      | 24/67 [05:05<13:44, 19.17s/it][A
 37%|███▋      | 25/67 [05:22<12:59, 18.57s/it][A
 39%|███▉      | 26/67 [05:30<10:33, 15.45s/it][A
 40%|████      | 27/67 [05:44<10:02, 15.06s/it][A
 42%|████▏     | 28/67 [05:56<09:08, 14.06s/it][A
 43%|████▎     | 29/67 [06:03<07:35, 11.98s/it][A
 45%|████▍     | 30/67 [06:11<06:35, 10.68s/it][A
 46%|████▋     | 31/67 [06:16<05:24,  9.03s/it][A
 48%|████▊     | 32/67 [06:30<06:10, 10.58s/it][A
 49%|████▉     | 33/67 [06:52<07:57, 14.04s/it][A
 51%|█████     | 34/67 [07:03<07:13, 13.15s/it][A
 52%|█████▏    | 35/67 [07:15<06:46, 12.70s/it][A
 54%|█████▎    | 36/67 [07:27<06:25, 12.42s/it][A
 55%|█████▌    | 37/67 [07:33<05:18, 10.62s/it][A
 57%|█████▋    | 38/67 [07:43<05:00, 10.38s/it][A
 58%|█████▊    | 39/67 [07:55<05:02, 10.81s/it][A
 60%|█████▉    | 40/67 [08:02<04:25,  9.83s/it][A
 61%|██████    | 41/67 [08:15<04:40, 10.77s/it][A
 63%|██████▎   | 42/67 [08:28<04:39, 11.18s/it][A
 64%|██████▍   | 43/67 [08:40<04:34, 11.44s/it][A
 66%|██████▌   | 44/67 [08:56<05:00, 13.06s/it][A
 67%|██████▋   | 45/67 [09:02<03:59, 10.88s/it][A
 69%|██████▊   | 46/67 [09:10<03:30, 10.04s/it][A
 70%|███████   | 47/67 [09:26<03:54, 11.74s/it][A
 72%|███████▏  | 48/67 [09:36<03:35, 11.32s/it][A
 73%|███████▎  | 49/67 [09:54<03:59, 13.29s/it][A
 75%|███████▍  | 50/67 [10:06<03:36, 12.73s/it][A
 76%|███████▌  | 51/67 [10:18<03:22, 12.65s/it][A
 78%|███████▊  | 52/67 [10:31<03:10, 12.72s/it][A
 79%|███████▉  | 53/67 [10:43<02:53, 12.40s/it][A
 81%|████████  | 54/67 [10:51<02:27, 11.31s/it][A
 82%|████████▏ | 55/67 [11:06<02:27, 12.32s/it][A
 84%|████████▎ | 56/67 [11:26<02:39, 14.47s/it][A
 85%|████████▌ | 57/67 [11:46<02:43, 16.37s/it][A
 87%|████████▋ | 58/67 [12:26<03:29, 23.22s/it][A
 88%|████████▊ | 59/67 [12:42<02:50, 21.26s/it][A
 90%|████████▉ | 60/67 [13:02<02:24, 20.66s/it][A
 91%|█████████ | 61/67 [13:11<01:43, 17.27s/it][A
 93%|█████████▎| 62/67 [13:17<01:09, 13.94s/it][A
 94%|█████████▍| 63/67 [13:29<00:52, 13.21s/it][A
 96%|█████████▌| 64/67 [13:39<00:37, 12.52s/it][A
 97%|█████████▋| 65/67 [13:48<00:22, 11.27s/it][A
 99%|█████████▊| 66/67 [14:00<00:11, 11.56s/it][A
100%|██████████| 67/67 [14:02<00:00,  8.61s/it][A                                                        
                                               [A 67%|██████▋   | 1140/1710 [11:02:29<3:00:48, 19.03s/it]
100%|██████████| 67/67 [14:03<00:00,  8.61s/it][A
                                               [A{'f1_1': 0.43690349946977736, 'precision': 0.4463705308775731, 'recall': 0.42782969885773625}
{'f1': 0.4167550371155886, 'precision': 0.4257854821235103, 'recall': 0.40809968847352024}
{'eval_f1': 0.4167550371155886, 'eval_precision': 0.4257854821235103, 'eval_recall': 0.40809968847352024, 'eval_runtime': 856.6222, 'eval_samples_per_second': 0.463, 'eval_steps_per_second': 0.078, 'epoch': 20.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 67%|██████▋   | 1141/1710 [11:02:49<43:40:23, 276.32s/it] 67%|██████▋   | 1142/1710 [11:03:07<31:23:09, 198.92s/it] 67%|██████▋   | 1143/1710 [11:03:24<22:42:48, 144.21s/it] 67%|██████▋   | 1144/1710 [11:03:41<16:40:58, 106.11s/it] 67%|██████▋   | 1145/1710 [11:04:00<12:32:23, 79.90s/it]  67%|██████▋   | 1146/1710 [11:04:16<9:31:43, 60.82s/it]  67%|██████▋   | 1147/1710 [11:04:35<7:33:45, 48.36s/it] 67%|██████▋   | 1148/1710 [11:04:52<6:05:08, 38.98s/it] 67%|██████▋   | 1149/1710 [11:05:13<5:13:21, 33.51s/it] 67%|██████▋   | 1150/1710 [11:05:40<4:53:18, 31.43s/it]                                                         67%|██████▋   | 1150/1710 [11:05:40<4:53:18, 31.43s/it] 67%|██████▋   | 1151/1710 [11:06:04<4:33:32, 29.36s/it] 67%|██████▋   | 1152/1710 [11:06:25<4:08:41, 26.74s/it] 67%|██████▋   | 1153/1710 [11:06:44<3:47:23, 24.49s/it] 67%|██████▋   | 1154/1710 [11:07:00<3:24:06, 22.03s/it] 68%|██████▊   | 1155/1710 [11:07:19<3:13:42, 20.94s/it] 68%|██████▊   | 1156/1710 [11:07:36<3:03:20, 19.86s/it] 68%|██████▊   | 1157/1710 [11:07:54<2:58:48, 19.40s/it] 68%|██████▊   | 1158/1710 [11:08:19<3:13:02, 20.98s/it] 68%|██████▊   | 1159/1710 [11:08:42<3:17:07, 21.47s/it] 68%|██████▊   | 1160/1710 [11:09:00<3:09:30, 20.67s/it]                                                         68%|██████▊   | 1160/1710 [11:09:00<3:09:30, 20.67s/it] 68%|██████▊   | 1161/1710 [11:09:19<3:04:02, 20.11s/it] 68%|██████▊   | 1162/1710 [11:09:42<3:10:44, 20.88s/it] 68%|██████▊   | 1163/1710 [11:09:59<3:00:47, 19.83s/it] 68%|██████▊   | 1164/1710 [11:10:15<2:49:16, 18.60s/it] 68%|██████▊   | 1165/1710 [11:10:30<2:39:33, 17.57s/it] 68%|██████▊   | 1166/1710 [11:10:47<2:38:17, 17.46s/it] 68%|██████▊   | 1167/1710 [11:11:04<2:36:18, 17.27s/it] 68%|██████▊   | 1168/1710 [11:11:28<2:52:17, 19.07s/it] 68%|██████▊   | 1169/1710 [11:11:47<2:53:24, 19.23s/it] 68%|██████▊   | 1170/1710 [11:12:04<2:46:00, 18.45s/it]                                                         68%|██████▊   | 1170/1710 [11:12:04<2:46:00, 18.45s/it] 68%|██████▊   | 1171/1710 [11:12:19<2:37:19, 17.51s/it] 69%|██████▊   | 1172/1710 [11:12:40<2:45:01, 18.40s/it] 69%|██████▊   | 1173/1710 [11:12:57<2:42:03, 18.11s/it] 69%|██████▊   | 1174/1710 [11:13:15<2:40:29, 17.97s/it] 69%|██████▊   | 1175/1710 [11:13:42<3:06:21, 20.90s/it] 69%|██████▉   | 1176/1710 [11:14:01<2:58:53, 20.10s/it] 69%|██████▉   | 1177/1710 [11:14:20<2:57:34, 19.99s/it] 69%|██████▉   | 1178/1710 [11:14:38<2:50:47, 19.26s/it] 69%|██████▉   | 1179/1710 [11:14:57<2:48:45, 19.07s/it] 69%|██████▉   | 1180/1710 [11:15:18<2:54:41, 19.78s/it]                                                         69%|██████▉   | 1180/1710 [11:15:18<2:54:41, 19.78s/it] 69%|██████▉   | 1181/1710 [11:15:35<2:48:26, 19.11s/it] 69%|██████▉   | 1182/1710 [11:15:55<2:49:21, 19.24s/it] 69%|██████▉   | 1183/1710 [11:16:14<2:48:26, 19.18s/it] 69%|██████▉   | 1184/1710 [11:16:31<2:42:09, 18.50s/it] 69%|██████▉   | 1185/1710 [11:16:49<2:41:11, 18.42s/it] 69%|██████▉   | 1186/1710 [11:17:07<2:37:56, 18.08s/it] 69%|██████▉   | 1187/1710 [11:17:32<2:57:28, 20.36s/it] 69%|██████▉   | 1188/1710 [11:17:52<2:55:53, 20.22s/it] 70%|██████▉   | 1189/1710 [11:18:12<2:54:30, 20.10s/it] 70%|██████▉   | 1190/1710 [11:18:33<2:56:29, 20.36s/it]                                                         70%|██████▉   | 1190/1710 [11:18:33<2:56:29, 20.36s/it] 70%|██████▉   | 1191/1710 [11:18:51<2:50:35, 19.72s/it] 70%|██████▉   | 1192/1710 [11:19:11<2:50:34, 19.76s/it] 70%|██████▉   | 1193/1710 [11:19:28<2:44:19, 19.07s/it] 70%|██████▉   | 1194/1710 [11:19:46<2:38:58, 18.48s/it] 70%|██████▉   | 1195/1710 [11:20:02<2:33:41, 17.91s/it] 70%|██████▉   | 1196/1710 [11:20:20<2:33:41, 17.94s/it] 70%|███████   | 1197/1710 [11:20:38<2:34:21, 18.05s/it]{'loss': 0.0022, 'learning_rate': 2.6253600328613505e-05, 'epoch': 20.18}
{'loss': 0.0034, 'learning_rate': 2.5415626968490074e-05, 'epoch': 20.35}
{'loss': 0.0015, 'learning_rate': 2.4586663684402074e-05, 'epoch': 20.53}
{'loss': 0.0029, 'learning_rate': 2.3767014288133134e-05, 'epoch': 20.7}
{'loss': 0.0019, 'learning_rate': 2.29569791779636e-05, 'epoch': 20.88}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:09<05:17,  4.89s/it][A
  4%|▍         | 3/67 [00:17<06:31,  6.11s/it][A
  6%|▌         | 4/67 [00:24<06:52,  6.55s/it][A
  7%|▋         | 5/67 [00:39<09:33,  9.25s/it][A
  9%|▉         | 6/67 [00:54<11:21, 11.17s/it][A
 10%|█         | 7/67 [01:11<13:09, 13.16s/it][A
 12%|█▏        | 8/67 [01:33<15:44, 16.01s/it][A
 13%|█▎        | 9/67 [01:46<14:23, 14.88s/it][A
 15%|█▍        | 10/67 [01:55<12:27, 13.12s/it][A
 16%|█▋        | 11/67 [02:10<12:43, 13.64s/it][A
 18%|█▊        | 12/67 [02:25<12:51, 14.03s/it][A
 19%|█▉        | 13/67 [02:30<10:22, 11.52s/it][A
 21%|██        | 14/67 [02:39<09:30, 10.77s/it][A
 22%|██▏       | 15/67 [02:55<10:31, 12.15s/it][A
 24%|██▍       | 16/67 [03:00<08:39, 10.19s/it][A
 25%|██▌       | 17/67 [03:20<10:50, 13.00s/it][A
 27%|██▋       | 18/67 [03:32<10:18, 12.62s/it][A
 28%|██▊       | 19/67 [03:44<10:04, 12.60s/it][A
 30%|██▉       | 20/67 [03:53<08:56, 11.42s/it][A
 31%|███▏      | 21/67 [04:18<11:58, 15.61s/it][A
 33%|███▎      | 22/67 [04:34<11:41, 15.59s/it][A
 34%|███▍      | 23/67 [04:42<09:44, 13.28s/it][A
 36%|███▌      | 24/67 [04:56<09:39, 13.47s/it][A
 37%|███▋      | 25/67 [05:13<10:11, 14.56s/it][A
 39%|███▉      | 26/67 [05:21<08:38, 12.64s/it][A
 40%|████      | 27/67 [05:35<08:43, 13.08s/it][A
 42%|████▏     | 28/67 [05:45<07:52, 12.11s/it][A
 43%|████▎     | 29/67 [05:53<06:58, 11.01s/it][A
 45%|████▍     | 30/67 [06:01<06:09, 10.00s/it][A
 46%|████▋     | 31/67 [06:05<04:55,  8.20s/it][A
 48%|████▊     | 32/67 [06:16<05:18,  9.09s/it][A
 49%|████▉     | 33/67 [06:33<06:33, 11.57s/it][A
 51%|█████     | 34/67 [06:44<06:16, 11.41s/it][A
 52%|█████▏    | 35/67 [06:56<06:10, 11.59s/it][A
 54%|█████▎    | 36/67 [07:05<05:27, 10.57s/it][A
 55%|█████▌    | 37/67 [07:10<04:26,  8.87s/it][A
 57%|█████▋    | 38/67 [07:19<04:25,  9.14s/it][A
 58%|█████▊    | 39/67 [07:26<03:57,  8.47s/it][A
 60%|█████▉    | 40/67 [07:36<04:00,  8.89s/it][A
 61%|██████    | 41/67 [07:51<04:37, 10.69s/it][A
 63%|██████▎   | 42/67 [08:03<04:37, 11.09s/it][A
 64%|██████▍   | 43/67 [08:15<04:32, 11.35s/it][A
 66%|██████▌   | 44/67 [08:27<04:26, 11.60s/it][A
 67%|██████▋   | 45/67 [08:33<03:36,  9.84s/it][A
 69%|██████▊   | 46/67 [08:41<03:16,  9.36s/it][A
 70%|███████   | 47/67 [08:57<03:46, 11.35s/it][A
 72%|███████▏  | 48/67 [09:07<03:29, 11.03s/it][A
 73%|███████▎  | 49/67 [09:25<03:55, 13.09s/it][A
 75%|███████▍  | 50/67 [09:37<03:33, 12.57s/it][A
 76%|███████▌  | 51/67 [09:49<03:20, 12.54s/it][A
 78%|███████▊  | 52/67 [09:56<02:40, 10.73s/it][A
 79%|███████▉  | 53/67 [10:07<02:34, 11.01s/it][A
 81%|████████  | 54/67 [10:15<02:10, 10.05s/it][A
 82%|████████▏ | 55/67 [10:30<02:17, 11.45s/it][A
 84%|████████▎ | 56/67 [10:49<02:32, 13.87s/it][A
 85%|████████▌ | 57/67 [11:15<02:54, 17.40s/it][A
 87%|████████▋ | 58/67 [11:54<03:35, 23.94s/it][A
 88%|████████▊ | 59/67 [12:11<02:53, 21.73s/it][A
 90%|████████▉ | 60/67 [12:30<02:26, 20.97s/it][A
 91%|█████████ | 61/67 [12:39<01:44, 17.47s/it][A
 93%|█████████▎| 62/67 [12:49<01:16, 15.29s/it][A
 94%|█████████▍| 63/67 [13:01<00:56, 14.14s/it][A
 96%|█████████▌| 64/67 [13:12<00:39, 13.19s/it][A
 97%|█████████▋| 65/67 [13:20<00:23, 11.73s/it][A
 99%|█████████▊| 66/67 [13:32<00:11, 11.87s/it][A
100%|██████████| 67/67 [13:34<00:00,  8.82s/it][A                                                        
                                               [A 70%|███████   | 1197/1710 [11:34:26<2:34:21, 18.05s/it]
100%|██████████| 67/67 [13:35<00:00,  8.82s/it][A
                                               [A{'f1_1': 0.4358302776322682, 'precision': 0.4397463002114165, 'recall': 0.43198338525441327}
{'f1': 0.42430591932949185, 'precision': 0.4281183932346723, 'recall': 0.4205607476635514}
{'eval_f1': 0.42430591932949185, 'eval_precision': 0.4281183932346723, 'eval_recall': 0.4205607476635514, 'eval_runtime': 827.8093, 'eval_samples_per_second': 0.48, 'eval_steps_per_second': 0.081, 'epoch': 21.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 70%|███████   | 1198/1710 [11:34:49<38:05:17, 267.81s/it] 70%|███████   | 1199/1710 [11:35:05<27:17:50, 192.31s/it] 70%|███████   | 1200/1710 [11:35:24<19:53:05, 140.36s/it]                                                           70%|███████   | 1200/1710 [11:35:24<19:53:05, 140.36s/it] 70%|███████   | 1201/1710 [11:35:43<14:41:18, 103.89s/it] 70%|███████   | 1202/1710 [11:36:01<11:00:56, 78.06s/it]  70%|███████   | 1203/1710 [11:36:17<8:23:29, 59.59s/it]  70%|███████   | 1204/1710 [11:36:39<6:46:14, 48.17s/it] 70%|███████   | 1205/1710 [11:36:59<5:34:05, 39.70s/it] 71%|███████   | 1206/1710 [11:37:22<4:51:20, 34.68s/it] 71%|███████   | 1207/1710 [11:37:40<4:08:24, 29.63s/it] 71%|███████   | 1208/1710 [11:37:56<3:34:45, 25.67s/it] 71%|███████   | 1209/1710 [11:38:13<3:11:45, 22.96s/it] 71%|███████   | 1210/1710 [11:38:33<3:04:00, 22.08s/it]                                                         71%|███████   | 1210/1710 [11:38:33<3:04:00, 22.08s/it] 71%|███████   | 1211/1710 [11:38:54<3:01:55, 21.88s/it] 71%|███████   | 1212/1710 [11:39:18<3:07:39, 22.61s/it] 71%|███████   | 1213/1710 [11:39:37<2:57:01, 21.37s/it] 71%|███████   | 1214/1710 [11:39:57<2:53:37, 21.00s/it] 71%|███████   | 1215/1710 [11:40:14<2:44:23, 19.93s/it] 71%|███████   | 1216/1710 [11:40:32<2:37:15, 19.10s/it] 71%|███████   | 1217/1710 [11:40:59<2:56:08, 21.44s/it] 71%|███████   | 1218/1710 [11:41:15<2:43:20, 19.92s/it] 71%|███████▏  | 1219/1710 [11:41:39<2:54:06, 21.28s/it] 71%|███████▏  | 1220/1710 [11:42:02<2:57:13, 21.70s/it]                                                         71%|███████▏  | 1220/1710 [11:42:02<2:57:13, 21.70s/it] 71%|███████▏  | 1221/1710 [11:42:18<2:43:58, 20.12s/it] 71%|███████▏  | 1222/1710 [11:42:38<2:41:21, 19.84s/it] 72%|███████▏  | 1223/1710 [11:42:57<2:39:34, 19.66s/it] 72%|███████▏  | 1224/1710 [11:43:13<2:31:18, 18.68s/it] 72%|███████▏  | 1225/1710 [11:43:34<2:36:51, 19.41s/it] 72%|███████▏  | 1226/1710 [11:43:54<2:36:22, 19.39s/it] 72%|███████▏  | 1227/1710 [11:44:11<2:31:32, 18.83s/it] 72%|███████▏  | 1228/1710 [11:44:32<2:34:43, 19.26s/it] 72%|███████▏  | 1229/1710 [11:44:49<2:29:33, 18.66s/it] 72%|███████▏  | 1230/1710 [11:45:10<2:35:27, 19.43s/it]                                                         72%|███████▏  | 1230/1710 [11:45:10<2:35:27, 19.43s/it] 72%|███████▏  | 1231/1710 [11:45:31<2:37:57, 19.79s/it] 72%|███████▏  | 1232/1710 [11:45:49<2:33:18, 19.24s/it] 72%|███████▏  | 1233/1710 [11:46:07<2:30:33, 18.94s/it] 72%|███████▏  | 1234/1710 [11:46:24<2:25:09, 18.30s/it] 72%|███████▏  | 1235/1710 [11:46:47<2:36:03, 19.71s/it] 72%|███████▏  | 1236/1710 [11:47:04<2:30:59, 19.11s/it] 72%|███████▏  | 1237/1710 [11:47:21<2:24:16, 18.30s/it] 72%|███████▏  | 1238/1710 [11:47:39<2:24:17, 18.34s/it] 72%|███████▏  | 1239/1710 [11:47:58<2:25:21, 18.52s/it] 73%|███████▎  | 1240/1710 [11:48:16<2:24:35, 18.46s/it]                                                         73%|███████▎  | 1240/1710 [11:48:16<2:24:35, 18.46s/it] 73%|███████▎  | 1241/1710 [11:48:36<2:25:57, 18.67s/it] 73%|███████▎  | 1242/1710 [11:48:56<2:28:27, 19.03s/it] 73%|███████▎  | 1243/1710 [11:49:12<2:21:38, 18.20s/it] 73%|███████▎  | 1244/1710 [11:49:38<2:39:16, 20.51s/it] 73%|███████▎  | 1245/1710 [11:49:54<2:30:00, 19.36s/it] 73%|███████▎  | 1246/1710 [11:50:12<2:25:47, 18.85s/it] 73%|███████▎  | 1247/1710 [11:50:30<2:23:50, 18.64s/it] 73%|███████▎  | 1248/1710 [11:50:47<2:19:42, 18.14s/it] 73%|███████▎  | 1249/1710 [11:51:12<2:34:35, 20.12s/it] 73%|███████▎  | 1250/1710 [11:51:29<2:26:55, 19.16s/it]                                                         73%|███████▎  | 1250/1710 [11:51:29<2:26:55, 19.16s/it] 73%|███████▎  | 1251/1710 [11:51:48<2:26:22, 19.13s/it] 73%|███████▎  | 1252/1710 [11:52:05<2:22:21, 18.65s/it] 73%|███████▎  | 1253/1710 [11:52:25<2:23:47, 18.88s/it] 73%|███████▎  | 1254/1710 [11:52:40<2:15:09, 17.78s/it]{'loss': 0.0023, 'learning_rate': 2.215685522857585e-05, 'epoch': 21.05}
{'loss': 0.0013, 'learning_rate': 2.1366935682250727e-05, 'epoch': 21.23}
{'loss': 0.0039, 'learning_rate': 2.0587510041395554e-05, 'epoch': 21.4}
{'loss': 0.002, 'learning_rate': 1.98188639624425e-05, 'epoch': 21.58}
{'loss': 0.0034, 'learning_rate': 1.9061279151156735e-05, 'epoch': 21.75}
{'loss': 0.0009, 'learning_rate': 1.831503325939231e-05, 'epoch': 21.93}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:38,  5.20s/it][A
  4%|▍         | 3/67 [00:16<05:50,  5.47s/it][A
  6%|▌         | 4/67 [00:23<06:24,  6.11s/it][A
  7%|▋         | 5/67 [00:41<10:30, 10.17s/it][A
  9%|▉         | 6/67 [00:53<11:07, 10.94s/it][A
 10%|█         | 7/67 [01:08<12:17, 12.30s/it][A
 12%|█▏        | 8/67 [01:30<15:05, 15.35s/it][A
 13%|█▎        | 9/67 [01:48<15:33, 16.10s/it][A
 15%|█▍        | 10/67 [01:59<13:44, 14.46s/it][A
 16%|█▋        | 11/67 [02:11<12:55, 13.84s/it][A
 18%|█▊        | 12/67 [02:18<10:45, 11.73s/it][A
 19%|█▉        | 13/67 [02:24<08:55,  9.92s/it][A
 21%|██        | 14/67 [02:33<08:31,  9.66s/it][A
 22%|██▏       | 15/67 [02:43<08:23,  9.68s/it][A
 24%|██▍       | 16/67 [02:48<07:11,  8.46s/it][A
 25%|██▌       | 17/67 [03:10<10:13, 12.28s/it][A
 27%|██▋       | 18/67 [03:21<09:53, 12.11s/it][A
 28%|██▊       | 19/67 [03:34<09:47, 12.25s/it][A
 30%|██▉       | 20/67 [03:43<08:46, 11.20s/it][A
 31%|███▏      | 21/67 [04:08<11:51, 15.47s/it][A
 33%|███▎      | 22/67 [04:24<11:39, 15.55s/it][A
 34%|███▍      | 23/67 [04:32<09:43, 13.26s/it][A
 36%|███▌      | 24/67 [05:02<13:13, 18.45s/it][A
 37%|███▋      | 25/67 [05:20<12:43, 18.18s/it][A
 39%|███▉      | 26/67 [05:28<10:21, 15.17s/it][A
 40%|████      | 27/67 [05:42<09:55, 14.88s/it][A
 42%|████▏     | 28/67 [05:52<08:41, 13.38s/it][A
 43%|████▎     | 29/67 [06:00<07:25, 11.73s/it][A
 45%|████▍     | 30/67 [06:08<06:28, 10.51s/it][A
 46%|████▋     | 31/67 [06:13<05:24,  9.02s/it][A
 48%|████▊     | 32/67 [06:24<05:33,  9.52s/it][A
 49%|████▉     | 33/67 [06:46<07:30, 13.25s/it][A
 51%|█████     | 34/67 [06:57<06:55, 12.59s/it][A
 52%|█████▏    | 35/67 [07:08<06:33, 12.30s/it][A
 54%|█████▎    | 36/67 [07:21<06:24, 12.42s/it][A
 55%|█████▌    | 37/67 [07:27<05:17, 10.60s/it][A
 57%|█████▋    | 38/67 [07:39<05:16, 10.92s/it][A
 58%|█████▊    | 39/67 [07:50<05:07, 10.96s/it][A
 60%|█████▉    | 40/67 [07:58<04:27,  9.91s/it][A
 61%|██████    | 41/67 [08:11<04:44, 10.94s/it][A
 63%|██████▎   | 42/67 [08:25<04:57, 11.92s/it][A
 64%|██████▍   | 43/67 [08:37<04:46, 11.92s/it][A
 66%|██████▌   | 44/67 [08:49<04:33, 11.90s/it][A
 67%|██████▋   | 45/67 [08:55<03:41, 10.05s/it][A
 69%|██████▊   | 46/67 [09:03<03:19,  9.49s/it][A
 70%|███████   | 47/67 [09:19<03:48, 11.42s/it][A
 72%|███████▏  | 48/67 [09:29<03:31, 11.13s/it][A
 73%|███████▎  | 49/67 [09:47<03:55, 13.07s/it][A
 75%|███████▍  | 50/67 [09:58<03:33, 12.56s/it][A
 76%|███████▌  | 51/67 [10:11<03:20, 12.51s/it][A
 78%|███████▊  | 52/67 [10:17<02:40, 10.70s/it][A
 79%|███████▉  | 53/67 [10:30<02:37, 11.25s/it][A
 81%|████████  | 54/67 [10:43<02:32, 11.77s/it][A
 82%|████████▏ | 55/67 [10:57<02:31, 12.64s/it][A
 84%|████████▎ | 56/67 [11:17<02:41, 14.64s/it][A
 85%|████████▌ | 57/67 [11:39<02:51, 17.12s/it][A
 87%|████████▋ | 58/67 [12:19<03:33, 23.76s/it][A
 88%|████████▊ | 59/67 [12:32<02:44, 20.59s/it][A
 90%|████████▉ | 60/67 [12:51<02:21, 20.18s/it][A
 91%|█████████ | 61/67 [13:00<01:41, 16.92s/it][A
 93%|█████████▎| 62/67 [13:09<01:11, 14.40s/it][A
 94%|█████████▍| 63/67 [13:19<00:52, 13.05s/it][A
 96%|█████████▌| 64/67 [13:30<00:37, 12.40s/it][A
 97%|█████████▋| 65/67 [13:38<00:22, 11.17s/it][A
 99%|█████████▊| 66/67 [13:50<00:11, 11.48s/it][A
100%|██████████| 67/67 [13:52<00:00,  8.54s/it][A                                                        
                                               [A 73%|███████▎  | 1254/1710 [12:06:51<2:15:09, 17.78s/it]
100%|██████████| 67/67 [13:53<00:00,  8.54s/it][A
                                               [A{'f1_1': 0.4435146443514644, 'precision': 0.44678609062170704, 'recall': 0.4402907580477674}
{'f1': 0.42887029288702927, 'precision': 0.4320337197049526, 'recall': 0.4257528556593977}
{'eval_f1': 0.42887029288702927, 'eval_precision': 0.4320337197049526, 'eval_recall': 0.4257528556593977, 'eval_runtime': 851.3701, 'eval_samples_per_second': 0.466, 'eval_steps_per_second': 0.079, 'epoch': 22.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 73%|███████▎  | 1255/1710 [12:07:11<34:36:55, 273.88s/it] 73%|███████▎  | 1256/1710 [12:07:28<24:48:46, 196.75s/it] 74%|███████▎  | 1257/1710 [12:07:45<17:56:48, 142.62s/it] 74%|███████▎  | 1258/1710 [12:08:07<13:22:00, 106.46s/it] 74%|███████▎  | 1259/1710 [12:08:25<10:01:38, 80.04s/it]  74%|███████▎  | 1260/1710 [12:08:46<7:47:40, 62.36s/it]                                                          74%|███████▎  | 1260/1710 [12:08:46<7:47:40, 62.36s/it] 74%|███████▎  | 1261/1710 [12:09:04<6:06:38, 48.99s/it] 74%|███████▍  | 1262/1710 [12:09:19<4:50:27, 38.90s/it] 74%|███████▍  | 1263/1710 [12:09:36<4:01:12, 32.38s/it] 74%|███████▍  | 1264/1710 [12:09:57<3:34:48, 28.90s/it] 74%|███████▍  | 1265/1710 [12:10:19<3:17:49, 26.67s/it] 74%|███████▍  | 1266/1710 [12:10:38<3:00:53, 24.44s/it] 74%|███████▍  | 1267/1710 [12:10:57<2:47:50, 22.73s/it] 74%|███████▍  | 1268/1710 [12:11:19<2:46:02, 22.54s/it] 74%|███████▍  | 1269/1710 [12:11:36<2:33:08, 20.84s/it] 74%|███████▍  | 1270/1710 [12:11:55<2:28:45, 20.28s/it]                                                         74%|███████▍  | 1270/1710 [12:11:55<2:28:45, 20.28s/it] 74%|███████▍  | 1271/1710 [12:12:15<2:27:59, 20.23s/it] 74%|███████▍  | 1272/1710 [12:12:34<2:24:49, 19.84s/it] 74%|███████▍  | 1273/1710 [12:12:55<2:27:50, 20.30s/it] 75%|███████▍  | 1274/1710 [12:13:14<2:23:59, 19.82s/it] 75%|███████▍  | 1275/1710 [12:13:38<2:32:23, 21.02s/it] 75%|███████▍  | 1276/1710 [12:14:01<2:37:12, 21.73s/it] 75%|███████▍  | 1277/1710 [12:14:17<2:25:22, 20.14s/it] 75%|███████▍  | 1278/1710 [12:14:35<2:18:52, 19.29s/it] 75%|███████▍  | 1279/1710 [12:14:56<2:22:05, 19.78s/it] 75%|███████▍  | 1280/1710 [12:15:14<2:18:42, 19.35s/it]                                                         75%|███████▍  | 1280/1710 [12:15:14<2:18:42, 19.35s/it] 75%|███████▍  | 1281/1710 [12:15:31<2:12:58, 18.60s/it] 75%|███████▍  | 1282/1710 [12:15:48<2:09:42, 18.18s/it] 75%|███████▌  | 1283/1710 [12:16:07<2:10:45, 18.37s/it] 75%|███████▌  | 1284/1710 [12:16:25<2:10:53, 18.44s/it] 75%|███████▌  | 1285/1710 [12:16:44<2:11:30, 18.57s/it] 75%|███████▌  | 1286/1710 [12:17:02<2:08:24, 18.17s/it] 75%|███████▌  | 1287/1710 [12:17:20<2:08:02, 18.16s/it] 75%|███████▌  | 1288/1710 [12:17:39<2:10:03, 18.49s/it] 75%|███████▌  | 1289/1710 [12:17:56<2:06:06, 17.97s/it] 75%|███████▌  | 1290/1710 [12:18:15<2:09:28, 18.50s/it]                                                         75%|███████▌  | 1290/1710 [12:18:15<2:09:28, 18.50s/it] 75%|███████▌  | 1291/1710 [12:18:37<2:14:59, 19.33s/it] 76%|███████▌  | 1292/1710 [12:19:01<2:24:06, 20.68s/it] 76%|███████▌  | 1293/1710 [12:19:20<2:20:34, 20.23s/it] 76%|███████▌  | 1294/1710 [12:19:44<2:28:38, 21.44s/it] 76%|███████▌  | 1295/1710 [12:20:10<2:36:44, 22.66s/it] 76%|███████▌  | 1296/1710 [12:20:27<2:25:14, 21.05s/it] 76%|███████▌  | 1297/1710 [12:20:45<2:19:15, 20.23s/it] 76%|███████▌  | 1298/1710 [12:21:06<2:19:31, 20.32s/it] 76%|███████▌  | 1299/1710 [12:21:23<2:12:32, 19.35s/it] 76%|███████▌  | 1300/1710 [12:21:42<2:11:03, 19.18s/it]                                                         76%|███████▌  | 1300/1710 [12:21:42<2:11:03, 19.18s/it] 76%|███████▌  | 1301/1710 [12:21:59<2:07:19, 18.68s/it] 76%|███████▌  | 1302/1710 [12:22:19<2:10:31, 19.20s/it] 76%|███████▌  | 1303/1710 [12:22:44<2:21:21, 20.84s/it] 76%|███████▋  | 1304/1710 [12:23:02<2:16:02, 20.10s/it] 76%|███████▋  | 1305/1710 [12:23:22<2:15:27, 20.07s/it] 76%|███████▋  | 1306/1710 [12:23:40<2:10:16, 19.35s/it] 76%|███████▋  | 1307/1710 [12:23:57<2:04:34, 18.55s/it] 76%|███████▋  | 1308/1710 [12:24:15<2:03:37, 18.45s/it] 77%|███████▋  | 1309/1710 [12:24:34<2:03:25, 18.47s/it] 77%|███████▋  | 1310/1710 [12:24:50<1:58:13, 17.73s/it]                                                         77%|███████▋  | 1310/1710 [12:24:50<1:58:13, 17.73s/it] 77%|███████▋  | 1311/1710 [12:25:10<2:02:59, 18.50s/it]{'loss': 0.0005, 'learning_rate': 1.7580399783333846e-05, 'epoch': 22.11}
{'loss': 0.0006, 'learning_rate': 1.6857647963261336e-05, 'epoch': 22.28}
{'loss': 0.0008, 'learning_rate': 1.6147042684874508e-05, 'epoch': 22.46}
{'loss': 0.0007, 'learning_rate': 1.544884438221338e-05, 'epoch': 22.63}
{'loss': 0.0025, 'learning_rate': 1.4763308942210108e-05, 'epoch': 22.81}
{'loss': 0.0013, 'learning_rate': 1.409068761090755e-05, 'epoch': 22.98}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:44,  5.31s/it][A
  4%|▍         | 3/67 [00:16<05:58,  5.60s/it][A
  6%|▌         | 4/67 [00:23<06:34,  6.26s/it][A
  7%|▋         | 5/67 [00:42<10:44, 10.39s/it][A
  9%|▉         | 6/67 [00:52<10:42, 10.53s/it][A
 10%|█         | 7/67 [01:10<12:48, 12.81s/it][A
 12%|█▏        | 8/67 [01:33<15:35, 15.86s/it][A
 13%|█▎        | 9/67 [01:51<16:10, 16.73s/it][A
 15%|█▍        | 10/67 [02:00<13:39, 14.38s/it][A
 16%|█▋        | 11/67 [02:18<14:14, 15.26s/it][A
 18%|█▊        | 12/67 [02:25<11:41, 12.75s/it][A
 19%|█▉        | 13/67 [02:30<09:35, 10.67s/it][A
 21%|██        | 14/67 [02:40<09:01, 10.22s/it][A
 22%|██▏       | 15/67 [02:48<08:18,  9.59s/it][A
 24%|██▍       | 16/67 [02:55<07:30,  8.83s/it][A
 25%|██▌       | 17/67 [03:15<10:06, 12.14s/it][A
 27%|██▋       | 18/67 [03:27<09:52, 12.08s/it][A
 28%|██▊       | 19/67 [03:42<10:22, 12.96s/it][A
 30%|██▉       | 20/67 [03:51<09:12, 11.75s/it][A
 31%|███▏      | 21/67 [04:16<12:16, 16.01s/it][A
 33%|███▎      | 22/67 [04:32<11:59, 15.99s/it][A
 34%|███▍      | 23/67 [04:41<09:59, 13.62s/it][A
 36%|███▌      | 24/67 [05:15<14:13, 19.84s/it][A
 37%|███▋      | 25/67 [05:35<14:00, 20.01s/it][A
 39%|███▉      | 26/67 [05:44<11:16, 16.49s/it][A
 40%|████      | 27/67 [05:58<10:35, 15.89s/it][A
 42%|████▏     | 28/67 [06:10<09:31, 14.66s/it][A
 43%|████▎     | 29/67 [06:17<07:52, 12.42s/it][A
 45%|████▍     | 30/67 [06:25<06:47, 11.01s/it][A
 46%|████▋     | 31/67 [06:29<05:21,  8.93s/it][A
 48%|████▊     | 32/67 [06:41<05:50, 10.01s/it][A
 49%|████▉     | 33/67 [07:04<07:46, 13.71s/it][A
 51%|█████     | 34/67 [07:14<07:01, 12.79s/it][A
 52%|█████▏    | 35/67 [07:26<06:40, 12.50s/it][A
 54%|█████▎    | 36/67 [07:35<05:48, 11.26s/it][A
 55%|█████▌    | 37/67 [07:41<04:55,  9.84s/it][A
 57%|█████▋    | 38/67 [07:55<05:17, 10.96s/it][A
 58%|█████▊    | 39/67 [08:07<05:15, 11.26s/it][A
 60%|█████▉    | 40/67 [08:17<04:54, 10.90s/it][A
 61%|██████    | 41/67 [08:30<05:01, 11.61s/it][A
 63%|██████▎   | 42/67 [08:44<05:11, 12.45s/it][A
 64%|██████▍   | 43/67 [08:57<04:57, 12.38s/it][A
 66%|██████▌   | 44/67 [09:14<05:16, 13.77s/it][A
 67%|██████▋   | 45/67 [09:19<04:10, 11.40s/it][A
 69%|██████▊   | 46/67 [09:28<03:39, 10.44s/it][A
 70%|███████   | 47/67 [09:44<04:02, 12.12s/it][A
 72%|███████▏  | 48/67 [09:54<03:41, 11.68s/it][A
 73%|███████▎  | 49/67 [10:12<04:04, 13.60s/it][A
 75%|███████▍  | 50/67 [10:24<03:41, 13.01s/it][A
 76%|███████▌  | 51/67 [10:43<03:56, 14.79s/it][A
 78%|███████▊  | 52/67 [11:00<03:49, 15.32s/it][A
 79%|███████▉  | 53/67 [11:13<03:27, 14.79s/it][A
 81%|████████  | 54/67 [11:21<02:45, 12.75s/it][A
 82%|████████▏ | 55/67 [11:36<02:40, 13.41s/it][A
 84%|████████▎ | 56/67 [11:56<02:48, 15.31s/it][A
 85%|████████▌ | 57/67 [12:19<02:56, 17.69s/it][A
 87%|████████▋ | 58/67 [12:59<03:39, 24.39s/it][A
 88%|████████▊ | 59/67 [13:14<02:53, 21.63s/it][A
 90%|████████▉ | 60/67 [13:34<02:27, 21.01s/it][A
 91%|█████████ | 61/67 [13:43<01:45, 17.57s/it][A
 93%|█████████▎| 62/67 [13:53<01:16, 15.24s/it][A
 94%|█████████▍| 63/67 [14:03<00:54, 13.57s/it][A
 96%|█████████▌| 64/67 [14:14<00:38, 12.83s/it][A
 97%|█████████▋| 65/67 [14:22<00:23, 11.52s/it][A
 99%|█████████▊| 66/67 [14:35<00:11, 11.77s/it][A
100%|██████████| 67/67 [14:36<00:00,  8.75s/it][A                                                        
                                               [A 77%|███████▋  | 1311/1710 [12:40:06<2:02:59, 18.50s/it]
100%|██████████| 67/67 [14:38<00:00,  8.75s/it][A
                                               [A{'f1_1': 0.448578811369509, 'precision': 0.44650205761316875, 'recall': 0.45067497403946}
{'f1': 0.4279069767441861, 'precision': 0.42592592592592593, 'recall': 0.42990654205607476}
{'eval_f1': 0.4279069767441861, 'eval_precision': 0.42592592592592593, 'eval_recall': 0.42990654205607476, 'eval_runtime': 896.2126, 'eval_samples_per_second': 0.443, 'eval_steps_per_second': 0.075, 'epoch': 23.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 77%|███████▋  | 1312/1710 [12:40:25<31:46:04, 287.35s/it] 77%|███████▋  | 1313/1710 [12:40:41<22:43:58, 206.14s/it] 77%|███████▋  | 1314/1710 [12:41:00<16:29:26, 149.92s/it] 77%|███████▋  | 1315/1710 [12:41:19<12:09:24, 110.80s/it] 77%|███████▋  | 1316/1710 [12:41:37<9:04:46, 82.96s/it]   77%|███████▋  | 1317/1710 [12:41:59<7:02:12, 64.46s/it] 77%|███████▋  | 1318/1710 [12:42:16<5:29:07, 50.38s/it] 77%|███████▋  | 1319/1710 [12:42:33<4:23:10, 40.38s/it] 77%|███████▋  | 1320/1710 [12:42:50<3:37:08, 33.41s/it]                                                         77%|███████▋  | 1320/1710 [12:42:50<3:37:08, 33.41s/it] 77%|███████▋  | 1321/1710 [12:43:09<3:08:21, 29.05s/it] 77%|███████▋  | 1322/1710 [12:43:25<2:41:30, 24.98s/it] 77%|███████▋  | 1323/1710 [12:43:42<2:25:11, 22.51s/it] 77%|███████▋  | 1324/1710 [12:43:59<2:15:23, 21.05s/it] 77%|███████▋  | 1325/1710 [12:44:21<2:16:01, 21.20s/it] 78%|███████▊  | 1326/1710 [12:44:43<2:17:12, 21.44s/it] 78%|███████▊  | 1327/1710 [12:45:02<2:12:41, 20.79s/it] 78%|███████▊  | 1328/1710 [12:45:20<2:07:57, 20.10s/it] 78%|███████▊  | 1329/1710 [12:45:48<2:21:11, 22.23s/it] 78%|███████▊  | 1330/1710 [12:46:06<2:13:19, 21.05s/it]                                                         78%|███████▊  | 1330/1710 [12:46:06<2:13:19, 21.05s/it] 78%|███████▊  | 1331/1710 [12:46:30<2:19:04, 22.02s/it] 78%|███████▊  | 1332/1710 [12:46:47<2:09:00, 20.48s/it] 78%|███████▊  | 1333/1710 [12:47:08<2:09:12, 20.56s/it] 78%|███████▊  | 1334/1710 [12:47:25<2:02:27, 19.54s/it] 78%|███████▊  | 1335/1710 [12:47:42<1:56:55, 18.71s/it] 78%|███████▊  | 1336/1710 [12:48:00<1:56:21, 18.67s/it] 78%|███████▊  | 1337/1710 [12:48:21<2:00:16, 19.35s/it] 78%|███████▊  | 1338/1710 [12:48:39<1:56:54, 18.86s/it] 78%|███████▊  | 1339/1710 [12:48:58<1:55:56, 18.75s/it] 78%|███████▊  | 1340/1710 [12:49:15<1:53:59, 18.49s/it]                                                         78%|███████▊  | 1340/1710 [12:49:15<1:53:59, 18.49s/it] 78%|███████▊  | 1341/1710 [12:49:32<1:49:43, 17.84s/it] 78%|███████▊  | 1342/1710 [12:49:55<1:59:43, 19.52s/it] 79%|███████▊  | 1343/1710 [12:50:16<2:00:54, 19.77s/it] 79%|███████▊  | 1344/1710 [12:50:35<2:00:27, 19.75s/it] 79%|███████▊  | 1345/1710 [12:50:51<1:52:34, 18.51s/it] 79%|███████▊  | 1346/1710 [12:51:12<1:56:13, 19.16s/it] 79%|███████▉  | 1347/1710 [12:51:34<2:02:04, 20.18s/it] 79%|███████▉  | 1348/1710 [12:51:53<1:59:55, 19.88s/it] 79%|███████▉  | 1349/1710 [12:52:11<1:56:14, 19.32s/it] 79%|███████▉  | 1350/1710 [12:52:32<1:57:40, 19.61s/it]                                                         79%|███████▉  | 1350/1710 [12:52:32<1:57:40, 19.61s/it] 79%|███████▉  | 1351/1710 [12:52:50<1:55:10, 19.25s/it] 79%|███████▉  | 1352/1710 [12:53:09<1:54:49, 19.24s/it] 79%|███████▉  | 1353/1710 [12:53:26<1:50:29, 18.57s/it] 79%|███████▉  | 1354/1710 [12:53:51<2:00:44, 20.35s/it] 79%|███████▉  | 1355/1710 [12:54:10<1:57:44, 19.90s/it] 79%|███████▉  | 1356/1710 [12:54:29<1:56:27, 19.74s/it] 79%|███████▉  | 1357/1710 [12:54:46<1:52:04, 19.05s/it] 79%|███████▉  | 1358/1710 [12:55:07<1:53:44, 19.39s/it] 79%|███████▉  | 1359/1710 [12:55:25<1:51:43, 19.10s/it] 80%|███████▉  | 1360/1710 [12:55:45<1:53:44, 19.50s/it]                                                         80%|███████▉  | 1360/1710 [12:55:45<1:53:44, 19.50s/it] 80%|███████▉  | 1361/1710 [12:56:06<1:55:40, 19.89s/it] 80%|███████▉  | 1362/1710 [12:56:25<1:52:51, 19.46s/it] 80%|███████▉  | 1363/1710 [12:56:42<1:48:40, 18.79s/it] 80%|███████▉  | 1364/1710 [12:57:04<1:53:44, 19.72s/it] 80%|███████▉  | 1365/1710 [12:57:26<1:57:40, 20.46s/it] 80%|███████▉  | 1366/1710 [12:57:44<1:52:47, 19.67s/it] 80%|███████▉  | 1367/1710 [12:58:01<1:47:45, 18.85s/it] 80%|████████  | 1368/1710 [12:58:22<1:51:54, 19.63s/it]{'loss': 0.0006, 'learning_rate': 1.3431226901378463e-05, 'epoch': 23.16}
{'loss': 0.0007, 'learning_rate': 1.2785168503379475e-05, 'epoch': 23.33}
{'loss': 0.0009, 'learning_rate': 1.2152749194772784e-05, 'epoch': 23.51}
{'loss': 0.0014, 'learning_rate': 1.1534200754747925e-05, 'epoch': 23.68}
{'loss': 0.0006, 'learning_rate': 1.0929749878875667e-05, 'epoch': 23.86}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:43,  5.29s/it][A
  4%|▍         | 3/67 [00:18<06:46,  6.36s/it][A
  6%|▌         | 4/67 [00:25<07:03,  6.73s/it][A
  7%|▋         | 5/67 [00:37<08:53,  8.60s/it][A
  9%|▉         | 6/67 [00:53<10:56, 10.77s/it][A
 10%|█         | 7/67 [01:10<12:55, 12.92s/it][A
 12%|█▏        | 8/67 [01:32<15:34, 15.85s/it][A
 13%|█▎        | 9/67 [01:45<14:18, 14.80s/it][A
 15%|█▍        | 10/67 [01:54<12:22, 13.03s/it][A
 16%|█▋        | 11/67 [02:09<12:50, 13.76s/it][A
 18%|█▊        | 12/67 [02:16<10:43, 11.70s/it][A
 19%|█▉        | 13/67 [02:23<09:17, 10.33s/it][A
 21%|██        | 14/67 [02:32<08:48,  9.96s/it][A
 22%|██▏       | 15/67 [02:42<08:35,  9.92s/it][A
 24%|██▍       | 16/67 [02:49<07:41,  9.04s/it][A
 25%|██▌       | 17/67 [03:11<10:37, 12.75s/it][A
 27%|██▋       | 18/67 [03:23<10:14, 12.53s/it][A
 28%|██▊       | 19/67 [03:35<10:03, 12.58s/it][A
 30%|██▉       | 20/67 [03:44<08:58, 11.47s/it][A
 31%|███▏      | 21/67 [04:10<12:03, 15.74s/it][A
 33%|███▎      | 22/67 [04:26<11:49, 15.76s/it][A
 34%|███▍      | 23/67 [04:34<09:50, 13.43s/it][A
 36%|███▌      | 24/67 [04:51<10:30, 14.66s/it][A
 37%|███▋      | 25/67 [05:09<10:53, 15.55s/it][A
 39%|███▉      | 26/67 [05:21<09:55, 14.51s/it][A
 40%|████      | 27/67 [05:35<09:38, 14.47s/it][A
 42%|████▏     | 28/67 [05:47<08:53, 13.68s/it][A
 43%|████▎     | 29/67 [05:54<07:25, 11.72s/it][A
 45%|████▍     | 30/67 [06:02<06:28, 10.51s/it][A
 46%|████▋     | 31/67 [06:11<05:59, 10.00s/it][A
 48%|████▊     | 32/67 [06:23<06:17, 10.80s/it][A
 49%|████▉     | 33/67 [06:41<07:17, 12.86s/it][A
 51%|█████     | 34/67 [06:52<06:41, 12.16s/it][A
 52%|█████▏    | 35/67 [07:03<06:25, 12.04s/it][A
 54%|█████▎    | 36/67 [07:15<06:11, 11.98s/it][A
 55%|█████▌    | 37/67 [07:22<05:09, 10.32s/it][A
 57%|█████▋    | 38/67 [07:42<06:23, 13.22s/it][A
 58%|█████▊    | 39/67 [07:54<05:58, 12.82s/it][A
 60%|█████▉    | 40/67 [08:04<05:23, 11.97s/it][A
 61%|██████    | 41/67 [08:17<05:21, 12.36s/it][A
 63%|██████▎   | 42/67 [08:31<05:22, 12.91s/it][A
 64%|██████▍   | 43/67 [08:43<05:03, 12.65s/it][A
 66%|██████▌   | 44/67 [09:00<05:20, 13.94s/it][A
 67%|██████▋   | 45/67 [09:06<04:12, 11.49s/it][A
 69%|██████▊   | 46/67 [09:14<03:39, 10.47s/it][A
 70%|███████   | 47/67 [09:29<04:00, 12.02s/it][A
 72%|███████▏  | 48/67 [09:40<03:40, 11.59s/it][A
 73%|███████▎  | 49/67 [09:58<04:03, 13.51s/it][A
 75%|███████▍  | 50/67 [10:10<03:39, 12.90s/it][A
 76%|███████▌  | 51/67 [10:29<03:58, 14.91s/it][A
 78%|███████▊  | 52/67 [10:42<03:34, 14.27s/it][A
 79%|███████▉  | 53/67 [10:54<03:09, 13.52s/it][A
 81%|████████  | 54/67 [11:04<02:42, 12.53s/it][A
 82%|████████▏ | 55/67 [11:19<02:38, 13.23s/it][A
 84%|████████▎ | 56/67 [11:38<02:46, 15.15s/it][A
 85%|████████▌ | 57/67 [11:59<02:46, 16.68s/it][A
 87%|████████▋ | 58/67 [12:39<03:32, 23.63s/it][A
 88%|████████▊ | 59/67 [12:55<02:52, 21.59s/it][A
 90%|████████▉ | 60/67 [13:15<02:26, 20.91s/it][A
 91%|█████████ | 61/67 [13:24<01:44, 17.46s/it][A
 93%|█████████▎| 62/67 [13:32<01:12, 14.59s/it][A
 94%|█████████▍| 63/67 [13:42<00:52, 13.10s/it][A
 96%|█████████▌| 64/67 [13:53<00:37, 12.46s/it][A
 97%|█████████▋| 65/67 [14:01<00:22, 11.24s/it][A
 99%|█████████▊| 66/67 [14:13<00:11, 11.56s/it][A
100%|██████████| 67/67 [14:16<00:00,  8.92s/it][A                                                        
                                               [A 80%|████████  | 1368/1710 [13:12:58<1:51:54, 19.63s/it]
100%|██████████| 67/67 [14:17<00:00,  8.92s/it][A
                                               [A{'f1_1': 0.4522457408363449, 'precision': 0.44969199178644764, 'recall': 0.45482866043613707}
{'f1': 0.4305627258647393, 'precision': 0.42813141683778233, 'recall': 0.43302180685358255}
{'eval_f1': 0.4305627258647393, 'eval_precision': 0.42813141683778233, 'eval_recall': 0.43302180685358255, 'eval_runtime': 875.766, 'eval_samples_per_second': 0.453, 'eval_steps_per_second': 0.077, 'epoch': 24.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 80%|████████  | 1369/1710 [13:13:18<26:45:14, 282.45s/it] 80%|████████  | 1370/1710 [13:13:38<19:14:55, 203.81s/it]                                                           80%|████████  | 1370/1710 [13:13:38<19:14:55, 203.81s/it] 80%|████████  | 1371/1710 [13:13:58<14:00:27, 148.75s/it] 80%|████████  | 1372/1710 [13:14:19<10:20:41, 110.18s/it] 80%|████████  | 1373/1710 [13:14:36<7:43:03, 82.45s/it]   80%|████████  | 1374/1710 [13:14:55<5:54:26, 63.29s/it] 80%|████████  | 1375/1710 [13:15:20<4:49:10, 51.79s/it] 80%|████████  | 1376/1710 [13:15:38<3:52:25, 41.75s/it] 81%|████████  | 1377/1710 [13:15:57<3:13:36, 34.88s/it] 81%|████████  | 1378/1710 [13:16:15<2:45:14, 29.86s/it] 81%|████████  | 1379/1710 [13:16:32<2:23:44, 26.06s/it] 81%|████████  | 1380/1710 [13:16:50<2:08:32, 23.37s/it]                                                         81%|████████  | 1380/1710 [13:16:50<2:08:32, 23.37s/it] 81%|████████  | 1381/1710 [13:17:15<2:12:15, 24.12s/it] 81%|████████  | 1382/1710 [13:17:39<2:10:30, 23.87s/it] 81%|████████  | 1383/1710 [13:17:58<2:02:31, 22.48s/it] 81%|████████  | 1384/1710 [13:18:15<1:53:11, 20.83s/it] 81%|████████  | 1385/1710 [13:18:38<1:56:54, 21.58s/it] 81%|████████  | 1386/1710 [13:18:56<1:49:31, 20.28s/it] 81%|████████  | 1387/1710 [13:19:15<1:47:31, 19.97s/it] 81%|████████  | 1388/1710 [13:19:33<1:44:30, 19.47s/it] 81%|████████  | 1389/1710 [13:19:58<1:52:30, 21.03s/it] 81%|████████▏ | 1390/1710 [13:20:14<1:45:13, 19.73s/it]                                                         81%|████████▏ | 1390/1710 [13:20:14<1:45:13, 19.73s/it] 81%|████████▏ | 1391/1710 [13:20:33<1:43:10, 19.41s/it] 81%|████████▏ | 1392/1710 [13:20:54<1:45:54, 19.98s/it] 81%|████████▏ | 1393/1710 [13:21:17<1:49:37, 20.75s/it] 82%|████████▏ | 1394/1710 [13:21:33<1:41:31, 19.28s/it] 82%|████████▏ | 1395/1710 [13:21:52<1:41:32, 19.34s/it] 82%|████████▏ | 1396/1710 [13:22:11<1:40:25, 19.19s/it] 82%|████████▏ | 1397/1710 [13:22:29<1:37:58, 18.78s/it] 82%|████████▏ | 1398/1710 [13:22:51<1:42:20, 19.68s/it] 82%|████████▏ | 1399/1710 [13:23:10<1:42:07, 19.70s/it] 82%|████████▏ | 1400/1710 [13:23:30<1:41:14, 19.59s/it]                                                         82%|████████▏ | 1400/1710 [13:23:30<1:41:14, 19.59s/it] 82%|████████▏ | 1401/1710 [13:23:46<1:34:55, 18.43s/it] 82%|████████▏ | 1402/1710 [13:24:05<1:36:33, 18.81s/it] 82%|████████▏ | 1403/1710 [13:24:23<1:34:17, 18.43s/it] 82%|████████▏ | 1404/1710 [13:24:48<1:44:29, 20.49s/it] 82%|████████▏ | 1405/1710 [13:25:06<1:39:46, 19.63s/it] 82%|████████▏ | 1406/1710 [13:25:24<1:38:09, 19.37s/it] 82%|████████▏ | 1407/1710 [13:25:42<1:35:23, 18.89s/it] 82%|████████▏ | 1408/1710 [13:26:02<1:36:38, 19.20s/it] 82%|████████▏ | 1409/1710 [13:26:21<1:35:06, 18.96s/it] 82%|████████▏ | 1410/1710 [13:26:39<1:34:08, 18.83s/it]                                                         82%|████████▏ | 1410/1710 [13:26:39<1:34:08, 18.83s/it] 83%|████████▎ | 1411/1710 [13:26:56<1:30:59, 18.26s/it] 83%|████████▎ | 1412/1710 [13:27:14<1:30:34, 18.24s/it] 83%|████████▎ | 1413/1710 [13:27:36<1:34:51, 19.16s/it] 83%|████████▎ | 1414/1710 [13:27:54<1:33:06, 18.87s/it] 83%|████████▎ | 1415/1710 [13:28:17<1:38:45, 20.09s/it] 83%|████████▎ | 1416/1710 [13:28:40<1:43:42, 21.17s/it] 83%|████████▎ | 1417/1710 [13:28:58<1:38:25, 20.16s/it] 83%|████████▎ | 1418/1710 [13:29:18<1:37:30, 20.03s/it] 83%|████████▎ | 1419/1710 [13:29:38<1:37:44, 20.15s/it] 83%|████████▎ | 1420/1710 [13:29:54<1:31:12, 18.87s/it]                                                         83%|████████▎ | 1420/1710 [13:29:54<1:31:12, 18.87s/it] 83%|████████▎ | 1421/1710 [13:30:11<1:27:32, 18.17s/it] 83%|████████▎ | 1422/1710 [13:30:29<1:27:59, 18.33s/it] 83%|████████▎ | 1423/1710 [13:30:46<1:25:25, 17.86s/it] 83%|████████▎ | 1424/1710 [13:31:06<1:28:33, 18.58s/it] 83%|████████▎ | 1425/1710 [13:31:26<1:29:04, 18.75s/it]{'loss': 0.0002, 'learning_rate': 1.0339618096024945e-05, 'epoch': 24.04}
{'loss': 0.0007, 'learning_rate': 9.764021687173425e-06, 'epoch': 24.21}
{'loss': 0.0003, 'learning_rate': 9.203171606141337e-06, 'epoch': 24.39}
{'loss': 0.0003, 'learning_rate': 8.657273402277799e-06, 'epoch': 24.56}
{'loss': 0.0003, 'learning_rate': 8.126527145127726e-06, 'epoch': 24.74}
{'loss': 0.0004, 'learning_rate': 7.61112735110715e-06, 'epoch': 24.91}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:39,  5.22s/it][A
  4%|▍         | 3/67 [00:18<06:41,  6.27s/it][A
  6%|▌         | 4/67 [00:25<06:57,  6.63s/it][A
  7%|▋         | 5/67 [00:40<10:02,  9.71s/it][A
  9%|▉         | 6/67 [00:51<10:19, 10.16s/it][A
 10%|█         | 7/67 [01:09<12:30, 12.51s/it][A
 12%|█▏        | 8/67 [01:31<15:14, 15.49s/it][A
 13%|█▎        | 9/67 [01:49<15:40, 16.22s/it][A
 15%|█▍        | 10/67 [01:58<13:20, 14.04s/it][A
 16%|█▋        | 11/67 [02:13<13:30, 14.46s/it][A
 18%|█▊        | 12/67 [02:20<11:10, 12.19s/it][A
 19%|█▉        | 13/67 [02:26<09:12, 10.24s/it][A
 21%|██        | 14/67 [02:35<08:44,  9.89s/it][A
 22%|██▏       | 15/67 [02:45<08:33,  9.87s/it][A
 24%|██▍       | 16/67 [02:52<07:32,  8.88s/it][A
 25%|██▌       | 17/67 [03:11<10:06, 12.13s/it][A
 27%|██▋       | 18/67 [03:23<09:50, 12.04s/it][A
 28%|██▊       | 19/67 [03:36<09:47, 12.24s/it][A
 30%|██▉       | 20/67 [03:45<08:48, 11.24s/it][A
 31%|███▏      | 21/67 [04:10<11:56, 15.58s/it][A
 33%|███▎      | 22/67 [04:26<11:45, 15.67s/it][A
 34%|███▍      | 23/67 [04:34<09:48, 13.37s/it][A
 36%|███▌      | 24/67 [05:09<14:13, 19.84s/it][A
 37%|███▋      | 25/67 [05:26<13:20, 19.07s/it][A
 39%|███▉      | 26/67 [05:36<11:04, 16.20s/it][A
 40%|████      | 27/67 [05:50<10:25, 15.63s/it][A
 42%|████▏     | 28/67 [06:02<09:23, 14.44s/it][A
 43%|████▎     | 29/67 [06:09<07:45, 12.25s/it][A
 45%|████▍     | 30/67 [06:17<06:42, 10.88s/it][A
 46%|████▋     | 31/67 [06:21<05:17,  8.81s/it][A
 48%|████▊     | 32/67 [06:33<05:48,  9.96s/it][A
 49%|████▉     | 33/67 [06:55<07:42, 13.60s/it][A
 51%|█████     | 34/67 [07:07<07:04, 12.86s/it][A
 52%|█████▏    | 35/67 [07:18<06:40, 12.52s/it][A
 54%|█████▎    | 36/67 [07:27<05:48, 11.24s/it][A
 55%|█████▌    | 37/67 [07:33<04:54,  9.81s/it][A
 57%|█████▋    | 38/67 [07:45<05:00, 10.36s/it][A
 58%|█████▊    | 39/67 [07:57<05:02, 10.81s/it][A
 60%|█████▉    | 40/67 [08:07<04:45, 10.57s/it][A
 61%|██████    | 41/67 [08:28<06:00, 13.85s/it][A
 63%|██████▎   | 42/67 [08:42<05:48, 13.94s/it][A
 64%|██████▍   | 43/67 [08:54<05:21, 13.38s/it][A
 66%|██████▌   | 44/67 [09:09<05:18, 13.85s/it][A
 67%|██████▋   | 45/67 [09:15<04:11, 11.44s/it][A
 69%|██████▊   | 46/67 [09:23<03:39, 10.44s/it][A
 70%|███████   | 47/67 [09:39<04:00, 12.00s/it][A
 72%|███████▏  | 48/67 [09:50<03:43, 11.79s/it][A
 73%|███████▎  | 49/67 [10:08<04:05, 13.65s/it][A
 75%|███████▍  | 50/67 [10:21<03:48, 13.46s/it][A
 76%|███████▌  | 51/67 [10:40<04:01, 15.07s/it][A
 78%|███████▊  | 52/67 [10:53<03:35, 14.39s/it][A
 79%|███████▉  | 53/67 [11:08<03:26, 14.78s/it][A
 81%|████████  | 54/67 [11:22<03:05, 14.29s/it][A
 82%|████████▏ | 55/67 [11:36<02:53, 14.45s/it][A
 84%|████████▎ | 56/67 [11:56<02:56, 16.00s/it][A
 85%|████████▌ | 57/67 [12:19<03:01, 18.15s/it][A
 87%|████████▋ | 58/67 [12:59<03:41, 24.63s/it][A
 88%|████████▊ | 59/67 [13:14<02:54, 21.77s/it][A
 90%|████████▉ | 60/67 [13:33<02:27, 21.07s/it][A
 91%|█████████ | 61/67 [13:43<01:45, 17.59s/it][A
 93%|█████████▎| 62/67 [13:51<01:13, 14.69s/it][A
 94%|█████████▍| 63/67 [14:01<00:52, 13.18s/it][A
 96%|█████████▌| 64/67 [14:12<00:37, 12.53s/it][A
 97%|█████████▋| 65/67 [14:20<00:22, 11.30s/it][A
 99%|█████████▊| 66/67 [14:32<00:11, 11.59s/it][A
100%|██████████| 67/67 [14:35<00:00,  8.94s/it][A                                                        
                                               [A 83%|████████▎ | 1425/1710 [13:46:20<1:29:04, 18.75s/it]
100%|██████████| 67/67 [14:36<00:00,  8.94s/it][A
                                               [A{'f1_1': 0.4655704008221994, 'precision': 0.46083418107833163, 'recall': 0.470404984423676}
{'f1': 0.4460431654676259, 'precision': 0.44150559511698884, 'recall': 0.45067497403946}
{'eval_f1': 0.4460431654676259, 'eval_precision': 0.44150559511698884, 'eval_recall': 0.45067497403946, 'eval_runtime': 894.5195, 'eval_samples_per_second': 0.444, 'eval_steps_per_second': 0.075, 'epoch': 25.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 83%|████████▎ | 1426/1710 [13:46:39<22:39:05, 287.13s/it] 83%|████████▎ | 1427/1710 [13:47:00<16:17:20, 207.21s/it] 84%|████████▎ | 1428/1710 [13:47:16<11:44:23, 149.87s/it] 84%|████████▎ | 1429/1710 [13:47:33<8:35:57, 110.17s/it]  84%|████████▎ | 1430/1710 [13:47:54<6:28:54, 83.34s/it]                                                          84%|████████▎ | 1430/1710 [13:47:54<6:28:54, 83.34s/it] 84%|████████▎ | 1431/1710 [13:48:11<4:54:42, 63.38s/it] 84%|████████▎ | 1432/1710 [13:48:29<3:50:15, 49.70s/it] 84%|████████▍ | 1433/1710 [13:48:54<3:15:42, 42.39s/it] 84%|████████▍ | 1434/1710 [13:49:13<2:43:02, 35.44s/it] 84%|████████▍ | 1435/1710 [13:49:33<2:20:25, 30.64s/it] 84%|████████▍ | 1436/1710 [13:49:49<2:00:37, 26.42s/it] 84%|████████▍ | 1437/1710 [13:50:14<1:58:04, 25.95s/it] 84%|████████▍ | 1438/1710 [13:50:38<1:54:50, 25.33s/it] 84%|████████▍ | 1439/1710 [13:50:56<1:44:56, 23.24s/it] 84%|████████▍ | 1440/1710 [13:51:12<1:34:19, 20.96s/it]                                                         84%|████████▍ | 1440/1710 [13:51:12<1:34:19, 20.96s/it] 84%|████████▍ | 1441/1710 [13:51:36<1:38:03, 21.87s/it] 84%|████████▍ | 1442/1710 [13:51:57<1:36:06, 21.52s/it] 84%|████████▍ | 1443/1710 [13:52:13<1:28:40, 19.93s/it] 84%|████████▍ | 1444/1710 [13:52:32<1:27:56, 19.84s/it] 85%|████████▍ | 1445/1710 [13:52:53<1:28:38, 20.07s/it] 85%|████████▍ | 1446/1710 [13:53:12<1:26:56, 19.76s/it] 85%|████████▍ | 1447/1710 [13:53:32<1:26:13, 19.67s/it] 85%|████████▍ | 1448/1710 [13:53:48<1:22:06, 18.80s/it] 85%|████████▍ | 1449/1710 [13:54:07<1:21:45, 18.79s/it] 85%|████████▍ | 1450/1710 [13:54:24<1:18:32, 18.13s/it]                                                         85%|████████▍ | 1450/1710 [13:54:24<1:18:32, 18.13s/it] 85%|████████▍ | 1451/1710 [13:54:44<1:21:35, 18.90s/it] 85%|████████▍ | 1452/1710 [13:55:04<1:21:33, 18.97s/it] 85%|████████▍ | 1453/1710 [13:55:20<1:17:29, 18.09s/it] 85%|████████▌ | 1454/1710 [13:55:38<1:17:14, 18.10s/it] 85%|████████▌ | 1455/1710 [13:56:00<1:21:53, 19.27s/it] 85%|████████▌ | 1456/1710 [13:56:17<1:18:58, 18.66s/it] 85%|████████▌ | 1457/1710 [13:56:35<1:17:30, 18.38s/it] 85%|████████▌ | 1458/1710 [13:56:52<1:16:02, 18.10s/it] 85%|████████▌ | 1459/1710 [13:57:09<1:14:32, 17.82s/it] 85%|████████▌ | 1460/1710 [13:57:31<1:18:45, 18.90s/it]                                                         85%|████████▌ | 1460/1710 [13:57:31<1:18:45, 18.90s/it] 85%|████████▌ | 1461/1710 [13:57:48<1:15:59, 18.31s/it] 85%|████████▌ | 1462/1710 [13:58:06<1:15:20, 18.23s/it] 86%|████████▌ | 1463/1710 [13:58:24<1:15:24, 18.32s/it] 86%|████████▌ | 1464/1710 [13:58:43<1:15:10, 18.34s/it] 86%|████████▌ | 1465/1710 [13:59:01<1:14:59, 18.37s/it] 86%|████████▌ | 1466/1710 [13:59:25<1:21:17, 19.99s/it] 86%|████████▌ | 1467/1710 [13:59:43<1:18:46, 19.45s/it] 86%|████████▌ | 1468/1710 [14:00:01<1:16:49, 19.05s/it] 86%|████████▌ | 1469/1710 [14:00:18<1:14:16, 18.49s/it] 86%|████████▌ | 1470/1710 [14:00:41<1:19:19, 19.83s/it]                                                         86%|████████▌ | 1470/1710 [14:00:41<1:19:19, 19.83s/it] 86%|████████▌ | 1471/1710 [14:01:00<1:17:25, 19.44s/it] 86%|████████▌ | 1472/1710 [14:01:20<1:17:45, 19.60s/it] 86%|████████▌ | 1473/1710 [14:01:37<1:14:42, 18.91s/it] 86%|████████▌ | 1474/1710 [14:01:56<1:14:35, 18.96s/it] 86%|████████▋ | 1475/1710 [14:02:15<1:14:10, 18.94s/it] 86%|████████▋ | 1476/1710 [14:02:37<1:17:33, 19.89s/it] 86%|████████▋ | 1477/1710 [14:02:55<1:14:25, 19.16s/it] 86%|████████▋ | 1478/1710 [14:03:21<1:22:52, 21.43s/it] 86%|████████▋ | 1479/1710 [14:03:40<1:19:10, 20.57s/it] 87%|████████▋ | 1480/1710 [14:03:58<1:16:23, 19.93s/it]                                                         87%|████████▋ | 1480/1710 [14:03:58<1:16:23, 19.93s/it] 87%|████████▋ | 1481/1710 [14:04:17<1:14:52, 19.62s/it] 87%|████████▋ | 1482/1710 [14:04:34<1:11:02, 18.70s/it]{'loss': 0.0006, 'learning_rate': 7.1112629122137066e-06, 'epoch': 25.09}
{'loss': 0.0003, 'learning_rate': 6.6271170267984795e-06, 'epoch': 25.26}
{'loss': 0.0005, 'learning_rate': 6.158867132424523e-06, 'epoch': 25.44}
{'loss': 0.0007, 'learning_rate': 5.706684840836674e-06, 'epoch': 25.61}
{'loss': 0.0003, 'learning_rate': 5.270735875066562e-06, 'epoch': 25.79}
{'loss': 0.0003, 'learning_rate': 4.851180008695721e-06, 'epoch': 25.96}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:43,  5.28s/it][A
  4%|▍         | 3/67 [00:18<06:46,  6.35s/it][A
  6%|▌         | 4/67 [00:25<07:02,  6.71s/it][A
  7%|▋         | 5/67 [00:43<10:58, 10.62s/it][A
  9%|▉         | 6/67 [00:54<10:50, 10.66s/it][A
 10%|█         | 7/67 [01:11<12:49, 12.82s/it][A
 12%|█▏        | 8/67 [01:34<15:31, 15.79s/it][A
 13%|█▎        | 9/67 [01:51<15:53, 16.45s/it][A
 15%|█▍        | 10/67 [02:01<13:30, 14.21s/it][A
 16%|█▋        | 11/67 [02:18<14:06, 15.12s/it][A
 18%|█▊        | 12/67 [02:25<11:38, 12.71s/it][A
 19%|█▉        | 13/67 [02:31<09:32, 10.61s/it][A
 21%|██        | 14/67 [02:40<08:57, 10.15s/it][A
 22%|██▏       | 15/67 [02:48<08:14,  9.52s/it][A
 24%|██▍       | 16/67 [02:55<07:26,  8.76s/it][A
 25%|██▌       | 17/67 [03:16<10:27, 12.55s/it][A
 27%|██▋       | 18/67 [03:28<10:04, 12.34s/it][A
 28%|██▊       | 19/67 [03:41<09:57, 12.45s/it][A
 30%|██▉       | 20/67 [03:50<08:53, 11.36s/it][A
 31%|███▏      | 21/67 [04:12<11:15, 14.69s/it][A
 33%|███▎      | 22/67 [04:28<11:16, 15.04s/it][A
 34%|███▍      | 23/67 [04:36<09:28, 12.93s/it][A
 36%|███▌      | 24/67 [04:51<09:42, 13.55s/it][A
 37%|███▋      | 25/67 [05:07<09:55, 14.18s/it][A
 39%|███▉      | 26/67 [05:19<09:14, 13.54s/it][A
 40%|████      | 27/67 [05:33<09:10, 13.77s/it][A
 42%|████▏     | 28/67 [05:43<08:10, 12.59s/it][A
 43%|████▎     | 29/67 [05:51<07:05, 11.19s/it][A
 45%|████▍     | 30/67 [05:58<06:15, 10.14s/it][A
 46%|████▋     | 31/67 [06:02<04:59,  8.31s/it][A
 48%|████▊     | 32/67 [06:11<04:54,  8.41s/it][A
 49%|████▉     | 33/67 [06:33<07:05, 12.51s/it][A
 51%|█████     | 34/67 [06:44<06:39, 12.09s/it][A
 52%|█████▏    | 35/67 [06:56<06:23, 11.97s/it][A
 54%|█████▎    | 36/67 [07:09<06:18, 12.21s/it][A
 55%|█████▌    | 37/67 [07:15<05:14, 10.49s/it][A
 57%|█████▋    | 38/67 [07:35<06:27, 13.35s/it][A
 58%|█████▊    | 39/67 [07:47<06:01, 12.92s/it][A
 60%|█████▉    | 40/67 [07:57<05:24, 12.03s/it][A
 61%|██████    | 41/67 [08:11<05:24, 12.48s/it][A
 63%|██████▎   | 42/67 [08:25<05:24, 12.98s/it][A
 64%|██████▍   | 43/67 [08:37<05:04, 12.71s/it][A
 66%|██████▌   | 44/67 [08:54<05:21, 13.97s/it][A
 67%|██████▋   | 45/67 [08:59<04:13, 11.51s/it][A
 69%|██████▊   | 46/67 [09:08<03:40, 10.49s/it][A
 70%|███████   | 47/67 [09:24<04:02, 12.14s/it][A
 72%|███████▏  | 48/67 [09:33<03:34, 11.28s/it][A
 73%|███████▎  | 49/67 [09:49<03:48, 12.72s/it][A
 75%|███████▍  | 50/67 [10:00<03:29, 12.34s/it][A
 76%|███████▌  | 51/67 [10:16<03:32, 13.26s/it][A
 78%|███████▊  | 52/67 [10:29<03:16, 13.13s/it][A
 79%|███████▉  | 53/67 [10:42<03:02, 13.07s/it][A
 81%|████████  | 54/67 [10:50<02:29, 11.53s/it][A
 82%|████████▏ | 55/67 [11:04<02:30, 12.51s/it][A
 84%|████████▎ | 56/67 [11:24<02:40, 14.63s/it][A
 85%|████████▌ | 57/67 [11:44<02:42, 16.24s/it][A
 87%|████████▋ | 58/67 [12:23<03:28, 23.21s/it][A
 88%|████████▊ | 59/67 [12:40<02:50, 21.26s/it][A
 90%|████████▉ | 60/67 [12:59<02:24, 20.68s/it][A
 91%|█████████ | 61/67 [13:09<01:43, 17.29s/it][A
 93%|█████████▎| 62/67 [13:15<01:10, 14.06s/it][A
 94%|█████████▍| 63/67 [13:27<00:53, 13.30s/it][A
 96%|█████████▌| 64/67 [13:38<00:37, 12.59s/it][A
 97%|█████████▋| 65/67 [13:46<00:22, 11.33s/it][A
 99%|█████████▊| 66/67 [13:58<00:11, 11.62s/it][A
100%|██████████| 67/67 [14:00<00:00,  8.65s/it][A                                                        
                                               [A 87%|████████▋ | 1482/1710 [14:18:54<1:11:02, 18.70s/it]
100%|██████████| 67/67 [14:01<00:00,  8.65s/it][A
                                               [A{'f1_1': 0.44800827728918785, 'precision': 0.4463917525773196, 'recall': 0.44963655244029077}
{'f1': 0.42524573202276256, 'precision': 0.42371134020618556, 'recall': 0.42679127725856697}
{'eval_f1': 0.42524573202276256, 'eval_precision': 0.42371134020618556, 'eval_recall': 0.42679127725856697, 'eval_runtime': 859.8466, 'eval_samples_per_second': 0.462, 'eval_steps_per_second': 0.078, 'epoch': 26.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 87%|████████▋ | 1483/1710 [14:19:18<17:32:43, 278.25s/it] 87%|████████▋ | 1484/1710 [14:19:35<12:33:43, 200.10s/it] 87%|████████▋ | 1485/1710 [14:19:54<9:06:25, 145.71s/it]  87%|████████▋ | 1486/1710 [14:20:17<6:46:23, 108.86s/it] 87%|████████▋ | 1487/1710 [14:20:41<5:09:25, 83.25s/it]  87%|████████▋ | 1488/1710 [14:21:02<3:59:46, 64.80s/it] 87%|████████▋ | 1489/1710 [14:21:26<3:12:47, 52.34s/it] 87%|████████▋ | 1490/1710 [14:21:50<2:41:09, 43.95s/it]                                                         87%|████████▋ | 1490/1710 [14:21:50<2:41:09, 43.95s/it] 87%|████████▋ | 1491/1710 [14:22:07<2:11:21, 35.99s/it] 87%|████████▋ | 1492/1710 [14:22:24<1:49:38, 30.18s/it] 87%|████████▋ | 1493/1710 [14:22:40<1:34:08, 26.03s/it] 87%|████████▋ | 1494/1710 [14:23:01<1:27:32, 24.32s/it] 87%|████████▋ | 1495/1710 [14:23:19<1:20:34, 22.49s/it] 87%|████████▋ | 1496/1710 [14:23:36<1:14:35, 20.91s/it] 88%|████████▊ | 1497/1710 [14:23:54<1:11:15, 20.07s/it] 88%|████████▊ | 1498/1710 [14:24:11<1:07:27, 19.09s/it] 88%|████████▊ | 1499/1710 [14:24:28<1:04:30, 18.34s/it] 88%|████████▊ | 1500/1710 [14:24:55<1:13:16, 20.93s/it]                                                         88%|████████▊ | 1500/1710 [14:24:55<1:13:16, 20.93s/it] 88%|████████▊ | 1501/1710 [14:25:14<1:11:25, 20.51s/it] 88%|████████▊ | 1502/1710 [14:25:32<1:08:53, 19.87s/it] 88%|████████▊ | 1503/1710 [14:25:50<1:06:20, 19.23s/it] 88%|████████▊ | 1504/1710 [14:26:08<1:04:27, 18.77s/it] 88%|████████▊ | 1505/1710 [14:26:25<1:01:59, 18.15s/it] 88%|████████▊ | 1506/1710 [14:26:42<1:00:59, 17.94s/it] 88%|████████▊ | 1507/1710 [14:27:01<1:01:58, 18.32s/it] 88%|████████▊ | 1508/1710 [14:27:21<1:03:05, 18.74s/it] 88%|████████▊ | 1509/1710 [14:27:40<1:02:55, 18.78s/it] 88%|████████▊ | 1510/1710 [14:27:57<1:00:51, 18.26s/it]                                                         88%|████████▊ | 1510/1710 [14:27:57<1:00:51, 18.26s/it] 88%|████████▊ | 1511/1710 [14:28:15<1:00:45, 18.32s/it] 88%|████████▊ | 1512/1710 [14:28:48<1:14:17, 22.51s/it] 88%|████████▊ | 1513/1710 [14:29:09<1:12:29, 22.08s/it] 89%|████████▊ | 1514/1710 [14:29:25<1:06:32, 20.37s/it] 89%|████████▊ | 1515/1710 [14:29:45<1:05:37, 20.19s/it] 89%|████████▊ | 1516/1710 [14:30:04<1:03:53, 19.76s/it] 89%|████████▊ | 1517/1710 [14:30:23<1:02:51, 19.54s/it] 89%|████████▉ | 1518/1710 [14:30:41<1:01:16, 19.15s/it] 89%|████████▉ | 1519/1710 [14:30:57<57:53, 18.19s/it]   89%|████████▉ | 1520/1710 [14:31:15<57:53, 18.28s/it]                                                       89%|████████▉ | 1520/1710 [14:31:15<57:53, 18.28s/it] 89%|████████▉ | 1521/1710 [14:31:34<57:56, 18.40s/it] 89%|████████▉ | 1522/1710 [14:31:53<57:45, 18.43s/it] 89%|████████▉ | 1523/1710 [14:32:11<57:24, 18.42s/it] 89%|████████▉ | 1524/1710 [14:32:30<57:37, 18.59s/it] 89%|████████▉ | 1525/1710 [14:32:49<58:00, 18.81s/it] 89%|████████▉ | 1526/1710 [14:33:07<56:30, 18.43s/it] 89%|████████▉ | 1527/1710 [14:33:27<58:17, 19.11s/it] 89%|████████▉ | 1528/1710 [14:33:51<1:01:37, 20.32s/it] 89%|████████▉ | 1529/1710 [14:34:08<58:56, 19.54s/it]   89%|████████▉ | 1530/1710 [14:34:28<58:24, 19.47s/it]                                                       89%|████████▉ | 1530/1710 [14:34:28<58:24, 19.47s/it] 90%|████████▉ | 1531/1710 [14:34:46<56:51, 19.06s/it] 90%|████████▉ | 1532/1710 [14:35:04<55:41, 18.77s/it] 90%|████████▉ | 1533/1710 [14:35:20<53:08, 18.01s/it] 90%|████████▉ | 1534/1710 [14:35:40<54:36, 18.62s/it] 90%|████████▉ | 1535/1710 [14:35:56<51:44, 17.74s/it] 90%|████████▉ | 1536/1710 [14:36:12<50:29, 17.41s/it] 90%|████████▉ | 1537/1710 [14:36:31<51:02, 17.70s/it] 90%|████████▉ | 1538/1710 [14:36:47<49:04, 17.12s/it] 90%|█████████ | 1539/1710 [14:37:07<51:46, 18.17s/it]{'loss': 0.0003, 'learning_rate': 4.448171007299229e-06, 'epoch': 26.14}
{'loss': 0.0003, 'learning_rate': 4.061856572091216e-06, 'epoch': 26.32}
{'loss': 0.0003, 'learning_rate': 3.692378285792958e-06, 'epoch': 26.49}
{'loss': 0.0004, 'learning_rate': 3.3398715607433796e-06, 'epoch': 26.67}
{'loss': 0.0004, 'learning_rate': 3.004465589270955e-06, 'epoch': 26.84}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:42,  5.28s/it][A
  4%|▍         | 3/67 [00:18<06:46,  6.35s/it][A
  6%|▌         | 4/67 [00:25<07:02,  6.71s/it][A
  7%|▋         | 5/67 [00:41<10:10,  9.85s/it][A
  9%|▉         | 6/67 [00:56<11:47, 11.59s/it][A
 10%|█         | 7/67 [01:14<13:28, 13.48s/it][A
 12%|█▏        | 8/67 [01:36<15:59, 16.26s/it][A
 13%|█▎        | 9/67 [01:48<14:34, 15.09s/it][A
 15%|█▍        | 10/67 [01:57<12:34, 13.24s/it][A
 16%|█▋        | 11/67 [02:10<12:09, 13.03s/it][A
 18%|█▊        | 12/67 [02:21<11:26, 12.48s/it][A
 19%|█▉        | 13/67 [02:27<09:24, 10.46s/it][A
 21%|██        | 14/67 [02:36<08:53, 10.06s/it][A
 22%|██▏       | 15/67 [02:46<08:38,  9.98s/it][A
 24%|██▍       | 16/67 [02:53<07:42,  9.07s/it][A
 25%|██▌       | 17/67 [03:14<10:37, 12.75s/it][A
 27%|██▋       | 18/67 [03:31<11:26, 14.01s/it][A
 28%|██▊       | 19/67 [03:44<10:51, 13.58s/it][A
 30%|██▉       | 20/67 [03:53<09:31, 12.16s/it][A
 31%|███▏      | 21/67 [04:18<12:24, 16.19s/it][A
 33%|███▎      | 22/67 [04:34<12:10, 16.24s/it][A
 34%|███▍      | 23/67 [04:42<10:05, 13.76s/it][A
 36%|███▌      | 24/67 [04:59<10:24, 14.52s/it][A
 37%|███▋      | 25/67 [05:16<10:43, 15.32s/it][A
 39%|███▉      | 26/67 [05:24<09:00, 13.17s/it][A
 40%|████      | 27/67 [05:38<09:00, 13.51s/it][A
 42%|████▏     | 28/67 [05:48<08:04, 12.43s/it][A
 43%|████▎     | 29/67 [05:56<07:00, 11.07s/it][A
 45%|████▍     | 30/67 [06:04<06:11, 10.04s/it][A
 46%|████▋     | 31/67 [06:08<04:56,  8.23s/it][A
 48%|████▊     | 32/67 [06:19<05:15,  9.03s/it][A
 49%|████▉     | 33/67 [06:36<06:33, 11.58s/it][A
 51%|█████     | 34/67 [06:47<06:17, 11.43s/it][A
 52%|█████▏    | 35/67 [06:59<06:07, 11.50s/it][A
 54%|█████▎    | 36/67 [07:11<05:58, 11.58s/it][A
 55%|█████▌    | 37/67 [07:17<05:01, 10.04s/it][A
 57%|█████▋    | 38/67 [07:29<05:04, 10.49s/it][A
 58%|█████▊    | 39/67 [07:38<04:46, 10.25s/it][A
 60%|█████▉    | 40/67 [07:48<04:34, 10.16s/it][A
 61%|██████    | 41/67 [08:02<04:49, 11.13s/it][A
 63%|██████▎   | 42/67 [08:16<05:00, 12.03s/it][A
 64%|██████▍   | 43/67 [08:28<04:49, 12.04s/it][A
 66%|██████▌   | 44/67 [08:41<04:44, 12.36s/it][A
 67%|██████▋   | 45/67 [08:47<03:48, 10.38s/it][A
 69%|██████▊   | 46/67 [08:55<03:24,  9.75s/it][A
 70%|███████   | 47/67 [09:11<03:52, 11.63s/it][A
 72%|███████▏  | 48/67 [09:28<04:10, 13.21s/it][A
 73%|███████▎  | 49/67 [09:46<04:23, 14.63s/it][A
 75%|███████▍  | 50/67 [09:57<03:52, 13.69s/it][A
 76%|███████▌  | 51/67 [10:13<03:49, 14.36s/it][A
 78%|███████▊  | 52/67 [10:26<03:27, 13.87s/it][A
 79%|███████▉  | 53/67 [10:38<03:05, 13.22s/it][A
 81%|████████  | 54/67 [10:46<02:31, 11.63s/it][A
 82%|████████▏ | 55/67 [11:01<02:30, 12.58s/it][A
 84%|████████▎ | 56/67 [11:20<02:41, 14.67s/it][A
 85%|████████▌ | 57/67 [11:40<02:42, 16.27s/it][A
 87%|████████▋ | 58/67 [12:20<03:29, 23.29s/it][A
 88%|████████▊ | 59/67 [12:37<02:52, 21.58s/it][A
 90%|████████▉ | 60/67 [12:57<02:26, 20.93s/it][A
 91%|█████████ | 61/67 [13:06<01:44, 17.48s/it][A
 93%|█████████▎| 62/67 [13:15<01:14, 14.82s/it][A
 94%|█████████▍| 63/67 [13:24<00:53, 13.26s/it][A
 96%|█████████▌| 64/67 [13:35<00:37, 12.58s/it][A
 97%|█████████▋| 65/67 [13:44<00:22, 11.33s/it][A
 99%|█████████▊| 66/67 [13:56<00:11, 11.60s/it][A
100%|██████████| 67/67 [13:59<00:00,  8.94s/it][A                                                      
                                               [A 90%|█████████ | 1539/1710 [14:51:21<51:46, 18.17s/it]
100%|██████████| 67/67 [14:00<00:00,  8.94s/it][A
                                               [A{'f1_1': 0.452344152498712, 'precision': 0.4488752556237219, 'recall': 0.45586708203530635}
{'f1': 0.4327666151468315, 'precision': 0.4294478527607362, 'recall': 0.43613707165109034}
{'eval_f1': 0.4327666151468315, 'eval_precision': 0.4294478527607362, 'eval_recall': 0.43613707165109034, 'eval_runtime': 853.94, 'eval_samples_per_second': 0.465, 'eval_steps_per_second': 0.078, 'epoch': 27.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 90%|█████████ | 1540/1710 [14:51:41<12:58:27, 274.75s/it]                                                           90%|█████████ | 1540/1710 [14:51:41<12:58:27, 274.75s/it] 90%|█████████ | 1541/1710 [14:52:04<9:21:06, 199.21s/it]  90%|█████████ | 1542/1710 [14:52:21<6:45:17, 144.75s/it] 90%|█████████ | 1543/1710 [14:52:42<4:59:18, 107.53s/it] 90%|█████████ | 1544/1710 [14:52:59<3:42:14, 80.33s/it]  90%|█████████ | 1545/1710 [14:53:16<2:48:26, 61.25s/it] 90%|█████████ | 1546/1710 [14:53:36<2:14:15, 49.12s/it] 90%|█████████ | 1547/1710 [14:53:53<1:46:36, 39.24s/it] 91%|█████████ | 1548/1710 [14:54:11<1:28:57, 32.95s/it] 91%|█████████ | 1549/1710 [14:54:28<1:15:22, 28.09s/it] 91%|█████████ | 1550/1710 [14:54:46<1:07:13, 25.21s/it]                                                         91%|█████████ | 1550/1710 [14:54:46<1:07:13, 25.21s/it] 91%|█████████ | 1551/1710 [14:55:04<1:01:16, 23.12s/it] 91%|█████████ | 1552/1710 [14:55:21<55:50, 21.20s/it]   91%|█████████ | 1553/1710 [14:55:40<53:36, 20.49s/it] 91%|█████████ | 1554/1710 [14:56:01<53:27, 20.56s/it] 91%|█████████ | 1555/1710 [14:56:20<51:56, 20.11s/it] 91%|█████████ | 1556/1710 [14:56:39<51:12, 19.95s/it] 91%|█████████ | 1557/1710 [14:56:59<50:30, 19.81s/it] 91%|█████████ | 1558/1710 [14:57:15<47:15, 18.66s/it] 91%|█████████ | 1559/1710 [14:57:36<49:12, 19.55s/it] 91%|█████████ | 1560/1710 [14:57:56<48:55, 19.57s/it]                                                       91%|█████████ | 1560/1710 [14:57:56<48:55, 19.57s/it] 91%|█████████▏| 1561/1710 [14:58:15<48:04, 19.36s/it] 91%|█████████▏| 1562/1710 [14:58:33<47:01, 19.07s/it] 91%|█████████▏| 1563/1710 [14:58:53<46:59, 19.18s/it] 91%|█████████▏| 1564/1710 [14:59:11<45:56, 18.88s/it] 92%|█████████▏| 1565/1710 [14:59:30<45:58, 19.02s/it] 92%|█████████▏| 1566/1710 [14:59:48<44:52, 18.70s/it] 92%|█████████▏| 1567/1710 [15:00:07<44:37, 18.73s/it] 92%|█████████▏| 1568/1710 [15:00:29<46:53, 19.82s/it] 92%|█████████▏| 1569/1710 [15:00:50<47:18, 20.13s/it] 92%|█████████▏| 1570/1710 [15:01:10<46:30, 19.93s/it]                                                       92%|█████████▏| 1570/1710 [15:01:10<46:30, 19.93s/it] 92%|█████████▏| 1571/1710 [15:01:30<46:27, 20.05s/it] 92%|█████████▏| 1572/1710 [15:02:02<54:30, 23.70s/it] 92%|█████████▏| 1573/1710 [15:02:21<50:33, 22.14s/it] 92%|█████████▏| 1574/1710 [15:02:37<46:26, 20.49s/it] 92%|█████████▏| 1575/1710 [15:02:57<45:51, 20.38s/it] 92%|█████████▏| 1576/1710 [15:03:14<42:54, 19.21s/it] 92%|█████████▏| 1577/1710 [15:03:30<40:14, 18.16s/it] 92%|█████████▏| 1578/1710 [15:03:49<40:42, 18.50s/it] 92%|█████████▏| 1579/1710 [15:04:06<39:41, 18.18s/it] 92%|█████████▏| 1580/1710 [15:04:24<38:52, 17.95s/it]                                                       92%|█████████▏| 1580/1710 [15:04:24<38:52, 17.95s/it] 92%|█████████▏| 1581/1710 [15:04:48<42:57, 19.98s/it] 93%|█████████▎| 1582/1710 [15:05:07<41:38, 19.52s/it] 93%|█████████▎| 1583/1710 [15:05:26<41:17, 19.51s/it] 93%|█████████▎| 1584/1710 [15:05:47<41:49, 19.91s/it] 93%|█████████▎| 1585/1710 [15:06:13<44:58, 21.59s/it] 93%|█████████▎| 1586/1710 [15:06:31<42:22, 20.51s/it] 93%|█████████▎| 1587/1710 [15:06:47<39:31, 19.28s/it] 93%|█████████▎| 1588/1710 [15:07:09<41:03, 20.19s/it] 93%|█████████▎| 1589/1710 [15:07:27<39:00, 19.34s/it] 93%|█████████▎| 1590/1710 [15:07:44<37:35, 18.80s/it]                                                       93%|█████████▎| 1590/1710 [15:07:44<37:35, 18.80s/it] 93%|█████████▎| 1591/1710 [15:08:05<38:13, 19.28s/it] 93%|█████████▎| 1592/1710 [15:08:25<38:16, 19.46s/it] 93%|█████████▎| 1593/1710 [15:08:42<36:35, 18.77s/it] 93%|█████████▎| 1594/1710 [15:09:00<36:06, 18.68s/it] 93%|█████████▎| 1595/1710 [15:09:21<36:47, 19.19s/it] 93%|█████████▎| 1596/1710 [15:09:37<35:08, 18.50s/it]{'loss': 0.0009, 'learning_rate': 2.686283296345199e-06, 'epoch': 27.02}
{'loss': 0.0002, 'learning_rate': 2.385441294525176e-06, 'epoch': 27.19}
{'loss': 0.0004, 'learning_rate': 2.1020498412214705e-06, 'epoch': 27.37}
{'loss': 0.0006, 'learning_rate': 1.8362127982872457e-06, 'epoch': 27.54}
{'loss': 0.0003, 'learning_rate': 1.5880275939533063e-06, 'epoch': 27.72}
{'loss': 0.0003, 'learning_rate': 1.3575851871210299e-06, 'epoch': 27.89}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:09<05:23,  4.98s/it][A
  4%|▍         | 3/67 [00:17<06:35,  6.19s/it][A
  6%|▌         | 4/67 [00:25<06:56,  6.61s/it][A
  7%|▋         | 5/67 [00:37<08:47,  8.51s/it][A
  9%|▉         | 6/67 [00:52<10:52, 10.70s/it][A
 10%|█         | 7/67 [01:09<12:52, 12.87s/it][A
 12%|█▏        | 8/67 [01:32<15:33, 15.83s/it][A
 13%|█▎        | 9/67 [01:50<16:05, 16.65s/it][A
 15%|█▍        | 10/67 [01:59<13:36, 14.32s/it][A
 16%|█▋        | 11/67 [02:14<13:39, 14.63s/it][A
 18%|█▊        | 12/67 [02:21<11:16, 12.30s/it][A
 19%|█▉        | 13/67 [02:27<09:18, 10.35s/it][A
 21%|██        | 14/67 [02:36<08:48,  9.97s/it][A
 22%|██▏       | 15/67 [02:46<08:36,  9.93s/it][A
 24%|██▍       | 16/67 [02:52<07:20,  8.64s/it][A
 25%|██▌       | 17/67 [03:12<09:58, 11.97s/it][A
 27%|██▋       | 18/67 [03:23<09:45, 11.94s/it][A
 28%|██▊       | 19/67 [03:39<10:26, 13.05s/it][A
 30%|██▉       | 20/67 [03:48<09:14, 11.80s/it][A
 31%|███▏      | 21/67 [04:06<10:26, 13.62s/it][A
 33%|███▎      | 22/67 [04:22<10:42, 14.27s/it][A
 34%|███▍      | 23/67 [04:30<09:05, 12.40s/it][A
 36%|███▌      | 24/67 [04:46<09:38, 13.46s/it][A
 37%|███▋      | 25/67 [05:03<10:19, 14.76s/it][A
 39%|███▉      | 26/67 [05:15<09:32, 13.96s/it][A
 40%|████      | 27/67 [05:30<09:23, 14.09s/it][A
 42%|████▏     | 28/67 [05:40<08:20, 12.83s/it][A
 43%|████▎     | 29/67 [05:48<07:11, 11.36s/it][A
 45%|████▍     | 30/67 [05:58<06:49, 11.06s/it][A
 46%|████▋     | 31/67 [06:02<05:22,  8.95s/it][A
 48%|████▊     | 32/67 [06:12<05:24,  9.26s/it][A
 49%|████▉     | 33/67 [06:34<07:27, 13.16s/it][A
 51%|█████     | 34/67 [06:45<06:55, 12.58s/it][A
 52%|█████▏    | 35/67 [06:57<06:35, 12.35s/it][A
 54%|█████▎    | 36/67 [07:06<05:45, 11.15s/it][A
 55%|█████▌    | 37/67 [07:12<04:52,  9.76s/it][A
 57%|█████▋    | 38/67 [07:26<05:14, 10.84s/it][A
 58%|█████▊    | 39/67 [07:32<04:30,  9.68s/it][A
 60%|█████▉    | 40/67 [07:43<04:24,  9.79s/it][A
 61%|██████    | 41/67 [07:56<04:43, 10.90s/it][A
 63%|██████▎   | 42/67 [08:10<04:57, 11.91s/it][A
 64%|██████▍   | 43/67 [08:22<04:47, 11.98s/it][A
 66%|██████▌   | 44/67 [08:39<05:10, 13.50s/it][A
 67%|██████▋   | 45/67 [08:45<04:06, 11.20s/it][A
 69%|██████▊   | 46/67 [08:53<03:35, 10.28s/it][A
 70%|███████   | 47/67 [09:10<04:00, 12.04s/it][A
 72%|███████▏  | 48/67 [09:20<03:40, 11.61s/it][A
 73%|███████▎  | 49/67 [09:36<03:53, 12.97s/it][A
 75%|███████▍  | 50/67 [09:48<03:33, 12.55s/it][A
 76%|███████▌  | 51/67 [10:03<03:34, 13.41s/it][A
 78%|███████▊  | 52/67 [10:18<03:27, 13.83s/it][A
 79%|███████▉  | 53/67 [10:32<03:12, 13.75s/it][A
 81%|████████  | 54/67 [10:43<02:50, 13.14s/it][A
 82%|████████▏ | 55/67 [10:58<02:44, 13.67s/it][A
 84%|████████▎ | 56/67 [11:18<02:50, 15.47s/it][A
 85%|████████▌ | 57/67 [11:38<02:48, 16.89s/it][A
 87%|████████▋ | 58/67 [12:18<03:34, 23.83s/it][A
 88%|████████▊ | 59/67 [12:35<02:53, 21.74s/it][A
 90%|████████▉ | 60/67 [12:55<02:27, 21.09s/it][A
 91%|█████████ | 61/67 [13:04<01:45, 17.61s/it][A
 93%|█████████▎| 62/67 [13:13<01:14, 14.93s/it][A
 94%|█████████▍| 63/67 [13:23<00:53, 13.35s/it][A
 96%|█████████▌| 64/67 [13:34<00:37, 12.66s/it][A
 97%|█████████▋| 65/67 [13:42<00:22, 11.40s/it][A
 99%|█████████▊| 66/67 [13:54<00:11, 11.68s/it][A
100%|██████████| 67/67 [13:57<00:00,  9.00s/it][A                                                      
                                               [A 93%|█████████▎| 1596/1710 [15:23:48<35:08, 18.50s/it]
100%|██████████| 67/67 [13:58<00:00,  9.00s/it][A
                                               [A{'f1_1': 0.45510835913312697, 'precision': 0.4523076923076923, 'recall': 0.45794392523364486}
{'f1': 0.43653250773993807, 'precision': 0.4338461538461538, 'recall': 0.4392523364485981}
{'eval_f1': 0.43653250773993807, 'eval_precision': 0.4338461538461538, 'eval_recall': 0.4392523364485981, 'eval_runtime': 850.851, 'eval_samples_per_second': 0.467, 'eval_steps_per_second': 0.079, 'epoch': 28.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 93%|█████████▎| 1597/1710 [15:24:09<8:36:36, 274.30s/it] 93%|█████████▎| 1598/1710 [15:24:30<6:10:37, 198.55s/it] 94%|█████████▎| 1599/1710 [15:24:48<4:27:02, 144.35s/it] 94%|█████████▎| 1600/1710 [15:25:09<3:16:34, 107.22s/it]                                                          94%|█████████▎| 1600/1710 [15:25:09<3:16:34, 107.22s/it] 94%|█████████▎| 1601/1710 [15:25:27<2:26:21, 80.56s/it]  94%|█████████▎| 1602/1710 [15:25:46<1:51:41, 62.05s/it] 94%|█████████▎| 1603/1710 [15:26:07<1:28:39, 49.71s/it] 94%|█████████▍| 1604/1710 [15:26:24<1:10:23, 39.85s/it] 94%|█████████▍| 1605/1710 [15:26:41<57:54, 33.09s/it]   94%|█████████▍| 1606/1710 [15:27:02<50:50, 29.33s/it] 94%|█████████▍| 1607/1710 [15:27:20<44:43, 26.05s/it] 94%|█████████▍| 1608/1710 [15:27:37<39:44, 23.38s/it] 94%|█████████▍| 1609/1710 [15:27:55<36:36, 21.75s/it] 94%|█████████▍| 1610/1710 [15:28:14<34:38, 20.79s/it]                                                       94%|█████████▍| 1610/1710 [15:28:14<34:38, 20.79s/it] 94%|█████████▍| 1611/1710 [15:28:36<34:51, 21.13s/it] 94%|█████████▍| 1612/1710 [15:28:53<32:29, 19.90s/it] 94%|█████████▍| 1613/1710 [15:29:13<32:06, 19.86s/it] 94%|█████████▍| 1614/1710 [15:29:36<33:29, 20.94s/it] 94%|█████████▍| 1615/1710 [15:29:53<31:11, 19.70s/it] 95%|█████████▍| 1616/1710 [15:30:16<32:33, 20.78s/it] 95%|█████████▍| 1617/1710 [15:30:33<30:31, 19.70s/it] 95%|█████████▍| 1618/1710 [15:30:54<30:27, 19.86s/it] 95%|█████████▍| 1619/1710 [15:31:20<33:09, 21.87s/it] 95%|█████████▍| 1620/1710 [15:31:36<29:56, 19.96s/it]                                                       95%|█████████▍| 1620/1710 [15:31:36<29:56, 19.96s/it] 95%|█████████▍| 1621/1710 [15:31:56<29:54, 20.16s/it] 95%|█████████▍| 1622/1710 [15:32:15<28:56, 19.74s/it] 95%|█████████▍| 1623/1710 [15:32:32<27:32, 18.99s/it] 95%|█████████▍| 1624/1710 [15:32:52<27:41, 19.32s/it] 95%|█████████▌| 1625/1710 [15:33:09<26:04, 18.40s/it] 95%|█████████▌| 1626/1710 [15:33:36<29:40, 21.20s/it] 95%|█████████▌| 1627/1710 [15:33:57<28:58, 20.94s/it] 95%|█████████▌| 1628/1710 [15:34:16<28:00, 20.49s/it] 95%|█████████▌| 1629/1710 [15:34:40<29:00, 21.48s/it] 95%|█████████▌| 1630/1710 [15:34:57<26:48, 20.10s/it]                                                       95%|█████████▌| 1630/1710 [15:34:57<26:48, 20.10s/it] 95%|█████████▌| 1631/1710 [15:35:17<26:28, 20.10s/it] 95%|█████████▌| 1632/1710 [15:35:34<24:53, 19.15s/it] 95%|█████████▌| 1633/1710 [15:35:49<22:59, 17.91s/it] 96%|█████████▌| 1634/1710 [15:36:07<22:53, 18.07s/it] 96%|█████████▌| 1635/1710 [15:36:28<23:42, 18.97s/it] 96%|█████████▌| 1636/1710 [15:36:46<22:55, 18.59s/it] 96%|█████████▌| 1637/1710 [15:37:07<23:20, 19.18s/it] 96%|█████████▌| 1638/1710 [15:37:26<23:15, 19.39s/it] 96%|█████████▌| 1639/1710 [15:37:45<22:45, 19.23s/it] 96%|█████████▌| 1640/1710 [15:38:04<22:09, 18.99s/it]                                                       96%|█████████▌| 1640/1710 [15:38:04<22:09, 18.99s/it] 96%|█████████▌| 1641/1710 [15:38:24<22:21, 19.45s/it] 96%|█████████▌| 1642/1710 [15:38:41<21:13, 18.73s/it] 96%|█████████▌| 1643/1710 [15:38:59<20:43, 18.56s/it] 96%|█████████▌| 1644/1710 [15:39:18<20:31, 18.65s/it] 96%|█████████▌| 1645/1710 [15:39:36<19:44, 18.22s/it] 96%|█████████▋| 1646/1710 [15:39:54<19:33, 18.33s/it] 96%|█████████▋| 1647/1710 [15:40:19<21:14, 20.23s/it] 96%|█████████▋| 1648/1710 [15:40:36<20:04, 19.43s/it] 96%|█████████▋| 1649/1710 [15:40:58<20:22, 20.04s/it] 96%|█████████▋| 1650/1710 [15:41:15<19:17, 19.29s/it]                                                       96%|█████████▋| 1650/1710 [15:41:15<19:17, 19.29s/it] 97%|█████████▋| 1651/1710 [15:41:37<19:31, 19.85s/it] 97%|█████████▋| 1652/1710 [15:41:53<18:10, 18.80s/it] 97%|█████████▋| 1653/1710 [15:42:11<17:47, 18.73s/it]{'loss': 0.0003, 'learning_rate': 1.144970034026277e-06, 'epoch': 28.07}
{'loss': 0.0003, 'learning_rate': 9.502600572865284e-07, 'epoch': 28.25}
{'loss': 0.0003, 'learning_rate': 7.735266173425348e-07, 'epoch': 28.42}
{'loss': 0.0005, 'learning_rate': 6.14834486305027e-07, 'epoch': 28.6}
{'loss': 0.0003, 'learning_rate': 4.7424182421594855e-07, 'epoch': 28.77}
{'loss': 0.0003, 'learning_rate': 3.5180015773305095e-07, 'epoch': 28.95}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:44,  5.30s/it][A
  4%|▍         | 3/67 [00:18<06:50,  6.41s/it][A
  6%|▌         | 4/67 [00:25<07:06,  6.77s/it][A
  7%|▋         | 5/67 [00:39<09:16,  8.98s/it][A
  9%|▉         | 6/67 [00:54<11:13, 11.04s/it][A
 10%|█         | 7/67 [01:11<13:08, 13.14s/it][A
 12%|█▏        | 8/67 [01:34<15:48, 16.07s/it][A
 13%|█▎        | 9/67 [01:52<16:20, 16.90s/it][A
 15%|█▍        | 10/67 [02:02<13:49, 14.55s/it][A
 16%|█▋        | 11/67 [02:14<13:02, 13.98s/it][A
 18%|█▊        | 12/67 [02:21<10:52, 11.87s/it][A
 19%|█▉        | 13/67 [02:27<09:02, 10.05s/it][A
 21%|██        | 14/67 [02:36<08:38,  9.79s/it][A
 22%|██▏       | 15/67 [02:46<08:30,  9.82s/it][A
 24%|██▍       | 16/67 [02:52<07:17,  8.58s/it][A
 25%|██▌       | 17/67 [03:12<09:59, 11.98s/it][A
 27%|██▋       | 18/67 [03:24<09:46, 11.97s/it][A
 28%|██▊       | 19/67 [03:40<10:29, 13.11s/it][A
 30%|██▉       | 20/67 [03:49<09:17, 11.85s/it][A
 31%|███▏      | 21/67 [04:15<12:30, 16.31s/it][A
 33%|███▎      | 22/67 [04:31<12:09, 16.21s/it][A
 34%|███▍      | 23/67 [04:39<10:05, 13.77s/it][A
 36%|███▌      | 24/67 [05:12<13:52, 19.37s/it][A
 37%|███▋      | 25/67 [05:30<13:18, 19.02s/it][A
 39%|███▉      | 26/67 [05:40<11:06, 16.26s/it][A
 40%|████      | 27/67 [05:55<10:33, 15.83s/it][A
 42%|████▏     | 28/67 [06:05<09:12, 14.17s/it][A
 43%|████▎     | 29/67 [06:13<07:50, 12.38s/it][A
 45%|████▍     | 30/67 [06:21<06:49, 11.06s/it][A
 46%|████▋     | 31/67 [06:25<05:23,  8.99s/it][A
 48%|████▊     | 32/67 [06:38<05:55, 10.15s/it][A
 49%|████▉     | 33/67 [07:01<07:53, 13.92s/it][A
 51%|█████     | 34/67 [07:12<07:12, 13.11s/it][A
 52%|█████▏    | 35/67 [07:24<06:47, 12.72s/it][A
 54%|█████▎    | 36/67 [07:32<05:53, 11.41s/it][A
 55%|█████▌    | 37/67 [07:39<04:58,  9.95s/it][A
 57%|█████▋    | 38/67 [07:51<05:07, 10.59s/it][A
 58%|█████▊    | 39/67 [08:03<05:08, 11.00s/it][A
 60%|█████▉    | 40/67 [08:13<04:49, 10.71s/it][A
 61%|██████    | 41/67 [08:27<05:01, 11.58s/it][A
 63%|██████▎   | 42/67 [08:41<05:10, 12.41s/it][A
 64%|██████▍   | 43/67 [08:53<04:55, 12.33s/it][A
 66%|██████▌   | 44/67 [09:10<05:16, 13.75s/it][A
 67%|██████▋   | 45/67 [09:16<04:10, 11.38s/it][A
 69%|██████▊   | 46/67 [09:24<03:38, 10.40s/it][A
 70%|███████   | 47/67 [09:40<04:02, 12.13s/it][A
 72%|███████▏  | 48/67 [09:51<03:41, 11.68s/it][A
 73%|███████▎  | 49/67 [10:09<04:04, 13.61s/it][A
 75%|███████▍  | 50/67 [10:21<03:41, 13.01s/it][A
 76%|███████▌  | 51/67 [10:36<03:40, 13.78s/it][A
 78%|███████▊  | 52/67 [10:49<03:22, 13.53s/it][A
 79%|███████▉  | 53/67 [11:03<03:11, 13.67s/it][A
 81%|████████  | 54/67 [11:16<02:56, 13.56s/it][A
 82%|████████▏ | 55/67 [11:31<02:47, 13.98s/it][A
 84%|████████▎ | 56/67 [11:51<02:52, 15.72s/it][A
 85%|████████▌ | 57/67 [12:14<02:59, 17.98s/it][A
 87%|████████▋ | 58/67 [12:54<03:41, 24.62s/it][A
 88%|████████▊ | 59/67 [13:11<02:58, 22.30s/it][A
 90%|████████▉ | 60/67 [13:31<02:30, 21.48s/it][A
 91%|█████████ | 61/67 [13:40<01:47, 17.90s/it][A
 93%|█████████▎| 62/67 [13:49<01:15, 15.08s/it][A
 94%|█████████▍| 63/67 [13:59<00:53, 13.48s/it][A
 96%|█████████▌| 64/67 [14:10<00:38, 12.77s/it][A
 97%|█████████▋| 65/67 [14:18<00:22, 11.50s/it][A
 99%|█████████▊| 66/67 [14:31<00:11, 11.79s/it][A
100%|██████████| 67/67 [14:34<00:00,  9.07s/it][A                                                      
                                               [A 97%|█████████▋| 1653/1710 [15:57:05<17:47, 18.73s/it]
100%|██████████| 67/67 [14:35<00:00,  9.07s/it][A
                                               [A{'f1_1': 0.4588477366255144, 'precision': 0.454638124362895, 'recall': 0.46313603322949115}
{'f1': 0.4423868312757201, 'precision': 0.4383282364933741, 'recall': 0.446521287642783}
{'eval_f1': 0.4423868312757201, 'eval_precision': 0.4383282364933741, 'eval_recall': 0.446521287642783, 'eval_runtime': 893.2207, 'eval_samples_per_second': 0.444, 'eval_steps_per_second': 0.075, 'epoch': 29.0}
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/baishengyuan/anaconda3/envs/nllm/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 97%|█████████▋| 1654/1710 [15:57:21<4:26:54, 285.98s/it] 97%|█████████▋| 1655/1710 [15:57:42<3:09:20, 206.55s/it] 97%|█████████▋| 1656/1710 [15:58:01<2:15:07, 150.14s/it] 97%|█████████▋| 1657/1710 [15:58:20<1:38:00, 110.95s/it] 97%|█████████▋| 1658/1710 [15:58:38<1:12:02, 83.12s/it]  97%|█████████▋| 1659/1710 [15:58:58<54:23, 64.00s/it]   97%|█████████▋| 1660/1710 [15:59:20<42:53, 51.47s/it]                                                       97%|█████████▋| 1660/1710 [15:59:20<42:53, 51.47s/it] 97%|█████████▋| 1661/1710 [15:59:40<34:17, 41.99s/it] 97%|█████████▋| 1662/1710 [15:59:59<28:07, 35.15s/it] 97%|█████████▋| 1663/1710 [16:00:17<23:22, 29.84s/it] 97%|█████████▋| 1664/1710 [16:00:33<19:42, 25.71s/it] 97%|█████████▋| 1665/1710 [16:00:51<17:32, 23.39s/it] 97%|█████████▋| 1666/1710 [16:01:09<15:59, 21.81s/it] 97%|█████████▋| 1667/1710 [16:01:27<14:57, 20.87s/it] 98%|█████████▊| 1668/1710 [16:01:45<13:50, 19.78s/it] 98%|█████████▊| 1669/1710 [16:02:04<13:22, 19.58s/it] 98%|█████████▊| 1670/1710 [16:02:22<12:48, 19.21s/it]                                                       98%|█████████▊| 1670/1710 [16:02:22<12:48, 19.21s/it] 98%|█████████▊| 1671/1710 [16:02:40<12:09, 18.70s/it] 98%|█████████▊| 1672/1710 [16:02:59<11:59, 18.94s/it] 98%|█████████▊| 1673/1710 [16:03:20<12:06, 19.63s/it] 98%|█████████▊| 1674/1710 [16:03:40<11:41, 19.49s/it] 98%|█████████▊| 1675/1710 [16:03:58<11:12, 19.23s/it] 98%|█████████▊| 1676/1710 [16:04:15<10:34, 18.67s/it] 98%|█████████▊| 1677/1710 [16:04:36<10:32, 19.17s/it] 98%|█████████▊| 1678/1710 [16:04:53<09:50, 18.45s/it] 98%|█████████▊| 1679/1710 [16:05:13<09:52, 19.10s/it] 98%|█████████▊| 1680/1710 [16:05:38<10:22, 20.74s/it]                                                       98%|█████████▊| 1680/1710 [16:05:38<10:22, 20.74s/it] 98%|█████████▊| 1681/1710 [16:06:02<10:35, 21.91s/it] 98%|█████████▊| 1682/1710 [16:06:19<09:27, 20.27s/it] 98%|█████████▊| 1683/1710 [16:06:36<08:41, 19.31s/it] 98%|█████████▊| 1684/1710 [16:06:56<08:31, 19.67s/it] 99%|█████████▊| 1685/1710 [16:07:14<07:54, 18.98s/it] 99%|█████████▊| 1686/1710 [16:07:38<08:10, 20.42s/it] 99%|█████████▊| 1687/1710 [16:07:54<07:19, 19.12s/it] 99%|█████████▊| 1688/1710 [16:08:11<06:45, 18.44s/it] 99%|█████████▉| 1689/1710 [16:08:31<06:40, 19.06s/it] 99%|█████████▉| 1690/1710 [16:08:50<06:19, 18.99s/it]                                                       99%|█████████▉| 1690/1710 [16:08:50<06:19, 18.99s/it] 99%|█████████▉| 1691/1710 [16:09:13<06:26, 20.36s/it] 99%|█████████▉| 1692/1710 [16:09:35<06:14, 20.80s/it] 99%|█████████▉| 1693/1710 [16:09:56<05:53, 20.77s/it] 99%|█████████▉| 1694/1710 [16:10:17<05:34, 20.88s/it] 99%|█████████▉| 1695/1710 [16:10:41<05:25, 21.67s/it] 99%|█████████▉| 1696/1710 [16:10:57<04:39, 19.99s/it] 99%|█████████▉| 1697/1710 [16:11:22<04:40, 21.55s/it] 99%|█████████▉| 1698/1710 [16:11:48<04:33, 22.78s/it] 99%|█████████▉| 1699/1710 [16:12:06<03:56, 21.52s/it] 99%|█████████▉| 1700/1710 [16:12:24<03:24, 20.47s/it]                                                       99%|█████████▉| 1700/1710 [16:12:24<03:24, 20.47s/it] 99%|█████████▉| 1701/1710 [16:12:41<02:55, 19.53s/it]100%|█████████▉| 1702/1710 [16:13:01<02:36, 19.56s/it]100%|█████████▉| 1703/1710 [16:13:17<02:09, 18.55s/it]100%|█████████▉| 1704/1710 [16:13:34<01:48, 18.08s/it]100%|█████████▉| 1705/1710 [16:13:55<01:34, 18.91s/it]100%|█████████▉| 1706/1710 [16:14:13<01:13, 18.49s/it]100%|█████████▉| 1707/1710 [16:14:37<01:00, 20.15s/it]100%|█████████▉| 1708/1710 [16:14:54<00:38, 19.42s/it]100%|█████████▉| 1709/1710 [16:15:13<00:19, 19.15s/it]100%|██████████| 1710/1710 [16:15:32<00:00, 19.12s/it]                                                      100%|██████████| 1710/1710 [16:15:32<00:00, 19.12s/it]{'loss': 0.0003, 'learning_rate': 2.4755436124560547e-07, 'epoch': 29.12}
{'loss': 0.0003, 'learning_rate': 1.615426404280529e-07, 'epoch': 29.3}
{'loss': 0.0003, 'learning_rate': 9.379651823782087e-08, 'epoch': 29.47}
{'loss': 0.0003, 'learning_rate': 4.434082336228218e-08, 'epoch': 29.65}
{'loss': 0.0003, 'learning_rate': 1.3193681119116897e-08, 'epoch': 29.82}
{'loss': 0.0003, 'learning_rate': 3.6650681346506177e-10, 'epoch': 30.0}

  0%|          | 0/67 [00:00<?, ?it/s][A
  3%|▎         | 2/67 [00:10<05:40,  5.24s/it][A
  4%|▍         | 3/67 [00:18<06:42,  6.29s/it][A
  6%|▌         | 4/67 [00:25<06:59,  6.66s/it][A
  7%|▋         | 5/67 [00:40<09:45,  9.45s/it][A
  9%|▉         | 6/67 [00:55<11:29, 11.30s/it][A
 10%|█         | 7/67 [01:12<13:15, 13.25s/it][A
 12%|█▏        | 8/67 [01:34<15:47, 16.05s/it][A
 13%|█▎        | 9/67 [01:52<16:02, 16.60s/it][A
 15%|█▍        | 10/67 [02:01<13:35, 14.31s/it][A
 16%|█▋        | 11/67 [02:17<13:39, 14.63s/it][A
 18%|█▊        | 12/67 [02:24<11:23, 12.42s/it][A
 19%|█▉        | 13/67 [02:30<09:22, 10.42s/it][A
 21%|██        | 14/67 [02:39<08:50, 10.02s/it][A
 22%|██▏       | 15/67 [02:49<08:37,  9.95s/it][A
 24%|██▍       | 16/67 [02:56<07:41,  9.05s/it][A
 25%|██▌       | 17/67 [03:17<10:37, 12.75s/it][A
 27%|██▋       | 18/67 [03:29<10:11, 12.48s/it][A
 28%|██▊       | 19/67 [03:42<10:04, 12.59s/it][A
 30%|██▉       | 20/67 [03:51<08:59, 11.49s/it][A
 31%|███▏      | 21/67 [04:16<12:06, 15.79s/it][A
 33%|███▎      | 22/67 [04:33<11:59, 15.99s/it][A
 34%|███▍      | 23/67 [04:41<09:58, 13.61s/it][A
 36%|███▌      | 24/67 [04:56<09:58, 13.92s/it][A
 37%|███▋      | 25/67 [05:16<11:08, 15.91s/it][A
 39%|███▉      | 26/67 [05:28<10:06, 14.78s/it][A
 40%|████      | 27/67 [05:43<09:45, 14.65s/it][A
 42%|████▏     | 28/67 [05:53<08:36, 13.26s/it][A
 43%|████▎     | 29/67 [06:01<07:23, 11.67s/it][A
 45%|████▍     | 30/67 [06:08<06:27, 10.48s/it][A
 46%|████▋     | 31/67 [06:12<05:07,  8.55s/it][A
 48%|████▊     | 32/67 [06:22<05:14,  9.00s/it][A
 49%|████▉     | 33/67 [06:45<07:21, 12.97s/it][A
 51%|█████     | 34/67 [06:55<06:45, 12.27s/it][A
 52%|█████▏    | 35/67 [07:07<06:28, 12.13s/it][A
 54%|█████▎    | 36/67 [07:19<06:14, 12.07s/it][A
 55%|█████▌    | 37/67 [07:25<05:12, 10.41s/it][A
 57%|█████▋    | 38/67 [07:37<05:12, 10.78s/it][A
 58%|█████▊    | 39/67 [07:50<05:15, 11.26s/it][A
 60%|█████▉    | 40/67 [08:00<04:54, 10.91s/it][A
 61%|██████    | 41/67 [08:09<04:33, 10.53s/it][A
 63%|██████▎   | 42/67 [08:24<04:52, 11.69s/it][A
 64%|██████▍   | 43/67 [08:36<04:43, 11.83s/it][A
 66%|██████▌   | 44/67 [08:53<05:07, 13.38s/it][A
 67%|██████▋   | 45/67 [08:59<04:04, 11.11s/it][A
 69%|██████▊   | 46/67 [09:07<03:35, 10.27s/it][A
 70%|███████   | 47/67 [09:23<03:58, 11.91s/it][A
 72%|███████▏  | 48/67 [09:33<03:39, 11.53s/it][A
 73%|███████▎  | 49/67 [09:51<04:03, 13.51s/it][A
 75%|███████▍  | 50/67 [10:03<03:39, 12.93s/it][A
 76%|███████▌  | 51/67 [10:16<03:25, 12.85s/it][A
 78%|███████▊  | 52/67 [10:29<03:16, 13.08s/it][A
 79%|███████▉  | 53/67 [10:42<03:01, 12.99s/it][A
 81%|████████  | 54/67 [10:50<02:29, 11.49s/it][A
 82%|████████▏ | 55/67 [11:06<02:35, 12.97s/it][A
 84%|████████▎ | 56/67 [11:26<02:45, 15.04s/it][A
 85%|████████▌ | 57/67 [11:47<02:46, 16.62s/it][A
 87%|████████▋ | 58/67 [12:27<03:32, 23.66s/it][A
 88%|████████▊ | 59/67 [12:44<02:52, 21.62s/it][A
 90%|████████▉ | 60/67 [13:03<02:26, 20.98s/it][A
 91%|█████████ | 61/67 [13:13<01:45, 17.52s/it][A
 93%|█████████▎| 62/67 [13:20<01:13, 14.64s/it][A
 94%|█████████▍| 63/67 [13:30<00:52, 13.15s/it][A
 96%|█████████▌| 64/67 [13:41<00:37, 12.51s/it][A
 97%|█████████▋| 65/67 [13:50<00:22, 11.29s/it][A
 99%|█████████▊| 66/67 [14:02<00:11, 11.58s/it][A
100%|██████████| 67/67 [14:04<00:00,  8.62s/it][A                                                      
                                               [A100%|██████████| 1710/1710 [16:29:49<00:00, 19.12s/it]
100%|██████████| 67/67 [14:05<00:00,  8.62s/it][A
                                               [A                                                      100%|██████████| 1710/1710 [16:29:50<00:00, 19.12s/it]100%|██████████| 1710/1710 [16:29:50<00:00, 34.73s/it]
{'f1_1': 0.44799176107106076, 'precision': 0.44433094994892747, 'recall': 0.4517133956386293}
{'f1': 0.431513903192585, 'precision': 0.4279877425944842, 'recall': 0.43509865005192105}
{'eval_f1': 0.431513903192585, 'eval_precision': 0.4279877425944842, 'eval_recall': 0.43509865005192105, 'eval_runtime': 857.1897, 'eval_samples_per_second': 0.463, 'eval_steps_per_second': 0.078, 'epoch': 30.0}
{'train_runtime': 59390.7256, 'train_samples_per_second': 0.69, 'train_steps_per_second': 0.029, 'train_loss': 0.26081850057432415, 'epoch': 30.0}
***** train metrics *****
  epoch                    =        30.0
  train_loss               =      0.2608
  train_runtime            = 16:29:50.72
  train_samples_per_second =        0.69
  train_steps_per_second   =       0.029
scripts/run.sh: line 2: on: command not found
